import json
import random
import re
import time
from html import unescape
from typing import Dict, List, Tuple, Optional

import requests
import streamlit as st
from requests.exceptions import ReadTimeout, ConnectionError, HTTPError, RequestException
from concurrent.futures import ThreadPoolExecutor, as_completed

st.set_page_config(page_title="ë‚˜ì™€ ì–´ìš¸ë¦¬ëŠ” ì±…ì€?", page_icon="ðŸ“š", layout="centered")

# =====================================================
# Sidebar
# =====================================================
st.sidebar.header("ðŸ”‘ API ì„¤ì •")

nl_api_key = st.sidebar.text_input(
    "êµ­ë¦½ì¤‘ì•™ë„ì„œê´€(ISBN ì„œì§€ì •ë³´) API Key (cert_key)",
    type="password",
)

openai_api_key = st.sidebar.text_input(
    "OpenAI API Key (ì„ íƒ)",
    type="password",
    help="ìž…ë ¥í•˜ë©´ AIê°€ 'í•œêµ­ì–´ ì±…' 3ê¶Œì„ ì¶”ì²œí•©ë‹ˆë‹¤. ì—†ìœ¼ë©´ ë°ëª¨ ì¶”ì²œ ëª©ë¡ìœ¼ë¡œ ë™ìž‘í•©ë‹ˆë‹¤.",
)

openai_model = st.sidebar.text_input("OpenAI ëª¨ë¸", value="gpt-4o-mini")

demo_mode = st.sidebar.checkbox(
    "ë°ëª¨ ëª¨ë“œ(ì„œì§€ì •ë³´ ì‹¤íŒ¨í•´ë„ ê²°ê³¼ ë³´ê¸°)",
    value=True,
)

st.sidebar.subheader("âš¡ ì†ë„ ì˜µì…˜(ì¶”ì²œ)")
fetch_summary_default = st.sidebar.checkbox(
    "ì¤„ê±°ë¦¬/ì±…ì†Œê°œë„ ë°”ë¡œ ê°€ì ¸ì˜¤ê¸°(ëŠë¦¼)",
    value=False,
    help="OFF ê¶Œìž¥: ê¸°ë³¸ì€ í‘œì§€/ISBNë§Œ ì¡°íšŒí•´ì„œ ë¹ ë¥´ê²Œ ë³´ì—¬ì¤ë‹ˆë‹¤. ì¤„ê±°ë¦¬ëŠ” ë²„íŠ¼ìœ¼ë¡œ ì§€ì—° ë¡œë”© ê°€ëŠ¥.",
)

nl_timeout = st.sidebar.slider("êµ­ë¦½ì¤‘ì•™ë„ì„œê´€ API íƒ€ìž„ì•„ì›ƒ(ì´ˆ)", 5, 30, 10, 1)
nl_retries = st.sidebar.slider("êµ­ë¦½ì¤‘ì•™ë„ì„œê´€ API ìž¬ì‹œë„ íšŸìˆ˜", 0, 2, 1, 1)
max_workers = st.sidebar.slider("ë™ì‹œ ìš”ì²­ ìˆ˜(ë³‘ë ¬ ì²˜ë¦¬)", 1, 6, 3, 1)

# =====================================================
# Header
# =====================================================
st.title("ðŸ“š ë‚˜ì™€ ì–´ìš¸ë¦¬ëŠ” ì±…ì€?")
st.write("ì„±í–¥(ìž¥ë¥´) + ìƒí™©(ì§€ê¸ˆ í•„ìš”í•œ ê²ƒ)ì„ í•¨ê»˜ ë¶„ì„í•´ ì±… 3ê¶Œì„ ì¶”ì²œí•©ë‹ˆë‹¤.")

# =====================================================
# Questions
# =====================================================
questions = [
    "1) ìƒˆë¡œìš´ ì±…ì„ ê³ ë¥¼ ë•Œ ê°€ìž¥ ëŒë¦¬ëŠ” ìš”ì†ŒëŠ”?",
    "2) ì¹œêµ¬ê°€ ì±… ì¶”ì²œì„ ë¶€íƒí•˜ë©´ ë‚˜ëŠ” ë³´í†µâ€¦",
    "3) ë‚´ê°€ ì±…ì„ ì½ì„ ë•Œ ê°€ìž¥ ë§Œì¡±ìŠ¤ëŸ¬ìš´ ìˆœê°„ì€?",
    "4) í‰ì†Œ ë‚´ê°€ ê°€ìž¥ ìžì£¼ ê´€ì‹¬ì„ ê°–ëŠ” ì£¼ì œëŠ”?",
    "5) ìš”ì¦˜ ë‚˜ì—ê²Œ ê°€ìž¥ í•„ìš”í•œ ê²ƒì€?",
    "6) ìµœê·¼ ë‚´ê°€ ì±…ì„ ì°¾ê²Œ ë˜ëŠ” ì´ìœ ëŠ”?",
    "7) ì§€ê¸ˆ ë‹¹ìž¥ ì±…ì´ ë‚´ê²Œ í•´ì¤¬ìœ¼ë©´ í•˜ëŠ” ì—­í• ì€?",
]

question_choices = [
    ["A. ì½ê³  ë‚˜ì„œ ë°”ë¡œ ì‹¤ì²œí•  ìˆ˜ ìžˆëŠ” ì¡°ì–¸","B. ì‚¶ì— ëŒ€í•œ ê¹Šì€ ì§ˆë¬¸ê³¼ í†µì°°","C. ìƒˆë¡œìš´ ì§€ì‹ê³¼ ê¸°ìˆ ì„ ë°°ìš°ëŠ” ìž¬ë¯¸","D. ì‚¬íšŒì™€ ì‹œëŒ€ë¥¼ ì´í•´í•˜ëŠ” ê´€ì ","E. ê°ì •ì ìœ¼ë¡œ ëª°ìž…í•  ìˆ˜ ìžˆëŠ” ì´ì•¼ê¸°"],
    ["A. ë„ì›€ì´ ë  ë§Œí•œ í˜„ì‹¤ì ì¸ ì±…ì„ ì¶”ì²œí•œë‹¤","B. ìƒê°ì„ ë„“í˜€ì¤„ ì±…ì„ ì¶”ì²œí•œë‹¤","C. ì‹ ê¸°í•œ ì •ë³´ë¥¼ ì£¼ëŠ” ì±…ì„ ì¶”ì²œí•œë‹¤","D. ì„¸ìƒì„ ì´í•´í•˜ê²Œ í•´ì£¼ëŠ” ì±…ì„ ì¶”ì²œí•œë‹¤","E. ìž¬ë¯¸ìžˆê²Œ ì½ížˆëŠ” ì±…ì„ ì¶”ì²œí•œë‹¤"],
    ["A. â€œì´ê±´ ë‚´ ì‚¶ì— ë°”ë¡œ ì ìš©í•  ìˆ˜ ìžˆê² ë‹¤â€ ëŠë‚„ ë•Œ","B. â€œì„¸ìƒì„ ë³´ëŠ” ì‹œì•¼ê°€ ë„“ì–´ì¡Œë‹¤â€ ëŠë‚„ ë•Œ","C. â€œìƒˆë¡œìš´ ì‚¬ì‹¤ì„ ë°°ì› ë‹¤â€ ëŠë‚„ ë•Œ","D. â€œì‚¬íšŒë‚˜ ì—­ì‚¬ë¥¼ ì´í•´í•˜ê²Œ ëë‹¤â€ ëŠë‚„ ë•Œ","E. â€œì™„ì „ížˆ ëª°ìž…í•´ì„œ ê°ì •ì´ ì›€ì§ì˜€ë‹¤â€ ëŠë‚„ ë•Œ"],
    ["A. ì„±ìž¥, ëª©í‘œ, ìžê¸°ê´€ë¦¬","B. ì¸ê°„ê´€ê³„, ì‚¶ì˜ ì˜ë¯¸","C. ë¯¸ëž˜ê¸°ìˆ , ê³¼í•™, ë°ì´í„°","D. ì‚¬íšŒë¬¸ì œ, ì—­ì‚¬ì  ì‚¬ê±´","E. ê°ì •, ì´ì•¼ê¸°, ìƒìƒ ì† ì„¸ê³„"],
    ["A. ë‹¤ì‹œ ë™ê¸°ë¶€ì—¬í•˜ê³  ë°©í–¥ì„ ìž¡ëŠ” ê²ƒ","B. ë‚´ ë§ˆìŒì„ ì •ë¦¬í•  ìˆ˜ ìžˆëŠ” í†µì°°","C. ë¨¸ë¦¬ë¥¼ ìžê·¹í•˜ëŠ” ìƒˆë¡œìš´ í˜¸ê¸°ì‹¬","D. í˜„ì‹¤ì„ ì´í•´í•˜ê³  ì‹œì•¼ë¥¼ ë„“ížˆëŠ” ê´€ì ","E. ìœ„ë¡œë°›ê³  ê°ì •ì„ ì‰¬ê²Œ í•˜ëŠ” ì´ì•¼ê¸°"],
    ["A. ë¯¸ëž˜ ì¤€ë¹„ë‚˜ ìžê¸°ê³„ë°œì´ í•„ìš”í•´ì„œ","B. ë³µìž¡í•œ ê°ì •ì„ ì •ë¦¬í•˜ê³  ì‹¶ì–´ì„œ","C. ìƒˆë¡œìš´ ë¶„ì•¼ë¥¼ ë°°ìš°ê³  ì‹¶ì–´ì„œ","D. ì‚¬íšŒì™€ ì„¸ìƒ íë¦„ì´ ê¶ê¸ˆí•´ì„œ","E. ì§€ì¹˜ê³  ì‰¬ê³  ì‹¶ì–´ì„œ"],
    ["A. â€œì•žìœ¼ë¡œ ë­˜ í•´ì•¼ í• ì§€ ì•Œë ¤ì£¼ëŠ” ë‚˜ì¹¨ë°˜â€","B. â€œìƒê°ì„ ì •ë¦¬í•´ì£¼ëŠ” ëŒ€í™” ìƒëŒ€â€","C. â€œìƒˆë¡œìš´ ì„¸ìƒì„ ë³´ì—¬ì£¼ëŠ” ì°½ë¬¸â€","D. â€œí˜„ì‹¤ì„ ì´í•´í•˜ê²Œ í•´ì£¼ëŠ” ì§€ë„â€","E. â€œë§ˆìŒì„ ì‰¬ê²Œ í•´ì£¼ëŠ” íœ´ì‹ì²˜â€"],
]

# =====================================================
# Mappings
# =====================================================
genre_map = {"A": "ìžê¸°ê³„ë°œ", "B": "ì¸ë¬¸/ì² í•™", "C": "ê³¼í•™/IT", "D": "ì—­ì‚¬/ì‚¬íšŒ", "E": "ì†Œì„¤"}

genre_persona = {
    "ìžê¸°ê³„ë°œ": "ì‹¤í–‰Â·ë£¨í‹´Â·ì„±ê³¼ë¥¼ ì¤‘ì‹œí•˜ëŠ” ì„±ìž¥í˜•",
    "ì¸ë¬¸/ì² í•™": "ì˜ë¯¸Â·ê°€ì¹˜Â·ìžê¸°ì´í•´ë¥¼ ê¹Šê²Œ íŒŒê³ ë“œëŠ” ì„±ì°°í˜•",
    "ê³¼í•™/IT": "ì›ë¦¬Â·êµ¬ì¡°Â·ì •ë³´ë¥¼ ë¶„ì„í•˜ëŠ” íƒêµ¬í˜•",
    "ì—­ì‚¬/ì‚¬íšŒ": "ì‚¬íšŒ êµ¬ì¡°Â·ë§¥ë½Â·íë¦„ì„ ì´í•´í•˜ë ¤ëŠ” ê´€ì°°í˜•",
    "ì†Œì„¤": "ê°ì •Â·ë¶„ìœ„ê¸°Â·ì„œì‚¬ ëª°ìž…ì„ í†µí•´ íšŒë³µí•˜ëŠ” ê°ì„±í˜•",
}

genre_book_point = {
    "ìžê¸°ê³„ë°œ": "ë°”ë¡œ ì ìš© ê°€ëŠ¥í•œ ìŠµê´€Â·ì‹¤í–‰ í¬ì¸íŠ¸",
    "ì¸ë¬¸/ì² í•™": "ê°ì •ê³¼ ìƒê°ì„ ì •ë¦¬í•´ì£¼ëŠ” í†µì°°",
    "ê³¼í•™/IT": "ìƒˆë¡œìš´ ì§€ì‹ê³¼ ì›ë¦¬ë¥¼ ì´í•´í•˜ëŠ” ìž¬ë¯¸",
    "ì—­ì‚¬/ì‚¬íšŒ": "ì„¸ìƒ íë¦„ì„ ì½ê³  ê´€ì ì„ ë„“ížˆëŠ” ë‚´ìš©",
    "ì†Œì„¤": "ê°ì •ì ìœ¼ë¡œ ëª°ìž…í•˜ë©° ìœ„ë¡œì™€ ì—¬ìš´ì„ ì£¼ëŠ” ì„œì‚¬",
}

genre_flavors = {
    "ìžê¸°ê³„ë°œ": ["ì‹¤í–‰", "ë£¨í‹´", "ë™ê¸°ë¶€ì—¬", "ìŠµê´€", "ìžê¸°ê´€ë¦¬"],
    "ì¸ë¬¸/ì² í•™": ["ì„±ì°°", "ê´€ì ", "ìžê¸°ì´í•´", "ê°€ì¹˜", "ì§ˆë¬¸"],
    "ê³¼í•™/IT": ["ì›ë¦¬", "í˜¸ê¸°ì‹¬", "ë¯¸ëž˜", "ë¬¸ì œí•´ê²°", "êµ¬ì¡°"],
    "ì—­ì‚¬/ì‚¬íšŒ": ["ë§¥ë½", "íë¦„", "êµ¬ì¡°", "ì‚¬ë¡€", "ì‹œì•¼"],
    "ì†Œì„¤": ["ìœ„ë¡œ", "ëª°ìž…", "ì—¬ìš´", "ê´€ê³„", "íšŒë³µ"],
}

situation_tag_map_q5_to_q7 = {
    5: {"A": ["ë™ê¸°"], "B": ["ìœ„ë¡œ"], "C": ["íƒêµ¬"], "D": ["íƒêµ¬"], "E": ["ìœ„ë¡œ", "íœ´ì‹"]},
    6: {"A": ["ë™ê¸°"], "B": ["ìœ„ë¡œ"], "C": ["íƒêµ¬"], "D": ["íƒêµ¬"], "E": ["íœ´ì‹", "ìœ„ë¡œ"]},
    7: {"A": ["ë™ê¸°"], "B": ["ìœ„ë¡œ"], "C": ["íƒêµ¬"], "D": ["íƒêµ¬"], "E": ["íœ´ì‹", "ìœ„ë¡œ"]},
}
tag_display = {"ë™ê¸°": "ë°©í–¥/ë™ê¸°ë¶€ì—¬", "ìœ„ë¡œ": "ê°ì • ì •ë¦¬/ìœ„ë¡œ", "íœ´ì‹": "íœ´ì‹/íšŒë³µ", "íƒêµ¬": "í˜¸ê¸°ì‹¬/íƒêµ¬"}

# =====================================================
# Demo fallback pool (í•œêµ­ì–´/ë²ˆì—­ì„œ í˜¼í•©ì´ì§€ë§Œ í•œêµ­ì–´ë¡œ ìœ í†µë˜ëŠ” ì±…ë“¤)
# =====================================================
fallback_pool = {
    "ìžê¸°ê³„ë°œ": [{"title": "ì•„ì£¼ ìž‘ì€ ìŠµê´€ì˜ íž˜", "author": "ì œìž„ìŠ¤ í´ë¦¬ì–´"},{"title": "ê·¸ë¦¿", "author": "ì•¤ì ˆë¼ ë”í¬ì›ŒìŠ¤"},{"title": "ë”¥ ì›Œí¬", "author": "ì¹¼ ë‰´í¬íŠ¸"},{"title": "ì›ì”½", "author": "ê²Œë¦¬ ì¼ˆëŸ¬"},{"title": "ë¯¸ë¼í´ ëª¨ë‹", "author": "í•  ì—˜ë¡œë“œ"}],
    "ì¸ë¬¸/ì² í•™": [{"title": "ì •ì˜ëž€ ë¬´ì—‡ì¸ê°€", "author": "ë§ˆì´í´ ìƒŒë¸"},{"title": "ì£½ìŒì˜ ìˆ˜ìš©ì†Œì—ì„œ", "author": "ë¹…í„° í”„ëž­í´"},{"title": "ì†Œí¬ë¼í…ŒìŠ¤ ìµìŠ¤í”„ë ˆìŠ¤", "author": "ì—ë¦­ ì™€ì´ë„ˆ"},{"title": "ì² í•™ì€ ì–´ë–»ê²Œ ì‚¶ì˜ ë¬´ê¸°ê°€ ë˜ëŠ”ê°€", "author": "ì•¼ë§ˆêµ¬ì¹˜ ìŠˆ"},{"title": "ì‚¬í”¼ì—”ìŠ¤", "author": "ìœ ë°œ í•˜ë¼ë¦¬"}],
    "ê³¼í•™/IT": [{"title": "ì½”ìŠ¤ëª¨ìŠ¤", "author": "ì¹¼ ì„¸ì´ê±´"},{"title": "íŒ©íŠ¸í’€ë‹ˆìŠ¤", "author": "í•œìŠ¤ ë¡œìŠ¬ë§"},{"title": "í´ë¦° ì½”ë“œ", "author": "ë¡œë²„íŠ¸ C. ë§ˆí‹´"},{"title": "AI 2041", "author": "ì¹´ì´í‘¸ ë¦¬, ì²œì¹˜ìš°íŒ"},{"title": "ì´ê¸°ì  ìœ ì „ìž", "author": "ë¦¬ì²˜ë“œ ë„í‚¨ìŠ¤"}],
    "ì—­ì‚¬/ì‚¬íšŒ": [{"title": "ì´, ê· , ì‡ ", "author": "ìž¬ë ˆë“œ ë‹¤ì´ì•„ëª¬ë“œ"},{"title": "ë„›ì§€", "author": "ë¦¬ì²˜ë“œ íƒˆëŸ¬, ìºìŠ¤ ì„ ìŠ¤íƒ€ì¸"},{"title": "ì—­ì‚¬ì˜ ì“¸ëª¨", "author": "ìµœíƒœì„±"},{"title": "21ì„¸ê¸° ìžë³¸", "author": "í† ë§ˆ í”¼ì¼€í‹°"},{"title": "ì •ì¹˜ì˜ ì‹¬ë¦¬í•™", "author": "ë“œë£¨ ì›¨ìŠ¤í„´"}],
    "ì†Œì„¤": [{"title": "ë‚˜ë¯¸ì•¼ ìž¡í™”ì ì˜ ê¸°ì ", "author": "ížˆê°€ì‹œë…¸ ê²Œì´ê³ "},{"title": "ë¶ˆíŽ¸í•œ íŽ¸ì˜ì ", "author": "ê¹€í˜¸ì—°"},{"title": "1984", "author": "ì¡°ì§€ ì˜¤ì›°"},{"title": "ë‹¬ëŸ¬êµ¬íŠ¸ ê¿ˆ ë°±í™”ì ", "author": "ì´ë¯¸ì˜ˆ"},{"title": "ë°ë¯¸ì•ˆ", "author": "í—¤ë¥´ë§Œ í—¤ì„¸"}],
}

# =====================================================
# Session state
# =====================================================
if "submitted" not in st.session_state:
    st.session_state.submitted = False
if "result" not in st.session_state:
    st.session_state.result = None
if "summary_loaded" not in st.session_state:
    st.session_state.summary_loaded = False

for i in range(7):
    k = f"q{i+1}"
    if k not in st.session_state:
        st.session_state[k] = None

def reset_test():
    for i in range(7):
        st.session_state[f"q{i+1}"] = None
    st.session_state.submitted = False
    st.session_state.result = None
    st.session_state.summary_loaded = False

# =====================================================
# Scoring
# =====================================================
def letter_of(ans: str) -> str:
    return ans.strip()[0]

def compute_genre_scores(answers: List[str]) -> Dict[str, int]:
    scores = {g: 0 for g in genre_map.values()}
    for a in answers:
        scores[genre_map[letter_of(a)]] += 1
    return scores

def compute_situation_scores(answers: List[str]) -> Dict[str, int]:
    tags = {"ìœ„ë¡œ": 0, "íœ´ì‹": 0, "ë™ê¸°": 0, "íƒêµ¬": 0}
    for qno in [5, 6, 7]:
        l = letter_of(answers[qno - 1])
        for t in situation_tag_map_q5_to_q7[qno].get(l, []):
            tags[t] += 1
    return tags

def ranked(scores: Dict[str, int]):
    return sorted(scores.items(), key=lambda x: x[1], reverse=True)

def top_keys(scores: Dict[str, int]):
    r = ranked(scores)
    maxv = r[0][1]
    top = [k for k, v in r if v == maxv]
    # second tier for fallback mixing
    second = [k for k, v in r if v == (r[1][1] if len(r) > 1 else -1)]
    return top, second, r

def pick_3_books(top_genres: List[str], second_genres: List[str]):
    # ë³µí•© ì„±í–¥ì´ë©´ ì„žê³ , ì•„ë‹ˆë©´ 1ë“± 2ê¶Œ + 2ë“± 1ê¶Œ(ìžˆìœ¼ë©´)
    if len(top_genres) >= 2:
        pool = []
        for g in top_genres[:2]:
            pool += [{"genre": g, **b} for b in fallback_pool[g]]
        random.shuffle(pool)
        out, seen = [], set()
        for item in pool:
            if item["title"] in seen:
                continue
            out.append(item)
            seen.add(item["title"])
            if len(out) == 3:
                break
        return out

    primary = top_genres[0]
    out = [{"genre": primary, **b} for b in random.sample(fallback_pool[primary], k=2)]
    if second_genres and second_genres[0] != primary:
        out.append({"genre": second_genres[0], **random.choice(fallback_pool[second_genres[0]])})
        random.shuffle(out)
        return out[:3]
    return [{"genre": primary, **b} for b in random.sample(fallback_pool[primary], k=3)]

# =====================================================
# Evidence + diversified reason generation
# =====================================================
def evidence_by_genre(answers: List[str], target_genre: str) -> List[str]:
    target_letter = next((l for l, g in genre_map.items() if g == target_genre), None)
    return [a[3:].strip() for a in answers if target_letter and letter_of(a) == target_letter]

def situation_evidence_candidates(answers: List[str], situation_tags: List[str]) -> List[str]:
    ev = []
    for qno in [5, 6, 7]:
        ans = answers[qno - 1]
        l = letter_of(ans)
        tags = situation_tag_map_q5_to_q7[qno].get(l, [])
        if any(t in situation_tags for t in tags):
            ev.append(ans[3:].strip())
    return ev

def rotate_pick(items: List[str], used: set, fallback: str = "") -> str:
    for it in items:
        if it and it not in used:
            used.add(it)
            return it
    return fallback if fallback else (items[0] if items else "")

def pick_focus_tag(top_situations: List[str], idx: int) -> List[str]:
    if not top_situations:
        return []
    if len(top_situations) == 1:
        return top_situations
    if idx == 0:
        return [top_situations[0]]
    if idx == 1:
        return [top_situations[1 % len(top_situations)]]
    return top_situations[:2]

reason_templates = [
    "ìµœê·¼ â€œ{s_ev}â€ë¼ê³  ë‹µí•œ ê±¸ ë³´ë©´ ì§€ê¸ˆì€ **{sit}**ì´(ê°€) í•„ìš”í•´ ë³´ì—¬ìš”. ê·¸ë¦¬ê³  â€œ{g_ev}â€ ì„ íƒì´ ë§Žì•„ {persona} ì„±í–¥ë„ ê°•í•˜ë„¤ìš”. ê·¸ëž˜ì„œ **{title}**ì„(ë¥¼) ì¶”ì²œí•©ë‹ˆë‹¤. ({flavor} í¬ì¸íŠ¸ì— íŠ¹ížˆ ìž˜ ë§žì•„ìš”.)",
    "ë‹¹ì‹ ì´ ê³ ë¥¸ ë‹µë³€ ì¤‘ â€œ{g_ev}â€ê°€ ëˆˆì— ë„ì–´ìš”. {persona} ì„±í–¥ì¸ ë‹¹ì‹ ì—ê²Œ **{sit}**ì„(ë¥¼) ì±„ì›Œì¤„ ì±…ì´ í•„ìš”í•´ì„œ, {flavor}ì— ê°•í•œ **{title}**ì„(ë¥¼) ê³¨ëžì–´ìš”.",
    "ì§€ê¸ˆì€ **{sit}**ì„(ë¥¼) ì–»ëŠ” ê²Œ ìš°ì„ ì¼ ê²ƒ ê°™ì•„ìš”(â€œ{s_ev}â€). ë™ì‹œì— â€œ{g_ev}â€ë¥¼ ì„ íƒí•œ ê±¸ ë³´ë©´ {persona}ë‹µê²Œ ì½ì„ ë§Œí•œ ì±…ì´ í•„ìš”í•˜ì£ . ê·¸ëž˜ì„œ **{title}**ì„(ë¥¼) ì¶”ì²œí•©ë‹ˆë‹¤.",
    "ì„¤ë¬¸ì—ì„œ â€œ{s_ev}â€ë¼ê³  í–ˆë˜ ì ì„ ë°˜ì˜í–ˆì–´ìš”. {persona} ì„±í–¥ì˜ ë‹¹ì‹ ì—ê²Œ **{title}**ì€(ëŠ”) {flavor}ì„ í†µí•´ **{sit}**ì— ë„ì›€ì„ ì¤„ í™•ë¥ ì´ ë†’ì•„ìš”.",
    "í˜„ìž¬ ìƒíƒœ(â€œ{s_ev}â€)ë¥¼ ë³´ë©´ **{sit}**ì„(ë¥¼) ì±™ê²¨ì•¼ í•´ìš”. ê·¸ë¦¬ê³  â€œ{g_ev}â€ ì„ íƒì€ {persona} ì„±í–¥ì„ ë³´ì—¬ì¤˜ìš”. ê·¸ëž˜ì„œ {flavor}ì´(ê°€) ê°•í•œ **{title}**ì„(ë¥¼) ì¶”ì²œí•©ë‹ˆë‹¤.",
]

def build_reason_diversified(
    answers: List[str],
    title: str,
    genre: str,
    top_situations: List[str],
    idx: int,
    used_genre_ev: set,
    used_sit_ev: set,
    used_flavor: set,
    used_template: set,
) -> str:
    focus_tags = pick_focus_tag(top_situations, idx)
    sit_label = ", ".join([tag_display.get(t, t) for t in focus_tags]) if focus_tags else "ì§€ê¸ˆ í•„ìš”í•œ ê²ƒ"

    g_candidates = evidence_by_genre(answers, genre)
    s_candidates = situation_evidence_candidates(answers, focus_tags) if focus_tags else []

    g_ev = rotate_pick(g_candidates, used_genre_ev, fallback=(g_candidates[0] if g_candidates else "ì±…ì—ì„œ ì–»ê³  ì‹¶ì€ ê²Œ ìžˆë‹¤"))
    s_ev = rotate_pick(s_candidates, used_sit_ev, fallback="ìš”ì¦˜ ì±…ì´ í•„ìš”í•˜ë‹¤")

    # ê·¼ê±°ê°€ ë¹ˆ ê²½ìš° ëŒ€ë¹„
    if s_ev == "ìš”ì¦˜ ì±…ì´ í•„ìš”í•˜ë‹¤":
        q5to7 = [answers[i][3:].strip() for i in [4, 5, 6] if answers[i]]
        if q5to7:
            s_ev = rotate_pick(q5to7, used_sit_ev, fallback=q5to7[0])
    if g_ev == "ì±…ì—ì„œ ì–»ê³  ì‹¶ì€ ê²Œ ìžˆë‹¤":
        q1to4 = [answers[i][3:].strip() for i in [0, 1, 2, 3] if answers[i]]
        if q1to4:
            g_ev = rotate_pick(q1to4, used_genre_ev, fallback=q1to4[0])

    flavor_candidates = genre_flavors.get(genre, [])
    flavor = rotate_pick(flavor_candidates, used_flavor, fallback=(flavor_candidates[0] if flavor_candidates else "í•µì‹¬"))

    template = rotate_pick(reason_templates, used_template, fallback=reason_templates[idx % len(reason_templates)])
    persona = genre_persona.get(genre, "ì´ëŸ° ì„±í–¥")

    return template.format(s_ev=s_ev, g_ev=g_ev, sit=sit_label, persona=persona, title=title, flavor=flavor)

# =====================================================
# OpenAI (í•œêµ­ì–´ ì±…ë§Œ ì¶”ì²œ)
# =====================================================
@st.cache_data(show_spinner=False)
def call_openai_json(api_key: str, model: str, system: str, user: str) -> dict:
    url = "https://api.openai.com/v1/chat/completions"
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    payload = {
        "model": model,
        "temperature": 0.6,
        "response_format": {"type": "json_object"},
        "messages": [{"role": "system", "content": system}, {"role": "user", "content": user}],
    }
    r = requests.post(url, headers=headers, json=payload, timeout=30)
    r.raise_for_status()
    return json.loads(r.json()["choices"][0]["message"]["content"])

def ai_pick_books_korean_only(answers: List[str], focus_genres: List[str], top_situations: List[str]) -> List[dict]:
    system = (
        "ë„ˆëŠ” í•œêµ­ì˜ ë…ì„œ íë ˆì´í„°ë‹¤.\n"
        "ë°˜ë“œì‹œ 'í•œêµ­ì–´ë¡œ ì¶œê°„/ìœ í†µë˜ëŠ” ì±…(êµ­ë‚´ ë„ì„œ ë˜ëŠ” í•œêµ­ì–´ ë²ˆì—­ì„œ)'ë§Œ ì¶”ì²œí•´ë¼.\n"
        "ì‚¬ìš©ìžì˜ ì„¤ë¬¸(ì„±í–¥+ìƒí™©)ì„ ë°˜ì˜í•´ 3ê¶Œì„ ì¶”ì²œí•˜ë˜, ì•„ëž˜ JSON í˜•ì‹ë§Œ ì¶œë ¥í•´ë¼.\n\n"
        "{\n"
        '  "recommendations": [\n'
        '    {"title":"ë„ì„œëª…", "author":"ì €ìž(ëª¨ë¥´ë©´ ë¹ˆ ë¬¸ìžì—´)", "genre":"ìžê¸°ê³„ë°œ|ì¸ë¬¸/ì² í•™|ê³¼í•™/IT|ì—­ì‚¬/ì‚¬íšŒ|ì†Œì„¤"}\n'
        "  ]\n"
        "}\n\n"
        "ê·œì¹™:\n"
        "- ë°˜ë“œì‹œ ì‹¤ì œë¡œ ì¡´ìž¬í•˜ëŠ” ì±…\n"
        "- genreëŠ” ì§€ì •ëœ 5ê°œ ì¤‘ í•˜ë‚˜\n"
        "- focus_genresë¥¼ ìš°ì„  ë°˜ì˜í•˜ë˜, ìƒí™©(top_situations)ë„ ê³ ë ¤\n"
        "- ëŒ€í•™ìƒì´ ì½ê¸° ë¬´ë‚œí•œ ë‚œì´ë„ ìš°ì„ \n"
        "- ì‹œ/ë§Œí™”/ì›¹íˆ°ì€ ì œì™¸\n"
    )
    user = (
        f"focus_genres: {focus_genres}\n"
        f"top_situations: {top_situations}\n"
        "ì‚¬ìš©ìž ë‹µë³€:\n" + "\n".join([f"- {a}" for a in answers])
    )
    obj = call_openai_json(openai_api_key, openai_model, system, user)
    recs = obj.get("recommendations", [])

    cleaned = []
    for r in recs[:5]:  # ì—¬ìœ  ìžˆê²Œ ë°›ê³  3ê°œë¡œ ìžë¦„
        title = str(r.get("title", "")).strip()
        author = str(r.get("author", "")).strip()
        genre = str(r.get("genre", "")).strip()
        if genre not in genre_map.values():
            genre = focus_genres[0] if focus_genres else "ì†Œì„¤"
        if title:
            cleaned.append({"title": title, "author": author, "genre": genre})

    # ì¤‘ë³µ ì œê±°
    uniq = []
    seen = set()
    for c in cleaned:
        if c["title"] in seen:
            continue
        seen.add(c["title"])
        uniq.append(c)
        if len(uniq) == 3:
            break
    return uniq

# =====================================================
# Networking (fast)
# =====================================================
def requests_get(url, params=None, timeout=10, retries=1):
    last = None
    for i in range(retries + 1):
        try:
            return requests.get(url, params=params, timeout=timeout)
        except (ReadTimeout, ConnectionError) as e:
            last = e
            if i == retries:
                raise
            time.sleep(0.4 * (2**i))
    raise last

@st.cache_data(show_spinner=False)
def nl_isbn_search(cert_key: str, title: str, author: str = "", page_size: int = 5, timeout: int = 10, retries: int = 1):
    url = "https://www.nl.go.kr/seoji/SearchApi.do"
    params = {"cert_key": cert_key, "result_style": "json", "page_no": 1, "page_size": page_size, "title": title}
    if author:
        params["author"] = author
    r = requests_get(url, params=params, timeout=timeout, retries=retries)
    r.raise_for_status()
    try:
        return r.json()
    except Exception:
        return json.loads(r.text)

def pick_best_item(nl_json, wanted_title: str):
    items = None
    if isinstance(nl_json, dict):
        for k in ["docs", "data", "items", "result"]:
            if k in nl_json and isinstance(nl_json[k], list):
                items = nl_json[k]
                break
        if items is None:
            for v in nl_json.values():
                if isinstance(v, list) and v and isinstance(v[0], dict):
                    items = v
                    break
    if not items:
        return None

    wt = wanted_title.replace(" ", "").lower()

    def score(it):
        t = str(it.get("TITLE", "") or it.get("title", "")).replace(" ", "").lower()
        if not t:
            return 0
        if t == wt:
            return 100
        if wt in t or t in wt:
            return 60
        return 1

    return sorted(items, key=score, reverse=True)[0]

@st.cache_data(show_spinner=False)
def fetch_text_from_url(url: str, max_chars: int = 650, timeout: int = 10, retries: int = 0) -> str:
    if not url:
        return ""
    try:
        r = requests_get(url, params=None, timeout=timeout, retries=retries)
        r.raise_for_status()
        text = r.text
        text = re.sub(r"<script.*?>.*?</script>", " ", text, flags=re.DOTALL | re.IGNORECASE)
        text = re.sub(r"<style.*?>.*?</style>", " ", text, flags=re.DOTALL | re.IGNORECASE)
        text = re.sub(r"<[^>]+>", " ", text)
        text = unescape(text)
        text = re.sub(r"\s+", " ", text).strip()
        return (text[:max_chars].rstrip() + "â€¦") if len(text) > max_chars else text
    except RequestException:
        return ""

def fetch_one_book_nl(c: dict) -> dict:
    if not nl_api_key:
        return {**c, "isbn": "", "cover_url": "", "summary": "", "note": ""}

    try:
        nl_json = nl_isbn_search(
            nl_api_key,
            title=c["title"],
            author=c.get("author", ""),
            page_size=5,
            timeout=nl_timeout,
            retries=nl_retries,
        )
        item = pick_best_item(nl_json, c["title"])
        if not item:
            return {**c, "isbn": "", "cover_url": "", "summary": "", "note": "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì–´ ì„œì§€ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆì–´ìš”."}

        isbn = item.get("EA_ISBN") or item.get("ISBN") or item.get("isbn") or ""
        cover_url = item.get("TITLE_URL") or item.get("cover") or item.get("image") or ""

        summary = ""
        if fetch_summary_default or st.session_state.summary_loaded:
            intro_url = item.get("BOOK_INTRODUCTION_URL") or ""
            summary_url = item.get("BOOK_SUMMARY_URL") or ""
            summary = fetch_text_from_url(summary_url, timeout=nl_timeout, retries=0)
            if not summary:
                summary = fetch_text_from_url(intro_url, timeout=nl_timeout, retries=0)

        return {
            **c,
            "title": (item.get("TITLE") or c["title"]).strip(),
            "author": (item.get("AUTHOR") or c.get("author", "")).strip(),
            "isbn": str(isbn).strip(),
            "cover_url": str(cover_url).strip(),
            "summary": summary.strip(),
            "note": "",
        }

    except (ReadTimeout, ConnectionError, HTTPError, RequestException):
        if demo_mode:
            return {**c, "isbn": "", "cover_url": "", "summary": "", "note": "API ì‘ë‹µì´ ëŠë ¤ì„œ(Timeout/ì˜¤ë¥˜) ì„œì§€ì •ë³´ë¥¼ ìƒëžµí–ˆì–´ìš”."}
        raise

# =====================================================
# UI: Questionnaire
# =====================================================
st.divider()
st.subheader("ðŸ“ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”")

for i, q in enumerate(questions):
    st.markdown(f"**{q}**")
    st.radio(
        label=f"q{i+1}",
        options=question_choices[i],
        key=f"q{i+1}",
        index=None,
        label_visibility="collapsed",
    )
    st.write("")

st.divider()
c1, c2, c3 = st.columns([1, 1, 1.4])
with c1:
    clicked = st.button("ê²°ê³¼ ë³´ê¸°", type="primary")
with c2:
    st.button("ë‹¤ì‹œ í…ŒìŠ¤íŠ¸í•˜ê¸°", on_click=reset_test)
with c3:
    load_summary_clicked = st.button("ì¤„ê±°ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°(ëŠë¦¼)", help="ê²°ê³¼ê°€ ë‚˜ì˜¨ ë’¤ ëˆŒëŸ¬ì£¼ì„¸ìš”. (ì§€ì—° ë¡œë”©)")

if load_summary_clicked:
    st.session_state.summary_loaded = True

# =====================================================
# Flow
# =====================================================
if clicked:
    answers = [st.session_state[f"q{i+1}"] for i in range(7)]
    if any(a is None for a in answers):
        missing = [str(i + 1) for i, a in enumerate(answers) if a is None]
        st.warning(f"ëª¨ë“  ì§ˆë¬¸ì— ë‹µë³€í•´ ì£¼ì„¸ìš”! (ë¯¸ì‘ë‹µ: {', '.join(missing)}ë²ˆ)")
    else:
        with st.spinner("ë¶„ì„ ì¤‘..."):
            genre_scores = compute_genre_scores(answers)
            top_genres, second_genres, _ = top_keys(genre_scores)

            situation_scores = compute_situation_scores(answers)
            top_situations, _, _ = top_keys(situation_scores)

            # focus: ìµœëŒ€ 2ê°œ ìž¥ë¥´
            focus_genres = top_genres[:2] if len(top_genres) >= 2 else (top_genres + second_genres[:1])

            # 1) AI ì¶”ì²œ(ê°€ëŠ¥í•˜ë©´)
            candidates: List[dict] = []
            used_ai = False
            if openai_api_key:
                try:
                    ai_recs = ai_pick_books_korean_only(answers, focus_genres=focus_genres, top_situations=top_situations)
                    if len(ai_recs) == 3:
                        candidates = ai_recs
                        used_ai = True
                except Exception:
                    candidates = []
                    used_ai = False

            # 2) ì‹¤íŒ¨/ë¯¸ìž…ë ¥ ì‹œ fallback
            if len(candidates) < 3:
                fb = pick_3_books(top_genres, second_genres)
                candidates = [{"title": b["title"], "author": b.get("author", ""), "genre": b["genre"]} for b in fb]
                used_ai = False

            # âœ… ì±…ë§ˆë‹¤ ì´ìœ ê°€ ë‹¤ë¥´ê²Œ ìƒì„±
            used_genre_ev, used_sit_ev, used_flavor, used_template = set(), set(), set(), set()
            enriched = []
            for idx, c in enumerate(candidates[:3]):
                why = build_reason_diversified(
                    answers=answers,
                    title=c["title"],
                    genre=c["genre"],
                    top_situations=top_situations,
                    idx=idx,
                    used_genre_ev=used_genre_ev,
                    used_sit_ev=used_sit_ev,
                    used_flavor=used_flavor,
                    used_template=used_template,
                )
                enriched.append({**c, "why": why})

            # âœ… ë³‘ë ¬ë¡œ 3ê¶Œ ì¡°íšŒ (í‘œì§€/ISBN ìš°ì„ )
            books_final = []
            used_nl = False
            if nl_api_key:
                used_nl = True
                with ThreadPoolExecutor(max_workers=max_workers) as ex:
                    futures = [ex.submit(fetch_one_book_nl, c) for c in enriched]
                    for f in as_completed(futures):
                        books_final.append(f.result())
                # ì¶”ì²œ ìˆœì„œ ìœ ì§€(ì›ëž˜ ë¦¬ìŠ¤íŠ¸ ê¸°ì¤€) - title ê¸°ë°˜ìœ¼ë¡œ ì •ë ¬
                order = {b["title"]: i for i, b in enumerate(enriched)}
                books_final.sort(key=lambda x: order.get(x["title"], 999))
            else:
                books_final = [{**c, "isbn": "", "cover_url": "", "summary": "", "note": ""} for c in enriched]

            st.session_state.submitted = True
            st.session_state.result = {
                "genre_scores": genre_scores,
                "genre_top": top_genres,
                "situation_scores": situation_scores,
                "situation_top": top_situations,
                "books": books_final,
                "answers": answers,
                "used_ai": used_ai,
                "used_nl": used_nl,
            }

# =====================================================
# Render
# =====================================================
if st.session_state.submitted and st.session_state.result:
    r = st.session_state.result
    st.subheader("ðŸ“Œ ë¶„ì„ ê²°ê³¼")

    st.success(f"ë…ì„œ ì„±í–¥: {', '.join(r['genre_top'])}")
    sit_text = ", ".join([tag_display.get(t, t) for t in r["situation_top"]])
    st.info(f"í˜„ìž¬ í•„ìš”í•œ ê²ƒ: **{sit_text}**")

    if r.get("used_ai"):
        st.caption("âœ… OpenAIë¥¼ ì‚¬ìš©í•´ 'í•œêµ­ì–´ë¡œ ì¶œê°„/ìœ í†µë˜ëŠ” ì±…' 3ê¶Œì„ ì¶”ì²œí–ˆìŠµë‹ˆë‹¤.")
    else:
        st.caption("â„¹ï¸ OpenAI ë¯¸ì‚¬ìš©/ì‹¤íŒ¨ë¡œ ë°ëª¨ ì¶”ì²œ ëª©ë¡ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.")

    if r.get("used_nl"):
        st.caption("â€» ì†ë„ ê°œì„ : ê¸°ë³¸ì€ í‘œì§€/ISBNë§Œ ì¡°íšŒí•©ë‹ˆë‹¤. ì¤„ê±°ë¦¬ëŠ” â€˜ì¤„ê±°ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°â€™ ë²„íŠ¼ìœ¼ë¡œ ì§€ì—° ë¡œë”©í•˜ì„¸ìš”.")
    else:
        st.warning("êµ­ë¦½ì¤‘ì•™ë„ì„œê´€ API í‚¤ê°€ ì—†ì–´ì„œ í‘œì§€/ISBN/ì¤„ê±°ë¦¬ëŠ” í‘œì‹œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    st.subheader("ðŸ“š ì¶”ì²œ ë„ì„œ 3ê¶Œ")
    for idx, b in enumerate(r["books"], start=1):
        st.markdown(f"### {idx}. {b['title']}")
        meta = []
        if b.get("author"):
            meta.append(f"ì €ìž: {b['author']}")
        if b.get("isbn"):
            meta.append(f"ISBN: {b['isbn']}")
        if meta:
            st.caption(" Â· ".join(meta))

        cols = st.columns([1, 2])
        with cols[0]:
            if b.get("cover_url"):
                st.image(b["cover_url"], use_container_width=True)
            else:
                st.info("í‘œì§€ ì—†ìŒ/ì¡°íšŒ ì‹¤íŒ¨")

        with cols[1]:
            st.write("**ì¶”ì²œ ì´ìœ (ì±…ë§ˆë‹¤ ë‹¤ë¥´ê²Œ ìƒì„±ë¨)**")
            st.write(f"- {b.get('why', '')}")

            st.write("**ì¤„ê±°ë¦¬/ì±…ì†Œê°œ**")
            if b.get("summary"):
                st.write(b["summary"])
            else:
                st.info("ì¤„ê±°ë¦¬ ë¯¸ë¡œë”©(ë²„íŠ¼ìœ¼ë¡œ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìžˆì–´ìš”) ë˜ëŠ” ì œê³µ URL ì—†ìŒ/ì‹¤íŒ¨")

            if b.get("note"):
                st.warning(b["note"])

        st.divider()
