import json
import random
import re
import time
from html import unescape
from typing import Optional, Dict, Any, List, Tuple

import requests
import streamlit as st
from requests.exceptions import ReadTimeout, ConnectionError, HTTPError, RequestException

st.set_page_config(page_title="ë‚˜ì™€ ì–´ìš¸ë¦¬ëŠ” ì±…ì€?", page_icon="ğŸ“š", layout="centered")

# =====================================================
# Sidebar: API Keys / Options
# =====================================================
st.sidebar.header("ğŸ”‘ API ì„¤ì •")

nl_api_key = st.sidebar.text_input(
    "êµ­ë¦½ì¤‘ì•™ë„ì„œê´€(ISBN ì„œì§€ì •ë³´) API Key (cert_key)",
    type="password",
    help="êµ­ë¦½ì¤‘ì•™ë„ì„œê´€ ISBN ì„œì§€ì •ë³´ API cert_key ê°’ì„ ì…ë ¥í•˜ì„¸ìš”.",
)

openai_api_key = st.sidebar.text_input(
    "OpenAI API Key (ì„ íƒ)",
    type="password",
    help="AIê°€ ë„ì„œ í›„ë³´(ë„ì„œëª…/ì €ì)ë¥¼ ë” ë‹¤ì–‘í•˜ê²Œ ì¶”ì²œí•˜ë„ë¡ í•˜ë ¤ë©´ í•„ìš”í•©ë‹ˆë‹¤. ì—†ìœ¼ë©´ ë°ëª¨ ì¶”ì²œ ëª©ë¡ìœ¼ë¡œ ë™ì‘í•©ë‹ˆë‹¤.",
)
openai_model = st.sidebar.text_input("OpenAI ëª¨ë¸", value="gpt-4o-mini")

demo_mode = st.sidebar.checkbox(
    "ë°ëª¨ ëª¨ë“œ(êµ­ë¦½ì¤‘ì•™ë„ì„œê´€ APIê°€ ëŠë¦¬ê±°ë‚˜ ì‹¤íŒ¨í•´ë„ ê²°ê³¼ ë³´ê¸°)",
    value=True,
    help="API í˜¸ì¶œì´ íƒ€ì„ì•„ì›ƒ/ì‹¤íŒ¨í•´ë„ ì¶”ì²œ/ì´ìœ ëŠ” ë¨¼ì € ë³´ì—¬ì£¼ê³ , ì„œì§€ì •ë³´(í‘œì§€/ISBN/ì¤„ê±°ë¦¬)ëŠ” ê°€ëŠ¥í•œ ê²ƒë§Œ í‘œì‹œí•©ë‹ˆë‹¤.",
)

st.sidebar.subheader("â±ï¸ ë„¤íŠ¸ì›Œí¬ ì˜µì…˜")
nl_timeout = st.sidebar.slider(
    "êµ­ë¦½ì¤‘ì•™ë„ì„œê´€ API íƒ€ì„ì•„ì›ƒ(ì´ˆ)",
    min_value=10,
    max_value=60,
    value=45,
    step=5,
    help="Streamlit Cloud í™˜ê²½ì—ì„œ 30ì´ˆëŠ” ì¢…ì¢… ë¶€ì¡±í•´ìš”. 45~60ì´ˆ ê¶Œì¥.",
)
nl_retries = st.sidebar.slider(
    "ì¬ì‹œë„ íšŸìˆ˜",
    min_value=0,
    max_value=3,
    value=2,
    step=1,
    help="ReadTimeout ë°œìƒ ì‹œ ì¬ì‹œë„í•©ë‹ˆë‹¤. (ì§€ìˆ˜ ë°±ì˜¤í”„ ì ìš©)",
)

# =====================================================
# App Header
# =====================================================
st.title("ğŸ“š ë‚˜ì™€ ì–´ìš¸ë¦¬ëŠ” ì±…ì€?")
st.write(
    "7ë¬¸í•­ ì‹¬ë¦¬í…ŒìŠ¤íŠ¸ë¡œ **ì„±í–¥(ì¥ë¥´ ì·¨í–¥)**ê³¼ **í˜„ì¬ ìƒí™©(ë¬´ì—‡ì´ í•„ìš”í•œì§€)**ì„ í•¨ê»˜ íŒŒì•…í•´ "
    "ë‹¹ì‹ ì—ê²Œ ë§ëŠ” ì±… 3ê¶Œì„ ì¶”ì²œí•´ë“œë¦½ë‹ˆë‹¤.\n\n"
    "- êµ­ë¦½ì¤‘ì•™ë„ì„œê´€ API í‚¤ê°€ ìˆìœ¼ë©´: **í‘œì§€/ISBN/ì†Œê°œ**ê¹Œì§€ ì‹¤ì œ ë°ì´í„°ë¡œ í‘œì‹œ\n"
    "- APIê°€ ëŠë¦¬ê±°ë‚˜ ì‹¤íŒ¨í•˜ë©´: **ì¶”ì²œ/ì´ìœ ëŠ” ë¨¼ì €**, ì„œì§€ì •ë³´ëŠ” ê°€ëŠ¥í•œ ê²ƒë§Œ í‘œì‹œ"
)

# =====================================================
# Questionnaire (ì„±í–¥ + ìƒí™©) - 7ê°œ ìœ ì§€
# =====================================================
questions = [
    "1) ìƒˆë¡œìš´ ì±…ì„ ê³ ë¥¼ ë•Œ ê°€ì¥ ëŒë¦¬ëŠ” ìš”ì†ŒëŠ”?",
    "2) ì¹œêµ¬ê°€ ì±… ì¶”ì²œì„ ë¶€íƒí•˜ë©´ ë‚˜ëŠ” ë³´í†µâ€¦",
    "3) ë‚´ê°€ ì±…ì„ ì½ì„ ë•Œ ê°€ì¥ ë§Œì¡±ìŠ¤ëŸ¬ìš´ ìˆœê°„ì€?",
    "4) í‰ì†Œ ë‚´ê°€ ê°€ì¥ ìì£¼ ê´€ì‹¬ì„ ê°–ëŠ” ì£¼ì œëŠ”?",
    "5) ìš”ì¦˜ ë‚˜ì—ê²Œ ê°€ì¥ í•„ìš”í•œ ê²ƒì€?",
    "6) ìµœê·¼ ë‚´ê°€ ì±…ì„ ì°¾ê²Œ ë˜ëŠ” ì´ìœ ëŠ”?",
    "7) ì§€ê¸ˆ ë‹¹ì¥ ì±…ì´ ë‚´ê²Œ í•´ì¤¬ìœ¼ë©´ í•˜ëŠ” ì—­í• ì€?",
]

question_choices = [
    [
        "A. ì½ê³  ë‚˜ì„œ ë°”ë¡œ ì‹¤ì²œí•  ìˆ˜ ìˆëŠ” ì¡°ì–¸",
        "B. ì‚¶ì— ëŒ€í•œ ê¹Šì€ ì§ˆë¬¸ê³¼ í†µì°°",
        "C. ìƒˆë¡œìš´ ì§€ì‹ê³¼ ê¸°ìˆ ì„ ë°°ìš°ëŠ” ì¬ë¯¸",
        "D. ì‚¬íšŒì™€ ì‹œëŒ€ë¥¼ ì´í•´í•˜ëŠ” ê´€ì ",
        "E. ê°ì •ì ìœ¼ë¡œ ëª°ì…í•  ìˆ˜ ìˆëŠ” ì´ì•¼ê¸°",
    ],
    [
        "A. ë„ì›€ì´ ë  ë§Œí•œ í˜„ì‹¤ì ì¸ ì±…ì„ ì¶”ì²œí•œë‹¤",
        "B. ìƒê°ì„ ë„“í˜€ì¤„ ì±…ì„ ì¶”ì²œí•œë‹¤",
        "C. ì‹ ê¸°í•œ ì •ë³´ë¥¼ ì£¼ëŠ” ì±…ì„ ì¶”ì²œí•œë‹¤",
        "D. ì„¸ìƒì„ ì´í•´í•˜ê²Œ í•´ì£¼ëŠ” ì±…ì„ ì¶”ì²œí•œë‹¤",
        "E. ì¬ë¯¸ìˆê²Œ ì½íˆëŠ” ì±…ì„ ì¶”ì²œí•œë‹¤",
    ],
    [
        "A. â€œì´ê±´ ë‚´ ì‚¶ì— ë°”ë¡œ ì ìš©í•  ìˆ˜ ìˆê² ë‹¤â€ ëŠë‚„ ë•Œ",
        "B. â€œì„¸ìƒì„ ë³´ëŠ” ì‹œì•¼ê°€ ë„“ì–´ì¡Œë‹¤â€ ëŠë‚„ ë•Œ",
        "C. â€œìƒˆë¡œìš´ ì‚¬ì‹¤ì„ ë°°ì› ë‹¤â€ ëŠë‚„ ë•Œ",
        "D. â€œì‚¬íšŒë‚˜ ì—­ì‚¬ë¥¼ ì´í•´í•˜ê²Œ ëë‹¤â€ ëŠë‚„ ë•Œ",
        "E. â€œì™„ì „íˆ ëª°ì…í•´ì„œ ê°ì •ì´ ì›€ì§ì˜€ë‹¤â€ ëŠë‚„ ë•Œ",
    ],
    [
        "A. ì„±ì¥, ëª©í‘œ, ìê¸°ê´€ë¦¬",
        "B. ì¸ê°„ê´€ê³„, ì‚¶ì˜ ì˜ë¯¸",
        "C. ë¯¸ë˜ê¸°ìˆ , ê³¼í•™, ë°ì´í„°",
        "D. ì‚¬íšŒë¬¸ì œ, ì—­ì‚¬ì  ì‚¬ê±´",
        "E. ê°ì •, ì´ì•¼ê¸°, ìƒìƒ ì† ì„¸ê³„",
    ],
    [
        "A. ë‹¤ì‹œ ë™ê¸°ë¶€ì—¬í•˜ê³  ë°©í–¥ì„ ì¡ëŠ” ê²ƒ",
        "B. ë‚´ ë§ˆìŒì„ ì •ë¦¬í•  ìˆ˜ ìˆëŠ” í†µì°°",
        "C. ë¨¸ë¦¬ë¥¼ ìê·¹í•˜ëŠ” ìƒˆë¡œìš´ í˜¸ê¸°ì‹¬",
        "D. í˜„ì‹¤ì„ ì´í•´í•˜ê³  ì‹œì•¼ë¥¼ ë„“íˆëŠ” ê´€ì ",
        "E. ìœ„ë¡œë°›ê³  ê°ì •ì„ ì‰¬ê²Œ í•˜ëŠ” ì´ì•¼ê¸°",
    ],
    [
        "A. ë¯¸ë˜ ì¤€ë¹„ë‚˜ ìê¸°ê³„ë°œì´ í•„ìš”í•´ì„œ",
        "B. ë³µì¡í•œ ê°ì •ì„ ì •ë¦¬í•˜ê³  ì‹¶ì–´ì„œ",
        "C. ìƒˆë¡œìš´ ë¶„ì•¼ë¥¼ ë°°ìš°ê³  ì‹¶ì–´ì„œ",
        "D. ì‚¬íšŒì™€ ì„¸ìƒ íë¦„ì´ ê¶ê¸ˆí•´ì„œ",
        "E. ì§€ì¹˜ê³  ì‰¬ê³  ì‹¶ì–´ì„œ",
    ],
    [
        "A. â€œì•ìœ¼ë¡œ ë­˜ í•´ì•¼ í• ì§€ ì•Œë ¤ì£¼ëŠ” ë‚˜ì¹¨ë°˜â€",
        "B. â€œìƒê°ì„ ì •ë¦¬í•´ì£¼ëŠ” ëŒ€í™” ìƒëŒ€â€",
        "C. â€œìƒˆë¡œìš´ ì„¸ìƒì„ ë³´ì—¬ì£¼ëŠ” ì°½ë¬¸â€",
        "D. â€œí˜„ì‹¤ì„ ì´í•´í•˜ê²Œ í•´ì£¼ëŠ” ì§€ë„â€",
        "E. â€œë§ˆìŒì„ ì‰¬ê²Œ í•´ì£¼ëŠ” íœ´ì‹ì²˜â€",
    ],
]

# =====================================================
# Mappings
# =====================================================
genre_map = {"A": "ìê¸°ê³„ë°œ", "B": "ì¸ë¬¸/ì² í•™", "C": "ê³¼í•™/IT", "D": "ì—­ì‚¬/ì‚¬íšŒ", "E": "ì†Œì„¤"}

genre_persona = {
    "ìê¸°ê³„ë°œ": "ì‹¤í–‰Â·ë£¨í‹´Â·ì„±ê³¼ë¥¼ ì¤‘ì‹œí•˜ëŠ” ì„±ì¥í˜•",
    "ì¸ë¬¸/ì² í•™": "ì˜ë¯¸Â·ê°€ì¹˜Â·ìê¸°ì´í•´ë¥¼ ê¹Šê²Œ íŒŒê³ ë“œëŠ” ì„±ì°°í˜•",
    "ê³¼í•™/IT": "ì›ë¦¬Â·êµ¬ì¡°Â·ì •ë³´ë¥¼ ë¶„ì„í•˜ëŠ” íƒêµ¬í˜•",
    "ì—­ì‚¬/ì‚¬íšŒ": "ì‚¬íšŒ êµ¬ì¡°Â·ë§¥ë½Â·íë¦„ì„ ì´í•´í•˜ë ¤ëŠ” ê´€ì°°í˜•",
    "ì†Œì„¤": "ê°ì •Â·ë¶„ìœ„ê¸°Â·ì„œì‚¬ ëª°ì…ì„ í†µí•´ íšŒë³µí•˜ëŠ” ê°ì„±í˜•",
}

genre_book_point = {
    "ìê¸°ê³„ë°œ": "ë°”ë¡œ ì ìš© ê°€ëŠ¥í•œ ìŠµê´€Â·ì‹¤í–‰ í¬ì¸íŠ¸",
    "ì¸ë¬¸/ì² í•™": "ê°ì •ê³¼ ìƒê°ì„ ì •ë¦¬í•´ì£¼ëŠ” í†µì°°",
    "ê³¼í•™/IT": "ìƒˆë¡œìš´ ì§€ì‹ê³¼ ì›ë¦¬ë¥¼ ì´í•´í•˜ëŠ” ì¬ë¯¸",
    "ì—­ì‚¬/ì‚¬íšŒ": "ì„¸ìƒ íë¦„ì„ ì½ê³  ê´€ì ì„ ë„“íˆëŠ” ë‚´ìš©",
    "ì†Œì„¤": "ê°ì •ì ìœ¼ë¡œ ëª°ì…í•˜ë©° ìœ„ë¡œì™€ ì—¬ìš´ì„ ì£¼ëŠ” ì„œì‚¬",
}

situation_tag_map_q5_to_q7 = {
    5: {"A": ["ë™ê¸°"], "B": ["ìœ„ë¡œ"], "C": ["íƒêµ¬"], "D": ["íƒêµ¬"], "E": ["ìœ„ë¡œ", "íœ´ì‹"]},
    6: {"A": ["ë™ê¸°"], "B": ["ìœ„ë¡œ"], "C": ["íƒêµ¬"], "D": ["íƒêµ¬"], "E": ["íœ´ì‹", "ìœ„ë¡œ"]},
    7: {"A": ["ë™ê¸°"], "B": ["ìœ„ë¡œ"], "C": ["íƒêµ¬"], "D": ["íƒêµ¬"], "E": ["íœ´ì‹", "ìœ„ë¡œ"]},
}

tag_display = {"ë™ê¸°": "ë°©í–¥/ë™ê¸°ë¶€ì—¬", "ìœ„ë¡œ": "ê°ì • ì •ë¦¬/ìœ„ë¡œ", "íœ´ì‹": "íœ´ì‹/íšŒë³µ", "íƒêµ¬": "í˜¸ê¸°ì‹¬/íƒêµ¬"}

# =====================================================
# Demo fallback pool
# =====================================================
fallback_pool = {
    "ìê¸°ê³„ë°œ": [
        {"title": "ì•„ì£¼ ì‘ì€ ìŠµê´€ì˜ í˜", "author": "ì œì„ìŠ¤ í´ë¦¬ì–´"},
        {"title": "ê·¸ë¦¿", "author": "ì•¤ì ˆë¼ ë”í¬ì›ŒìŠ¤"},
        {"title": "ë”¥ ì›Œí¬", "author": "ì¹¼ ë‰´í¬íŠ¸"},
        {"title": "ì›ì”½", "author": "ê²Œë¦¬ ì¼ˆëŸ¬"},
        {"title": "ë¯¸ë¼í´ ëª¨ë‹", "author": "í•  ì—˜ë¡œë“œ"},
    ],
    "ì¸ë¬¸/ì² í•™": [
        {"title": "ì •ì˜ë€ ë¬´ì—‡ì¸ê°€", "author": "ë§ˆì´í´ ìƒŒë¸"},
        {"title": "ì£½ìŒì˜ ìˆ˜ìš©ì†Œì—ì„œ", "author": "ë¹…í„° í”„ë­í´"},
        {"title": "ì†Œí¬ë¼í…ŒìŠ¤ ìµìŠ¤í”„ë ˆìŠ¤", "author": "ì—ë¦­ ì™€ì´ë„ˆ"},
        {"title": "ì² í•™ì€ ì–´ë–»ê²Œ ì‚¶ì˜ ë¬´ê¸°ê°€ ë˜ëŠ”ê°€", "author": "ì•¼ë§ˆêµ¬ì¹˜ ìŠˆ"},
        {"title": "ì‚¬í”¼ì—”ìŠ¤", "author": "ìœ ë°œ í•˜ë¼ë¦¬"},
    ],
    "ê³¼í•™/IT": [
        {"title": "ì½”ìŠ¤ëª¨ìŠ¤", "author": "ì¹¼ ì„¸ì´ê±´"},
        {"title": "íŒ©íŠ¸í’€ë‹ˆìŠ¤", "author": "í•œìŠ¤ ë¡œìŠ¬ë§"},
        {"title": "í´ë¦° ì½”ë“œ", "author": "ë¡œë²„íŠ¸ C. ë§ˆí‹´"},
        {"title": "AI 2041", "author": "ì¹´ì´í‘¸ ë¦¬, ì²œì¹˜ìš°íŒ"},
        {"title": "ì´ê¸°ì  ìœ ì „ì", "author": "ë¦¬ì²˜ë“œ ë„í‚¨ìŠ¤"},
    ],
    "ì—­ì‚¬/ì‚¬íšŒ": [
        {"title": "ì´, ê· , ì‡ ", "author": "ì¬ë ˆë“œ ë‹¤ì´ì•„ëª¬ë“œ"},
        {"title": "ë„›ì§€", "author": "ë¦¬ì²˜ë“œ íƒˆëŸ¬, ìºìŠ¤ ì„ ìŠ¤íƒ€ì¸"},
        {"title": "ì—­ì‚¬ì˜ ì“¸ëª¨", "author": "ìµœíƒœì„±"},
        {"title": "21ì„¸ê¸° ìë³¸", "author": "í† ë§ˆ í”¼ì¼€í‹°"},
        {"title": "ì •ì¹˜ì˜ ì‹¬ë¦¬í•™", "author": "ë“œë£¨ ì›¨ìŠ¤í„´"},
    ],
    "ì†Œì„¤": [
        {"title": "ë‚˜ë¯¸ì•¼ ì¡í™”ì ì˜ ê¸°ì ", "author": "íˆê°€ì‹œë…¸ ê²Œì´ê³ "},
        {"title": "ë¶ˆí¸í•œ í¸ì˜ì ", "author": "ê¹€í˜¸ì—°"},
        {"title": "1984", "author": "ì¡°ì§€ ì˜¤ì›°"},
        {"title": "ë‹¬ëŸ¬êµ¬íŠ¸ ê¿ˆ ë°±í™”ì ", "author": "ì´ë¯¸ì˜ˆ"},
        {"title": "ë°ë¯¸ì•ˆ", "author": "í—¤ë¥´ë§Œ í—¤ì„¸"},
    ],
}

# =====================================================
# Session State init
# =====================================================
if "submitted" not in st.session_state:
    st.session_state.submitted = False
if "result" not in st.session_state:
    st.session_state.result = None

for i in range(7):
    k = f"q{i+1}"
    if k not in st.session_state:
        st.session_state[k] = None


def reset_test():
    for i in range(7):
        st.session_state[f"q{i+1}"] = None
    st.session_state.submitted = False
    st.session_state.result = None


# =====================================================
# Helpers
# =====================================================
def letter_of(answer: str) -> str:
    return answer.strip()[0]


def compute_genre_scores(answers: List[str]) -> Dict[str, int]:
    scores = {g: 0 for g in genre_map.values()}
    for ans in answers:
        scores[genre_map[letter_of(ans)]] += 1
    return scores


def compute_situation_scores(answers: List[str]) -> Dict[str, int]:
    tags = {"ìœ„ë¡œ": 0, "íœ´ì‹": 0, "ë™ê¸°": 0, "íƒêµ¬": 0}
    for qno in [5, 6, 7]:
        letter = letter_of(answers[qno - 1])
        for t in situation_tag_map_q5_to_q7[qno].get(letter, []):
            tags[t] += 1
    return tags


def ranked(scores: Dict[str, int]) -> List[Tuple[str, int]]:
    return sorted(scores.items(), key=lambda x: x[1], reverse=True)


def top_keys(scores: Dict[str, int]):
    r = ranked(scores)
    max_score = r[0][1]
    top = [k for k, v in r if v == max_score]
    second_score = None
    for k, v in r:
        if v < max_score:
            second_score = v
            break
    second = [k for k, v in r if second_score is not None and v == second_score]
    return top, second, r


def pick_3_books(primary_genres, secondary_genres):
    if len(primary_genres) >= 2:
        pool = []
        for g in primary_genres:
            pool += [{"genre": g, **b} for b in fallback_pool[g]]
        random.shuffle(pool)
        books, seen = [], set()
        for item in pool:
            if item["title"] in seen:
                continue
            books.append(item)
            seen.add(item["title"])
            if len(books) == 3:
                break
        return books

    primary = primary_genres[0]
    if secondary_genres:
        secondary = secondary_genres[0]
        p = random.sample(fallback_pool[primary], k=min(2, len(fallback_pool[primary])))
        s = random.sample(fallback_pool[secondary], k=1)
        books = [{"genre": primary, **b} for b in p] + [{"genre": secondary, **b} for b in s]
        random.shuffle(books)
        return books[:3]

    return [{"genre": primary, **b} for b in random.sample(fallback_pool[primary], k=3)]


def evidence_by_genre(answers, target_genre, max_evidence=2):
    target_letter = next((l for l, g in genre_map.items() if g == target_genre), None)
    matched = [a for a in answers if target_letter and letter_of(a) == target_letter]
    cleaned = [m[3:].strip() if len(m) > 3 else m.strip() for m in matched]
    random.shuffle(cleaned)
    return cleaned[:max_evidence]


def evidence_by_situation(answers, top_situation_tags, max_evidence=1):
    evidences = []
    for qno in [5, 6, 7]:
        ans = answers[qno - 1]
        letter = letter_of(ans)
        tags = situation_tag_map_q5_to_q7[qno].get(letter, [])
        if any(t in top_situation_tags for t in tags):
            evidences.append(ans[3:].strip() if len(ans) > 3 else ans.strip())
    random.shuffle(evidences)
    return evidences[:max_evidence]


def build_reason(answers, book_title, book_genre, top_situation_tags):
    genre_ev = evidence_by_genre(answers, book_genre, max_evidence=2)
    situa_ev = evidence_by_situation(answers, top_situation_tags, max_evidence=1)

    persona = genre_persona.get(book_genre, "")
    point = genre_book_point.get(book_genre, "")
    situa_phrase = ", ".join([tag_display.get(t, t) for t in top_situation_tags])

    parts = []
    if situa_ev:
        parts.append(f"ë‹¹ì‹ ì€ ìµœê·¼ â€œ{situa_ev[0]}â€ë¼ê³  ë‹µí•´ **{situa_phrase}**ê°€ í•„ìš”í•œ ìƒíƒœë¡œ ë³´ì—¬ìš”.")
    else:
        parts.append(f"ì§€ê¸ˆì€ **{situa_phrase}**ì— ë„ì›€ì´ ë˜ëŠ” ì±…ì´ ì˜ ë§ëŠ” ì‹œì ì´ì—ìš”.")

    if genre_ev:
        if len(genre_ev) >= 2:
            parts.append(f"ë˜ â€œ{genre_ev[0]}â€, â€œ{genre_ev[1]}â€ë¥¼ ê³ ë¥¸ ê±¸ ë³´ë©´ {persona} ì„±í–¥ë„ ê°•í•´ìš”.")
        else:
            parts.append(f"ë˜ â€œ{genre_ev[0]}â€ë¥¼ ì„ íƒí•œ ê±¸ ë³´ë©´ {persona} ì„±í–¥ë„ ê°•í•´ìš”.")
    else:
        parts.append(f"{persona} ì„±í–¥ì„ ë°”íƒ•ìœ¼ë¡œ ì±…ì„ ê³¨ëì–´ìš”.")

    parts.append(f"ê·¸ë˜ì„œ {point}ë¥¼ ì–»ê¸° ì¢‹ì€ **{book_title}**ì„(ë¥¼) ì¶”ì²œí•©ë‹ˆë‹¤.")
    return " ".join(parts)


# =====================================================
# Robust HTTP utilities (timeout/retry/backoff)
# =====================================================
def requests_get_with_retry(
    url: str,
    params: Optional[dict] = None,
    timeout: int = 45,
    retries: int = 2,
    backoff_base: float = 0.8,
    headers: Optional[dict] = None,
) -> requests.Response:
    """
    ReadTimeout/ConnectionError ë“± ë„¤íŠ¸ì›Œí¬ ì´ìŠˆì— ëŒ€í•´ ì¬ì‹œë„(ì§€ìˆ˜ ë°±ì˜¤í”„).
    Streamlit Cloudì—ì„œ ê°„í—ì ìœ¼ë¡œ ë°œìƒí•˜ëŠ” ReadTimeout ì™„í™”.
    """
    last_err: Optional[Exception] = None
    for attempt in range(retries + 1):
        try:
            return requests.get(url, params=params, headers=headers, timeout=timeout)
        except (ReadTimeout, ConnectionError) as e:
            last_err = e
            if attempt == retries:
                raise
            sleep_s = backoff_base * (2 ** attempt) + random.uniform(0, 0.2)
            time.sleep(sleep_s)
        except RequestException as e:
            # ê¸°íƒ€ requests ì˜ˆì™¸ëŠ” ê·¸ëŒ€ë¡œ ì˜¬ë¦¬ë˜, í•œ ë²ˆ ì •ë„ëŠ” ì¬ì‹œë„í•´ë³¼ ìˆ˜ë„ ìˆìŒ
            last_err = e
            if attempt == retries:
                raise
            sleep_s = backoff_base * (2 ** attempt) + random.uniform(0, 0.2)
            time.sleep(sleep_s)
    # ì´ ë¼ì¸ì—” ë³´í†µ ë„ë‹¬í•˜ì§€ ì•ŠìŒ
    raise last_err if last_err else RuntimeError("Unknown network error")


# =====================================================
# National Library API calls (with retry)
# =====================================================
@st.cache_data(show_spinner=False)
def nl_isbn_search(cert_key: str, title: str, author: str = "", page_size: int = 10, timeout: int = 45, retries: int = 2):
    url = "https://www.nl.go.kr/seoji/SearchApi.do"
    params = {
        "cert_key": cert_key,
        "result_style": "json",
        "page_no": 1,
        "page_size": page_size,
        "title": title,
    }
    if author:
        params["author"] = author

    r = requests_get_with_retry(url, params=params, timeout=timeout, retries=retries)
    r.raise_for_status()

    try:
        return r.json()
    except Exception:
        return json.loads(r.text)


def pick_best_item(nl_json, wanted_title: str):
    items = None
    if isinstance(nl_json, dict):
        for k in ["docs", "data", "items", "result"]:
            if k in nl_json and isinstance(nl_json[k], list):
                items = nl_json[k]
                break
        if items is None:
            for v in nl_json.values():
                if isinstance(v, list) and v and isinstance(v[0], dict):
                    items = v
                    break

    if not items:
        return None

    wt = wanted_title.replace(" ", "").lower()

    def score(item):
        t = str(item.get("TITLE", "") or item.get("title", "")).replace(" ", "").lower()
        if not t:
            return 0
        if t == wt:
            return 100
        if wt in t or t in wt:
            return 60
        return 10 if t[:5] == wt[:5] else 1

    return sorted(items, key=score, reverse=True)[0]


@st.cache_data(show_spinner=False)
def fetch_text_from_url(url: str, max_chars: int = 700, timeout: int = 30, retries: int = 1) -> str:
    if not url:
        return ""
    try:
        r = requests_get_with_retry(url, params=None, timeout=timeout, retries=retries)
        r.raise_for_status()
        text = r.text

        text = re.sub(r"<script.*?>.*?</script>", " ", text, flags=re.DOTALL | re.IGNORECASE)
        text = re.sub(r"<style.*?>.*?</style>", " ", text, flags=re.DOTALL | re.IGNORECASE)
        text = re.sub(r"<[^>]+>", " ", text)
        text = unescape(text)
        text = re.sub(r"\s+", " ", text).strip()

        if len(text) > max_chars:
            text = text[:max_chars].rstrip() + "â€¦"
        return text
    except RequestException:
        return ""


# =====================================================
# UI: Questionnaire
# =====================================================
st.divider()
st.subheader("ğŸ“ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”")

for i, q in enumerate(questions):
    st.markdown(f"**{q}**")
    st.radio(
        label=f"q{i+1}",
        options=question_choices[i],
        key=f"q{i+1}",
        index=None,
        label_visibility="collapsed",
    )
    st.write("")

st.divider()
c1, c2 = st.columns(2)
with c1:
    clicked = st.button("ê²°ê³¼ ë³´ê¸°", type="primary")
with c2:
    st.button("ë‹¤ì‹œ í…ŒìŠ¤íŠ¸í•˜ê¸°", on_click=reset_test)

# =====================================================
# Flow
# =====================================================
if clicked:
    answers = [st.session_state[f"q{i+1}"] for i in range(7)]
    if any(a is None for a in answers):
        missing = [str(i + 1) for i, a in enumerate(answers) if a is None]
        st.warning(f"ëª¨ë“  ì§ˆë¬¸ì— ë‹µë³€í•´ ì£¼ì„¸ìš”! (ë¯¸ì‘ë‹µ: {', '.join(missing)}ë²ˆ)")
    else:
        with st.spinner("ë¶„ì„ ì¤‘..."):
            # ì„±í–¥/ìƒí™© ë¶„ì„
            genre_scores = compute_genre_scores(answers)
            top_genres, second_genres, genre_ranked = top_keys(genre_scores)

            situation_scores = compute_situation_scores(answers)
            top_situations, _, situation_ranked = top_keys(situation_scores)

            # ì±… í›„ë³´(ë°ëª¨) 3ê¶Œ
            candidates = pick_3_books(top_genres, second_genres)
            candidates = [{"title": b["title"], "author": b.get("author", ""), "genre": b["genre"]} for b in candidates]

            # ê°œì¸í™” ì¶”ì²œ ì´ìœ  ìƒì„±
            enriched = []
            for c in candidates[:3]:
                why = build_reason(answers, c["title"], c["genre"], top_situations)
                enriched.append({**c, "why": why})

            # êµ­ë¦½ì¤‘ì•™ë„ì„œê´€ APIë¡œ ì‹¤ì œ ì •ë³´ ì¡°íšŒ(ê°€ëŠ¥í•˜ë©´)
            books_final = []
            used_nl = False
            if nl_api_key:
                used_nl = True
                for c in enriched:
                    try:
                        nl_json = nl_isbn_search(
                            nl_api_key,
                            title=c["title"],
                            author=c.get("author", ""),
                            page_size=10,
                            timeout=nl_timeout,
                            retries=nl_retries,
                        )
                        item = pick_best_item(nl_json, wanted_title=c["title"])

                        if not item:
                            books_final.append(
                                {**c, "isbn": "", "cover_url": "", "summary": "", "note": "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì–´ì„œ ì„œì§€ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆì–´ìš”."}
                            )
                            continue

                        picked_title = item.get("TITLE") or item.get("title") or c["title"]
                        picked_author = item.get("AUTHOR") or item.get("author") or c.get("author", "")
                        isbn = item.get("EA_ISBN") or item.get("ISBN") or item.get("isbn") or ""

                        cover_url = item.get("TITLE_URL") or item.get("cover") or item.get("image") or ""
                        intro_url = item.get("BOOK_INTRODUCTION_URL") or ""
                        summary_url = item.get("BOOK_SUMMARY_URL") or ""

                        summary_text = fetch_text_from_url(summary_url, timeout=nl_timeout, retries=1)
                        if not summary_text:
                            summary_text = fetch_text_from_url(intro_url, timeout=nl_timeout, retries=1)

                        books_final.append(
                            {
                                **c,
                                "title": str(picked_title).strip(),
                                "author": str(picked_author).strip(),
                                "isbn": str(isbn).strip(),
                                "cover_url": str(cover_url).strip(),
                                "summary": summary_text.strip(),
                                "note": "",
                            }
                        )

                    except ReadTimeout:
                        # âœ… í•µì‹¬: íƒ€ì„ì•„ì›ƒ ë‚˜ë„ ì•±ì´ ì£½ì§€ ì•Šê²Œ ì²˜ë¦¬
                        if demo_mode:
                            books_final.append(
                                {
                                    **c,
                                    "isbn": "",
                                    "cover_url": "",
                                    "summary": "",
                                    "note": "êµ­ë¦½ì¤‘ì•™ë„ì„œê´€ API ì‘ë‹µì´ ì§€ì—°ë˜ì–´(Timeout) ì„œì§€ì •ë³´ë¥¼ ìƒëµí–ˆì–´ìš”. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”.",
                                }
                            )
                        else:
                            raise
                    except (HTTPError, ConnectionError, RequestException):
                        if demo_mode:
                            books_final.append(
                                {
                                    **c,
                                    "isbn": "",
                                    "cover_url": "",
                                    "summary": "",
                                    "note": "êµ­ë¦½ì¤‘ì•™ë„ì„œê´€ API í˜¸ì¶œì— ì‹¤íŒ¨í•˜ì—¬ ì„œì§€ì •ë³´ë¥¼ ìƒëµí–ˆì–´ìš”. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”.",
                                }
                            )
                        else:
                            raise
            else:
                # í‚¤ê°€ ì—†ìœ¼ë©´(ë°ëª¨ ëª¨ë“œë“  ì•„ë‹ˆë“ ) ì¶”ì²œ/ì´ìœ ê¹Œì§€ë§Œ
                for c in enriched:
                    books_final.append({**c, "isbn": "", "cover_url": "", "summary": "", "note": ""})

            st.session_state.submitted = True
            st.session_state.result = {
                "genre_scores": genre_scores,
                "genre_top": top_genres,
                "genre_ranked": genre_ranked,
                "situation_scores": situation_scores,
                "situation_top": top_situations,
                "situation_ranked": situation_ranked,
                "books": books_final,
                "used_nl": used_nl,
            }

# =====================================================
# Render Result
# =====================================================
if st.session_state.submitted and st.session_state.result:
    r = st.session_state.result

    st.subheader("ğŸ“Œ ë¶„ì„ ê²°ê³¼")

    if len(r["genre_top"]) >= 2:
        st.success(f"ë‹¹ì‹ ì˜ **ë…ì„œ ì„±í–¥(ë³µí•©)**: {', '.join(r['genre_top'])}")
    else:
        st.success(f"ë‹¹ì‹ ì˜ **ë…ì„œ ì„±í–¥**: {r['genre_top'][0]}")

    sit_text = ", ".join([tag_display.get(t, t) for t in r["situation_top"]])
    st.info(f"í˜„ì¬ ë‹¹ì‹ ì—ê²Œ ê°€ì¥ í•„ìš”í•œ ê²ƒ: **{sit_text}**")

    st.caption("ì¥ë¥´ ì ìˆ˜: " + ", ".join([f"{k} {v}" for k, v in r["genre_scores"].items()]))
    st.caption("ìƒí™© ì ìˆ˜: " + ", ".join([f"{tag_display.get(k,k)} {v}" for k, v in r["situation_scores"].items()]))

    if r["used_nl"]:
        st.caption("â€» êµ­ë¦½ì¤‘ì•™ë„ì„œê´€ APIëŠ” íŠ¸ë˜í”½/ë„¤íŠ¸ì›Œí¬ ìƒíƒœì— ë”°ë¼ ì‘ë‹µì´ ì§€ì—°ë  ìˆ˜ ìˆì–´ìš”. (íƒ€ì„ì•„ì›ƒ ì‹œ ìë™ìœ¼ë¡œ ì¼ë¶€ ìƒëµ)")
    else:
        st.warning("êµ­ë¦½ì¤‘ì•™ë„ì„œê´€ API í‚¤ê°€ ì—†ì–´ì„œ **í‘œì§€/ISBN/ì¤„ê±°ë¦¬**ëŠ” í‘œì‹œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. (ì¶”ì²œ/ì´ìœ ëŠ” ì •ìƒ í‘œì‹œ)")

    st.subheader("ğŸ“š ì¶”ì²œ ë„ì„œ 3ê¶Œ")
    for idx, b in enumerate(r["books"], start=1):
        st.markdown(f"### {idx}. {b['title']}")
        meta = []
        if b.get("author"):
            meta.append(f"ì €ì: {b['author']}")
        if b.get("isbn"):
            meta.append(f"ISBN: {b['isbn']}")
        if meta:
            st.caption(" Â· ".join(meta))

        cols = st.columns([1, 2])
        with cols[0]:
            if b.get("cover_url"):
                st.image(b["cover_url"], use_container_width=True)
            else:
                st.info("í‘œì§€ ì´ë¯¸ì§€ ì—†ìŒ(ë°ëª¨/ê²€ìƒ‰ ì‹¤íŒ¨/Timeout)")

        with cols[1]:
            st.write("**ì´ ì±…ì„ ì¶”ì²œí•˜ëŠ” ì´ìœ (ì„¤ë¬¸ ê·¼ê±° + ìƒí™© ê¸°ë°˜)**")
            st.write(f"- {b.get('why','')}")

            st.write("**ì¤„ê±°ë¦¬/ì±…ì†Œê°œ**")
            if b.get("summary"):
                st.write(b["summary"])
            else:
                st.info("ì¤„ê±°ë¦¬/ì±…ì†Œê°œ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆì–´ìš”. (ì œê³µ URL ì—†ìŒ/Timeout)")

            if b.get("note"):
                st.warning(b["note"])

        st.divider()
