import json
import random
import re
import time
from html import unescape
from typing import Dict, List, Tuple, Optional

import requests
import streamlit as st
from requests.exceptions import ReadTimeout, ConnectionError, HTTPError, RequestException
from concurrent.futures import ThreadPoolExecutor, as_completed

# =====================================================
# Streamlit Setup
# =====================================================
st.set_page_config(page_title="ë‚˜ì™€ ì–´ìš¸ë¦¬ëŠ” ì±…ì€?", page_icon="ğŸ“š", layout="centered")


# =====================================================
# Sidebar
# =====================================================
st.sidebar.header("ğŸ”‘ API ì„¤ì •")

nl_api_key = st.sidebar.text_input(
    "êµ­ë¦½ì¤‘ì•™ë„ì„œê´€(ISBN ì„œì§€ì •ë³´) API Key (cert_key)",
    type="password",
    help="êµ­ë¦½ì¤‘ì•™ë„ì„œê´€ ISBN ì„œì§€ì •ë³´ APIì˜ cert_key",
)

openai_api_key = st.sidebar.text_input(
    "OpenAI API Key (ì„ íƒ)",
    type="password",
    help="ì…ë ¥í•˜ë©´ 'í›„ë³´ ë¦¬ìŠ¤íŠ¸ ì¤‘ì—ì„œ' AIê°€ 3ê¶Œì„ ì„ íƒí•©ë‹ˆë‹¤. ì—†ìœ¼ë©´ ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ ê³ ë¦…ë‹ˆë‹¤.",
)
openai_model = st.sidebar.text_input("OpenAI ëª¨ë¸", value="gpt-4o-mini")

st.sidebar.subheader("âš¡ ì†ë„ ì˜µì…˜")
pool_size = st.sidebar.slider("í›„ë³´ í’€(ê°€ì ¸ì˜¬ ì±… ê°œìˆ˜)", 20, 120, 60, 10)
nl_timeout = st.sidebar.slider("êµ­ë¦½ì¤‘ì•™ë„ì„œê´€ API íƒ€ì„ì•„ì›ƒ(ì´ˆ)", 5, 30, 10, 1)
nl_retries = st.sidebar.slider("êµ­ë¦½ì¤‘ì•™ë„ì„œê´€ API ì¬ì‹œë„ íšŸìˆ˜", 0, 2, 1, 1)

fetch_summary_default = st.sidebar.checkbox(
    "ì¤„ê±°ë¦¬/ì±…ì†Œê°œë„ ë°”ë¡œ ê°€ì ¸ì˜¤ê¸°(ëŠë¦¼)",
    value=False,
    help="OFF ê¶Œì¥: ê¸°ë³¸ì€ í‘œì§€/ISBNë§Œ ë¹ ë¥´ê²Œ í‘œì‹œ. ì¤„ê±°ë¦¬ëŠ” ë²„íŠ¼ìœ¼ë¡œ ì§€ì—° ë¡œë”©.",
)

st.sidebar.subheader("ğŸ§ª ë””ë²„ê·¸")
debug_show_raw = st.sidebar.checkbox("í›„ë³´ 1ê°œ raw JSON ë³´ê¸°", value=False)

# =====================================================
# Header
# =====================================================
st.title("ğŸ“š ë‚˜ì™€ ì–´ìš¸ë¦¬ëŠ” ì±…ì€?")
st.write("ì„±í–¥(ì¥ë¥´) + ìƒí™©(ì§€ê¸ˆ í•„ìš”í•œ ê²ƒ)ì„ ë¶„ì„í•˜ê³ , **êµ­ë¦½ì¤‘ì•™ë„ì„œê´€ í›„ë³´ ë¦¬ìŠ¤íŠ¸ ì¤‘ì—ì„œ** 3ê¶Œì„ ê³¨ë¼ ì¶”ì²œí•©ë‹ˆë‹¤.")


# =====================================================
# Questions
# =====================================================
questions = [
    "1) ìƒˆë¡œìš´ ì±…ì„ ê³ ë¥¼ ë•Œ ê°€ì¥ ëŒë¦¬ëŠ” ìš”ì†ŒëŠ”?",
    "2) ì¹œêµ¬ê°€ ì±… ì¶”ì²œì„ ë¶€íƒí•˜ë©´ ë‚˜ëŠ” ë³´í†µâ€¦",
    "3) ë‚´ê°€ ì±…ì„ ì½ì„ ë•Œ ê°€ì¥ ë§Œì¡±ìŠ¤ëŸ¬ìš´ ìˆœê°„ì€?",
    "4) í‰ì†Œ ë‚´ê°€ ê°€ì¥ ìì£¼ ê´€ì‹¬ì„ ê°–ëŠ” ì£¼ì œëŠ”?",
    "5) ìš”ì¦˜ ë‚˜ì—ê²Œ ê°€ì¥ í•„ìš”í•œ ê²ƒì€?",
    "6) ìµœê·¼ ë‚´ê°€ ì±…ì„ ì°¾ê²Œ ë˜ëŠ” ì´ìœ ëŠ”?",
    "7) ì§€ê¸ˆ ë‹¹ì¥ ì±…ì´ ë‚´ê²Œ í•´ì¤¬ìœ¼ë©´ í•˜ëŠ” ì—­í• ì€?",
]

question_choices = [
    ["A. ì½ê³  ë‚˜ì„œ ë°”ë¡œ ì‹¤ì²œí•  ìˆ˜ ìˆëŠ” ì¡°ì–¸","B. ì‚¶ì— ëŒ€í•œ ê¹Šì€ ì§ˆë¬¸ê³¼ í†µì°°","C. ìƒˆë¡œìš´ ì§€ì‹ê³¼ ê¸°ìˆ ì„ ë°°ìš°ëŠ” ì¬ë¯¸","D. ì‚¬íšŒì™€ ì‹œëŒ€ë¥¼ ì´í•´í•˜ëŠ” ê´€ì ","E. ê°ì •ì ìœ¼ë¡œ ëª°ì…í•  ìˆ˜ ìˆëŠ” ì´ì•¼ê¸°"],
    ["A. ë„ì›€ì´ ë  ë§Œí•œ í˜„ì‹¤ì ì¸ ì±…ì„ ì¶”ì²œí•œë‹¤","B. ìƒê°ì„ ë„“í˜€ì¤„ ì±…ì„ ì¶”ì²œí•œë‹¤","C. ì‹ ê¸°í•œ ì •ë³´ë¥¼ ì£¼ëŠ” ì±…ì„ ì¶”ì²œí•œë‹¤","D. ì„¸ìƒì„ ì´í•´í•˜ê²Œ í•´ì£¼ëŠ” ì±…ì„ ì¶”ì²œí•œë‹¤","E. ì¬ë¯¸ìˆê²Œ ì½íˆëŠ” ì±…ì„ ì¶”ì²œí•œë‹¤"],
    ["A. â€œì´ê±´ ë‚´ ì‚¶ì— ë°”ë¡œ ì ìš©í•  ìˆ˜ ìˆê² ë‹¤â€ ëŠë‚„ ë•Œ","B. â€œì„¸ìƒì„ ë³´ëŠ” ì‹œì•¼ê°€ ë„“ì–´ì¡Œë‹¤â€ ëŠë‚„ ë•Œ","C. â€œìƒˆë¡œìš´ ì‚¬ì‹¤ì„ ë°°ì› ë‹¤â€ ëŠë‚„ ë•Œ","D. â€œì‚¬íšŒë‚˜ ì—­ì‚¬ë¥¼ ì´í•´í•˜ê²Œ ëë‹¤â€ ëŠë‚„ ë•Œ","E. â€œì™„ì „íˆ ëª°ì…í•´ì„œ ê°ì •ì´ ì›€ì§ì˜€ë‹¤â€ ëŠë‚„ ë•Œ"],
    ["A. ì„±ì¥, ëª©í‘œ, ìê¸°ê´€ë¦¬","B. ì¸ê°„ê´€ê³„, ì‚¶ì˜ ì˜ë¯¸","C. ë¯¸ë˜ê¸°ìˆ , ê³¼í•™, ë°ì´í„°","D. ì‚¬íšŒë¬¸ì œ, ì—­ì‚¬ì  ì‚¬ê±´","E. ê°ì •, ì´ì•¼ê¸°, ìƒìƒ ì† ì„¸ê³„"],
    ["A. ë‹¤ì‹œ ë™ê¸°ë¶€ì—¬í•˜ê³  ë°©í–¥ì„ ì¡ëŠ” ê²ƒ","B. ë‚´ ë§ˆìŒì„ ì •ë¦¬í•  ìˆ˜ ìˆëŠ” í†µì°°","C. ë¨¸ë¦¬ë¥¼ ìê·¹í•˜ëŠ” ìƒˆë¡œìš´ í˜¸ê¸°ì‹¬","D. í˜„ì‹¤ì„ ì´í•´í•˜ê³  ì‹œì•¼ë¥¼ ë„“íˆëŠ” ê´€ì ","E. ìœ„ë¡œë°›ê³  ê°ì •ì„ ì‰¬ê²Œ í•˜ëŠ” ì´ì•¼ê¸°"],
    ["A. ë¯¸ë˜ ì¤€ë¹„ë‚˜ ìê¸°ê³„ë°œì´ í•„ìš”í•´ì„œ","B. ë³µì¡í•œ ê°ì •ì„ ì •ë¦¬í•˜ê³  ì‹¶ì–´ì„œ","C. ìƒˆë¡œìš´ ë¶„ì•¼ë¥¼ ë°°ìš°ê³  ì‹¶ì–´ì„œ","D. ì‚¬íšŒì™€ ì„¸ìƒ íë¦„ì´ ê¶ê¸ˆí•´ì„œ","E. ì§€ì¹˜ê³  ì‰¬ê³  ì‹¶ì–´ì„œ"],
    ["A. â€œì•ìœ¼ë¡œ ë­˜ í•´ì•¼ í• ì§€ ì•Œë ¤ì£¼ëŠ” ë‚˜ì¹¨ë°˜â€","B. â€œìƒê°ì„ ì •ë¦¬í•´ì£¼ëŠ” ëŒ€í™” ìƒëŒ€â€","C. â€œìƒˆë¡œìš´ ì„¸ìƒì„ ë³´ì—¬ì£¼ëŠ” ì°½ë¬¸â€","D. â€œí˜„ì‹¤ì„ ì´í•´í•˜ê²Œ í•´ì£¼ëŠ” ì§€ë„â€","E. â€œë§ˆìŒì„ ì‰¬ê²Œ í•´ì£¼ëŠ” íœ´ì‹ì²˜â€"],
]


# =====================================================
# Mappings
# =====================================================
genre_map = {"A": "ìê¸°ê³„ë°œ", "B": "ì¸ë¬¸/ì² í•™", "C": "ê³¼í•™/IT", "D": "ì—­ì‚¬/ì‚¬íšŒ", "E": "ì†Œì„¤"}

genre_persona = {
    "ìê¸°ê³„ë°œ": "ì‹¤í–‰Â·ë£¨í‹´Â·ì„±ê³¼ë¥¼ ì¤‘ì‹œí•˜ëŠ” ì„±ì¥í˜•",
    "ì¸ë¬¸/ì² í•™": "ì˜ë¯¸Â·ê°€ì¹˜Â·ìê¸°ì´í•´ë¥¼ ê¹Šê²Œ íŒŒê³ ë“œëŠ” ì„±ì°°í˜•",
    "ê³¼í•™/IT": "ì›ë¦¬Â·êµ¬ì¡°Â·ì •ë³´ë¥¼ ë¶„ì„í•˜ëŠ” íƒêµ¬í˜•",
    "ì—­ì‚¬/ì‚¬íšŒ": "ì‚¬íšŒ êµ¬ì¡°Â·ë§¥ë½Â·íë¦„ì„ ì´í•´í•˜ë ¤ëŠ” ê´€ì°°í˜•",
    "ì†Œì„¤": "ê°ì •Â·ë¶„ìœ„ê¸°Â·ì„œì‚¬ ëª°ì…ì„ í†µí•´ íšŒë³µí•˜ëŠ” ê°ì„±í˜•",
}

genre_flavors = {
    "ìê¸°ê³„ë°œ": ["ì‹¤í–‰", "ë£¨í‹´", "ë™ê¸°ë¶€ì—¬", "ìŠµê´€", "ìê¸°ê´€ë¦¬"],
    "ì¸ë¬¸/ì² í•™": ["ì„±ì°°", "ê´€ì ", "ìê¸°ì´í•´", "ê°€ì¹˜", "ì§ˆë¬¸"],
    "ê³¼í•™/IT": ["ì›ë¦¬", "í˜¸ê¸°ì‹¬", "ë¯¸ë˜", "ë¬¸ì œí•´ê²°", "êµ¬ì¡°"],
    "ì—­ì‚¬/ì‚¬íšŒ": ["ë§¥ë½", "íë¦„", "êµ¬ì¡°", "ì‚¬ë¡€", "ì‹œì•¼"],
    "ì†Œì„¤": ["ìœ„ë¡œ", "ëª°ì…", "ì—¬ìš´", "ê´€ê³„", "íšŒë³µ"],
}

# ìƒí™© íƒœê·¸(Q5~Q7)
situation_tag_map_q5_to_q7 = {
    5: {"A": ["ë™ê¸°"], "B": ["ìœ„ë¡œ"], "C": ["íƒêµ¬"], "D": ["íƒêµ¬"], "E": ["ìœ„ë¡œ", "íœ´ì‹"]},
    6: {"A": ["ë™ê¸°"], "B": ["ìœ„ë¡œ"], "C": ["íƒêµ¬"], "D": ["íƒêµ¬"], "E": ["íœ´ì‹", "ìœ„ë¡œ"]},
    7: {"A": ["ë™ê¸°"], "B": ["ìœ„ë¡œ"], "C": ["íƒêµ¬"], "D": ["íƒêµ¬"], "E": ["íœ´ì‹", "ìœ„ë¡œ"]},
}
tag_display = {"ë™ê¸°": "ë°©í–¥/ë™ê¸°ë¶€ì—¬", "ìœ„ë¡œ": "ê°ì • ì •ë¦¬/ìœ„ë¡œ", "íœ´ì‹": "íœ´ì‹/íšŒë³µ", "íƒêµ¬": "í˜¸ê¸°ì‹¬/íƒêµ¬"}

# ì¥ë¥´/ìƒí™© â†’ êµ­ë¦½ì¤‘ì•™ë„ì„œê´€ ê²€ìƒ‰ìš© í‚¤ì›Œë“œ(ì œëª© ê²€ìƒ‰ì— ì‚¬ìš©)
genre_seed_keywords = {
    "ìê¸°ê³„ë°œ": ["ìŠµê´€", "ê³µë¶€", "ì‹œê°„ê´€ë¦¬", "ëª©í‘œ", "ìê¸°ê³„ë°œ", "ë£¨í‹´"],
    "ì¸ë¬¸/ì² í•™": ["ì² í•™", "ì‚¬ìœ ", "ì¸ê°„", "ê´€ê³„", "ì‚¶", "ì˜ë¯¸"],
    "ê³¼í•™/IT": ["AI", "ë°ì´í„°", "ê³¼í•™", "í”„ë¡œê·¸ë˜ë°", "ì½”ë”©", "ê¸°ìˆ "],
    "ì—­ì‚¬/ì‚¬íšŒ": ["ì‚¬íšŒ", "ì—­ì‚¬", "ì •ì¹˜", "ê²½ì œ", "ë¬¸í™”", "ì„¸ê³„"],
    "ì†Œì„¤": ["ì†Œì„¤", "ì¥í¸", "ì„±ì¥", "íë§", "ê´€ê³„", "ì²­ì¶˜"],
}
situation_seed_keywords = {
    "ìœ„ë¡œ": ["ìœ„ë¡œ", "ë§ˆìŒ", "ë¶ˆì•ˆ", "ìƒì²˜", "ì¹˜ìœ "],
    "íœ´ì‹": ["íë§", "íœ´ì‹", "ì‰¼", "ì—¬ìœ "],
    "ë™ê¸°": ["ë™ê¸°", "ì—´ì •", "ì„±ì¥", "ëª©í‘œ", "ê³µë¶€"],
    "íƒêµ¬": ["í˜¸ê¸°ì‹¬", "ì§ˆë¬¸", "íƒêµ¬", "ë¯¸ë˜", "ì‚¬ê³ "],
}


# =====================================================
# Session State
# =====================================================
if "submitted" not in st.session_state:
    st.session_state.submitted = False
if "result" not in st.session_state:
    st.session_state.result = None
if "summary_loaded" not in st.session_state:
    st.session_state.summary_loaded = False

for i in range(7):
    k = f"q{i+1}"
    if k not in st.session_state:
        st.session_state[k] = None


def reset_test():
    for i in range(7):
        st.session_state[f"q{i+1}"] = None
    st.session_state.submitted = False
    st.session_state.result = None
    st.session_state.summary_loaded = False


# =====================================================
# Scoring Helpers
# =====================================================
def letter_of(ans: str) -> str:
    return ans.strip()[0]


def compute_genre_scores(answers: List[str]) -> Dict[str, int]:
    scores = {g: 0 for g in set(genre_map.values())}
    for a in answers:
        scores[genre_map[letter_of(a)]] += 1
    return scores


def compute_situation_scores(answers: List[str]) -> Dict[str, int]:
    tags = {"ìœ„ë¡œ": 0, "íœ´ì‹": 0, "ë™ê¸°": 0, "íƒêµ¬": 0}
    for qno in [5, 6, 7]:
        l = letter_of(answers[qno - 1])
        for t in situation_tag_map_q5_to_q7[qno].get(l, []):
            tags[t] += 1
    return tags


def ranked(scores: Dict[str, int]):
    return sorted(scores.items(), key=lambda x: x[1], reverse=True)


def top_two(scores: Dict[str, int]) -> List[str]:
    r = ranked(scores)
    if not r:
        return []
    top = [k for k, v in r if v == r[0][1]]
    if len(top) >= 2:
        return top[:2]
    # second best 1ê°œ ë¶™ì´ê¸°
    second = None
    for k, v in r:
        if v < r[0][1]:
            second = k
            break
    if second:
        return top + [second]
    return top


def top_list(scores: Dict[str, int]) -> List[str]:
    r = ranked(scores)
    if not r:
        return []
    topv = r[0][1]
    return [k for k, v in r if v == topv]


# =====================================================
# Networking (retry)
# =====================================================
def requests_get(url, params=None, timeout=10, retries=1):
    last = None
    for i in range(retries + 1):
        try:
            return requests.get(url, params=params, timeout=timeout)
        except (ReadTimeout, ConnectionError) as e:
            last = e
            if i == retries:
                raise
            time.sleep(0.4 * (2**i))
    raise last


@st.cache_data(show_spinner=False)
def nl_search_raw(cert_key: str, title_query: str, page_no: int, page_size: int, timeout: int, retries: int) -> dict:
    url = "https://www.nl.go.kr/seoji/SearchApi.do"
    params = {
        "cert_key": cert_key,
        "result_style": "json",
        "page_no": page_no,
        "page_size": page_size,
        "title": title_query,
    }
    r = requests_get(url, params=params, timeout=timeout, retries=retries)
    r.raise_for_status()
    try:
        return r.json()
    except Exception:
        return json.loads(r.text)


def _extract_items(nl_json: dict) -> List[dict]:
    """API ì‘ë‹µ êµ¬ì¡°ê°€ ì¼€ì´ìŠ¤ë³„ë¡œ ë‹¬ë¼ì„œ, list í˜•íƒœë¥¼ ìµœëŒ€í•œ ì°¾ì•„ëƒ„."""
    if not isinstance(nl_json, dict):
        return []

    # í”í•œ í‚¤ í›„ë³´
    for k in ["docs", "data", "items", "result"]:
        if k in nl_json and isinstance(nl_json[k], list):
            return nl_json[k]

    # value ì¤‘ list[dict] ì°¾ê¸°
    for v in nl_json.values():
        if isinstance(v, list) and v and isinstance(v[0], dict):
            return v

    return []


def _normalize_item(it: dict) -> dict:
    """ì—¬ëŸ¬ í‚¤ ì¼€ì´ìŠ¤ë¥¼ ê°ì•ˆí•´ì„œ í‘œì¤€ í•„ë“œë¡œ ì •ê·œí™”."""
    title = (it.get("TITLE") or it.get("title") or "").strip()
    author = (it.get("AUTHOR") or it.get("author") or "").strip()
    publisher = (it.get("PUBLISHER") or it.get("publisher") or "").strip()

    isbn = (it.get("EA_ISBN") or it.get("ISBN") or it.get("isbn") or "").strip()
    cover_url = (it.get("TITLE_URL") or it.get("cover") or it.get("image") or "").strip()

    intro_url = (it.get("BOOK_INTRODUCTION_URL") or it.get("book_introduction_url") or "").strip()
    summary_url = (it.get("BOOK_SUMMARY_URL") or it.get("book_summary_url") or "").strip()

    # ë°œí–‰ì—°ë„/ì¼ì ì¶”ì •
    pub_year = (it.get("PUBLISH_PREDATE") or it.get("PUBLISH_DATE") or it.get("publish_date") or "").strip()
    pub_year = pub_year[:4] if pub_year else ""

    # ë¶„ë¥˜ ê´€ë ¨(ìˆìœ¼ë©´)
    kdc_name = (it.get("KDC_NAME") or it.get("kdc_name") or "").strip()

    return {
        "title": title,
        "author": author,
        "publisher": publisher,
        "isbn": isbn,
        "cover_url": cover_url,
        "intro_url": intro_url,
        "summary_url": summary_url,
        "pub_year": pub_year,
        "kdc_name": kdc_name,
        "raw": it,
    }


def _dedup_items(items: List[dict]) -> List[dict]:
    seen = set()
    out = []
    for it in items:
        key = it.get("isbn") or (it.get("title", "") + "|" + it.get("author", ""))
        key = key.strip()
        if not key or key in seen:
            continue
        seen.add(key)
        out.append(it)
    return out


def build_nl_queries(focus_genres: List[str], top_situations: List[str]) -> List[str]:
    """
    êµ­ë¦½ì¤‘ì•™ë„ì„œê´€ SearchApiëŠ” 'title' íŒŒë¼ë¯¸í„°ê°€ ê°€ì¥ ì•ˆì „í•´ì„œ,
    ì¥ë¥´/ìƒí™©ì— ë”°ë¼ ì œëª© ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ëª‡ ê°œ ë§Œë“ ë‹¤.
    """
    queries = []
    for g in focus_genres[:2]:
        g_words = genre_seed_keywords.get(g, [])
        # ìƒí™© íƒœê·¸ê°€ ìˆìœ¼ë©´ ì„ê¸°(ë„ˆë¬´ ê¸¸ê²Œ ë§Œë“¤ì§€ ë§ê³  1~2ë‹¨ì–´ ìˆ˜ì¤€)
        if top_situations:
            s = top_situations[0]
            s_words = situation_seed_keywords.get(s, [])
            if g_words and s_words:
                queries.append(f"{random.choice(s_words)} {random.choice(g_words)}")
            elif g_words:
                queries.append(random.choice(g_words))
        else:
            if g_words:
                queries.append(random.choice(g_words))

    # ì—¬ë¶„ ì¿¼ë¦¬ 1ê°œ(ìƒí™© ì¤‘ì‹¬)
    if top_situations:
        s_words = situation_seed_keywords.get(top_situations[0], [])
        if s_words:
            queries.append(random.choice(s_words))

    # ì¤‘ë³µ ì œê±°
    uniq = []
    for q in queries:
        q = q.strip()
        if q and q not in uniq:
            uniq.append(q)
    return uniq[:3]  # ìµœëŒ€ 3ê°œë§Œ (ì†ë„/ë¶€í•˜ ì œí•œ)


def fetch_candidate_pool_from_nl(
    cert_key: str,
    focus_genres: List[str],
    top_situations: List[str],
    target_pool_size: int,
    timeout: int,
    retries: int,
) -> Tuple[List[dict], List[str]]:
    """
    ì—¬ëŸ¬ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰í•´ í›„ë³´ë¥¼ ëª¨ì•„ pool_sizeë§Œí¼ ë§Œë“¤ê¸°.
    ë°˜í™˜: (candidates, used_queries)
    """
    if not cert_key:
        return [], []

    used_queries = build_nl_queries(focus_genres, top_situations)
    all_items: List[dict] = []

    # ì¿¼ë¦¬ë³„ë¡œ 1í˜ì´ì§€ì”©ë§Œ ìš°ì„  ê°€ì ¸ì™€ë„ poolì€ ì¶©ë¶„íˆ ì±„ì›Œì§€ëŠ” ê²½ìš°ê°€ ë§ìŒ
    per_query_page_size = max(10, min(50, target_pool_size // max(1, len(used_queries))))
    per_query_page_size = min(per_query_page_size, 50)

    for q in used_queries:
        try:
            raw = nl_search_raw(cert_key, title_query=q, page_no=1, page_size=per_query_page_size, timeout=timeout, retries=retries)
            items = [_normalize_item(it) for it in _extract_items(raw)]
            all_items.extend(items)
        except Exception:
            continue

    all_items = _dedup_items(all_items)

    # pool_size ë§ì¶”ê¸°
    if len(all_items) > target_pool_size:
        all_items = all_items[:target_pool_size]

    return all_items, used_queries


# =====================================================
# Summary fetch (optional lazy)
# =====================================================
@st.cache_data(show_spinner=False)
def fetch_text_from_url(url: str, max_chars: int = 700, timeout: int = 10, retries: int = 0) -> str:
    if not url:
        return ""
    try:
        r = requests_get(url, params=None, timeout=timeout, retries=retries)
        r.raise_for_status()
        text = r.text

        text = re.sub(r"<script.*?>.*?</script>", " ", text, flags=re.DOTALL | re.IGNORECASE)
        text = re.sub(r"<style.*?>.*?</style>", " ", text, flags=re.DOTALL | re.IGNORECASE)
        text = re.sub(r"<[^>]+>", " ", text)
        text = unescape(text)
        text = re.sub(r"\s+", " ", text).strip()

        if len(text) > max_chars:
            text = text[:max_chars].rstrip() + "â€¦"
        return text
    except RequestException:
        return ""


def get_summary_for_book(book: dict) -> str:
    # summary_url ìš°ì„ , ì—†ìœ¼ë©´ intro_url
    s = ""
    if book.get("summary_url"):
        s = fetch_text_from_url(book["summary_url"], timeout=nl_timeout, retries=0)
    if not s and book.get("intro_url"):
        s = fetch_text_from_url(book["intro_url"], timeout=nl_timeout, retries=0)
    return s.strip()


# =====================================================
# OpenAI: choose 3 from candidate list (Korean books in list)
# =====================================================
@st.cache_data(show_spinner=False)
def call_openai_json(api_key: str, model: str, system: str, user: str) -> dict:
    url = "https://api.openai.com/v1/chat/completions"
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    payload = {
        "model": model,
        "temperature": 0.4,
        "response_format": {"type": "json_object"},
        "messages": [{"role": "system", "content": system}, {"role": "user", "content": user}],
    }
    r = requests.post(url, headers=headers, json=payload, timeout=30)
    r.raise_for_status()
    return json.loads(r.json()["choices"][0]["message"]["content"])


def ai_choose_from_pool(
    answers: List[str],
    focus_genres: List[str],
    top_situations: List[str],
    pool: List[dict],
) -> List[dict]:
    """
    pool(í›„ë³´ ë¦¬ìŠ¤íŠ¸) ì¤‘ì—ì„œ AIê°€ 3ê°œë¥¼ ê³ ë¥´ê³ ,
    ê° ì±…ì— ëŒ€í•´ book_hook(ì±…ë³„ë¡œ ë‹¤ë¥¸ í¬ì¸íŠ¸)ì„ ìƒì„±í•˜ê²Œ í•œë‹¤.
    """
    # ë„ˆë¬´ ë§ì€ í›„ë³´ë¥¼ ë³´ë‚´ë©´ í† í°/ì§€ì—° ì¦ê°€ â†’ ìµœëŒ€ 40ê°œë§Œ
    pool_trim = pool[:40]
    brief = []
    for i, b in enumerate(pool_trim):
        brief.append({
            "id": i,
            "title": b.get("title", ""),
            "author": b.get("author", ""),
            "publisher": b.get("publisher", ""),
            "pub_year": b.get("pub_year", ""),
            "isbn": b.get("isbn", ""),
            "kdc_name": b.get("kdc_name", ""),
        })

    system = (
        "ë„ˆëŠ” í•œêµ­ì–´ ë…ì„œ íë ˆì´í„°ë‹¤.\n"
        "ì‚¬ìš©ìì˜ ì„¤ë¬¸(ì„±í–¥+ìƒí™©)ì„ ë°˜ì˜í•´, ì œê³µëœ 'í›„ë³´ ë„ì„œ ë¦¬ìŠ¤íŠ¸' ì•ˆì—ì„œë§Œ 3ê¶Œì„ ê³¨ë¼ë¼.\n"
        "ë°˜ë“œì‹œ ì„œë¡œ ë‹¤ë¥¸ ì±… 3ê¶Œì´ì–´ì•¼ í•œë‹¤.\n"
        "ê° ì±…ì— ëŒ€í•´ 'ì™œ ì´ ì±…ì´ íŠ¹íˆ ë§ëŠ”ì§€'ë¥¼ 1ë¬¸ì¥ book_hookìœ¼ë¡œ ì‘ì„±í•˜ë˜, 3ê¶Œì´ ì„œë¡œ ë¹„ìŠ·í•˜ì§€ ì•Šê²Œ í¬ì¸íŠ¸ë¥¼ ë‹¬ë¦¬í•´ë¼.\n"
        "ì¶œë ¥ì€ ì•„ë˜ JSON í˜•ì‹ë§Œ:\n\n"
        "{\n"
        '  "picks": [\n'
        '    {"id": 0, "book_hook": "í•œ ë¬¸ì¥ ì´ìœ (ì±…ë§ˆë‹¤ ë‹¤ë¥´ê²Œ)"},\n'
        '    {"id": 1, "book_hook": "..."},\n'
        '    {"id": 2, "book_hook": "..."}\n'
        "  ]\n"
        "}\n"
    )
    user = (
        f"focus_genres: {focus_genres}\n"
        f"top_situations: {top_situations}\n"
        "ì‚¬ìš©ì ë‹µë³€:\n" + "\n".join([f"- {a}" for a in answers]) + "\n\n"
        "í›„ë³´ ë„ì„œ ë¦¬ìŠ¤íŠ¸(JSON):\n" + json.dumps({"candidates": brief}, ensure_ascii=False)
    )

    obj = call_openai_json(openai_api_key, openai_model, system, user)
    picks = obj.get("picks", [])

    picked = []
    used = set()
    for p in picks:
        try:
            idx = int(p.get("id"))
        except Exception:
            continue
        if idx < 0 or idx >= len(pool_trim) or idx in used:
            continue
        used.add(idx)
        b = dict(pool_trim[idx])
        b["book_hook"] = str(p.get("book_hook", "")).strip()
        picked.append(b)
        if len(picked) == 3:
            break

    return picked


# =====================================================
# Fallback chooser (no OpenAI): deterministic-ish selection from pool
# =====================================================
def fallback_choose_from_pool(pool: List[dict], focus_genres: List[str]) -> List[dict]:
    """
    OpenAIê°€ ì—†ìœ¼ë©´:
    - í‘œì§€/ISBN ì¡´ì¬í•˜ëŠ” í›„ë³´ë¥¼ ìš°ì„ 
    - ì œëª©/ì €ì ì¤‘ë³µ ìµœì†Œí™”
    - 3ê¶Œ ì„ íƒ
    """
    def score(b):
        s = 0
        if b.get("isbn"):
            s += 3
        if b.get("cover_url"):
            s += 2
        if b.get("pub_year"):
            s += 1
        if b.get("kdc_name"):
            s += 1
        # ëœë¤ ì†Œê¸ˆ(ë™ì  ë¶„ì‚°)
        s += random.random() * 0.1
        return s

    sorted_pool = sorted(pool, key=score, reverse=True)
    out = []
    seen = set()
    for b in sorted_pool:
        key = b.get("isbn") or (b.get("title","") + "|" + b.get("author",""))
        if not key or key in seen:
            continue
        seen.add(key)
        out.append({**b, "book_hook": ""})
        if len(out) == 3:
            break
    return out


# =====================================================
# Diversified ì´ìœ  ìƒì„± (ì„¤ë¬¸ ê·¼ê±° + AIì˜ book_hookê¹Œì§€ ì„ì–´ì„œ ì±…ë§ˆë‹¤ ë‹¤ë¥´ê²Œ)
# =====================================================
def evidence_by_genre(answers: List[str], target_genre_letter: str) -> List[str]:
    return [a[3:].strip() for a in answers if letter_of(a) == target_genre_letter]


def situation_evidence_candidates(answers: List[str], focus_tags: List[str]) -> List[str]:
    ev = []
    for qno in [5, 6, 7]:
        ans = answers[qno - 1]
        l = letter_of(ans)
        tags = situation_tag_map_q5_to_q7[qno].get(l, [])
        if any(t in focus_tags for t in tags):
            ev.append(ans[3:].strip())
    return ev


def rotate_pick(items: List[str], used: set, fallback: str = "") -> str:
    for it in items:
        if it and it not in used:
            used.add(it)
            return it
    return fallback if fallback else (items[0] if items else "")


def pick_focus_tag(top_situations: List[str], idx: int) -> List[str]:
    if not top_situations:
        return []
    if len(top_situations) == 1:
        return top_situations
    if idx == 0:
        return [top_situations[0]]
    if idx == 1:
        return [top_situations[1 % len(top_situations)]]
    return top_situations[:2]


reason_templates = [
    "ìµœê·¼ â€œ{s_ev}â€ë¼ê³  ë‹µí•œ ê±¸ ë³´ë©´ ì§€ê¸ˆì€ **{sit}**ì´(ê°€) í•„ìš”í•´ ë³´ì—¬ìš”. â€œ{g_ev}â€ ì„ íƒë„ ìˆì–´ì„œ {persona} ì„±í–¥ê³¼ ì˜ ë§ê³ , **{title}**ì€(ëŠ”) {flavor} ê´€ì ì—ì„œ ë„ì›€ì„ ì¤„ ìˆ˜ ìˆì–´ìš”. {hook}",
    "ë‹¹ì‹ ì´ ê³ ë¥¸ ë‹µ ì¤‘ â€œ{g_ev}â€ê°€ ëˆˆì— ë„ì–´ìš”. {persona}ì¸ ë‹¹ì‹ ì—ê²Œ **{sit}**ì„(ë¥¼) ì±„ì›Œì¤„ ì±…ì´ í•„ìš”í•´ì„œ, {flavor} í¬ì¸íŠ¸ê°€ ê°•í•œ **{title}**ì„(ë¥¼) ê³¨ëì–´ìš”. {hook}",
    "ì§€ê¸ˆì€ **{sit}**ì´(ê°€) ìš°ì„ ì¼ ê²ƒ ê°™ì•„ìš”(â€œ{s_ev}â€). ë™ì‹œì— â€œ{g_ev}â€ë¥¼ íƒí•œ ê±¸ ë³´ë©´ {persona}ë‹µê²Œ ì½ì„ ì±…ì´ í•„ìš”í•˜ì£ . ê·¸ë˜ì„œ **{title}**ì„(ë¥¼) ì¶”ì²œí•©ë‹ˆë‹¤. {hook}",
    "ì„¤ë¬¸ì—ì„œ â€œ{s_ev}â€ë¼ê³  í–ˆë˜ ì ì„ ë°˜ì˜í–ˆì–´ìš”. {persona} ì„±í–¥ì˜ ë‹¹ì‹ ì—ê²Œ **{title}**ì€(ëŠ”) {flavor}ì„ í†µí•´ **{sit}**ì— ë„ì›€ì„ ì¤„ í™•ë¥ ì´ ë†’ì•„ìš”. {hook}",
]


def build_reason_diversified(
    answers: List[str],
    genre: str,
    top_situations: List[str],
    idx: int,
    book: dict,
    used_genre_ev: set,
    used_sit_ev: set,
    used_flavor: set,
    used_template: set,
) -> str:
    # ì¥ë¥´ â†’ ì„¤ë¬¸ ì„ íƒì§€ ë¬¸ì ë§¤í•‘(A/B/C/D/E)
    genre_to_letter = {v: k for k, v in genre_map.items()}
    target_letter = genre_to_letter.get(genre, "")

    focus_tags = pick_focus_tag(top_situations, idx)
    sit_label = ", ".join([tag_display.get(t, t) for t in focus_tags]) if focus_tags else "ì§€ê¸ˆ í•„ìš”í•œ ê²ƒ"

    g_candidates = evidence_by_genre(answers, target_letter) if target_letter else []
    s_candidates = situation_evidence_candidates(answers, focus_tags) if focus_tags else []

    g_ev = rotate_pick(g_candidates, used_genre_ev, fallback="")
    s_ev = rotate_pick(s_candidates, used_sit_ev, fallback="ìš”ì¦˜ ì±…ì´ í•„ìš”í•˜ë‹¤")

    if not g_ev:
        q1to4 = [answers[i][3:].strip() for i in [0, 1, 2, 3] if answers[i]]
        g_ev = rotate_pick(q1to4, used_genre_ev, fallback=(q1to4[0] if q1to4 else "ì±…ì—ì„œ ì–»ê³  ì‹¶ì€ ê²Œ ìˆë‹¤"))

    flavor = rotate_pick(genre_flavors.get(genre, []), used_flavor, fallback="í•µì‹¬")
    template = rotate_pick(reason_templates, used_template, fallback=reason_templates[idx % len(reason_templates)])
    persona = genre_persona.get(genre, "ì´ëŸ° ì„±í–¥")

    hook = book.get("book_hook", "").strip()
    hook = f"({hook})" if hook else ""

    return template.format(
        s_ev=s_ev,
        g_ev=g_ev,
        sit=sit_label,
        persona=persona,
        title=book.get("title", ""),
        flavor=flavor,
        hook=hook,
    ).strip()


# =====================================================
# UI: Questionnaire
# =====================================================
st.divider()
st.subheader("ğŸ“ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”")

for i, q in enumerate(questions):
    st.markdown(f"**{q}**")
    st.radio(
        label=f"q{i+1}",
        options=question_choices[i],
        key=f"q{i+1}",
        index=None,
        label_visibility="collapsed",
    )
    st.write("")

st.divider()
c1, c2, c3 = st.columns([1, 1, 1.4])
with c1:
    clicked = st.button("ê²°ê³¼ ë³´ê¸°", type="primary")
with c2:
    st.button("ë‹¤ì‹œ í…ŒìŠ¤íŠ¸í•˜ê¸°", on_click=reset_test)
with c3:
    load_summary_clicked = st.button("ì¤„ê±°ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°(ëŠë¦¼)", help="ê²°ê³¼ê°€ ë‚˜ì˜¨ ë’¤ ëˆŒëŸ¬ì£¼ì„¸ìš”. (ì§€ì—° ë¡œë”©)")

if load_summary_clicked:
    st.session_state.summary_loaded = True


# =====================================================
# Main Flow
# =====================================================
if clicked:
    answers = [st.session_state[f"q{i+1}"] for i in range(7)]
    if any(a is None for a in answers):
        missing = [str(i + 1) for i, a in enumerate(answers) if a is None]
        st.warning(f"ëª¨ë“  ì§ˆë¬¸ì— ë‹µë³€í•´ ì£¼ì„¸ìš”! (ë¯¸ì‘ë‹µ: {', '.join(missing)}ë²ˆ)")
    else:
        if not nl_api_key:
            st.error("êµ­ë¦½ì¤‘ì•™ë„ì„œê´€ API í‚¤(cert_key)ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì— ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        else:
            with st.spinner("ë¶„ì„ + í›„ë³´ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
                genre_scores = compute_genre_scores(answers)
                situation_scores = compute_situation_scores(answers)

                focus_genres = top_two(genre_scores)  # ìµœëŒ€ 2ê°œ ì¥ë¥´
                top_situations = top_list(situation_scores)

                # 1) í›„ë³´ í’€: NLì—ì„œ ë¨¼ì € ê°€ì ¸ì˜¤ê¸°
                pool, used_queries = fetch_candidate_pool_from_nl(
                    cert_key=nl_api_key,
                    focus_genres=focus_genres,
                    top_situations=top_situations,
                    target_pool_size=pool_size,
                    timeout=nl_timeout,
                    retries=nl_retries,
                )

                if not pool:
                    st.error("êµ­ë¦½ì¤‘ì•™ë„ì„œê´€ APIì—ì„œ í›„ë³´ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆì–´ìš”. (í‚¤/ë„¤íŠ¸ì›Œí¬/ì¿¼ë¦¬ ë¬¸ì œ ê°€ëŠ¥)")
                else:
                    # 2) í›„ë³´ ì¤‘ì—ì„œ 3ê¶Œ ì„ íƒ: AI(ê°€ëŠ¥í•˜ë©´) / ì—†ìœ¼ë©´ fallback
                    used_ai = False
                    if openai_api_key:
                        try:
                            picked = ai_choose_from_pool(
                                answers=answers,
                                focus_genres=focus_genres,
                                top_situations=top_situations,
                                pool=pool,
                            )
                            if len(picked) == 3:
                                used_ai = True
                            else:
                                picked = fallback_choose_from_pool(pool, focus_genres)
                        except Exception:
                            picked = fallback_choose_from_pool(pool, focus_genres)
                            used_ai = False
                    else:
                        picked = fallback_choose_from_pool(pool, focus_genres)
                        used_ai = False

                    # 3) (ì˜µì…˜) ì¤„ê±°ë¦¬ ì§€ì—° ë¡œë”©
                    if fetch_summary_default or st.session_state.summary_loaded:
                        for b in picked:
                            b["summary"] = get_summary_for_book(b)
                    else:
                        for b in picked:
                            b["summary"] = ""

                    # 4) ì¶”ì²œ ì´ìœ : ì±…ë§ˆë‹¤ ë‹¤ë¥´ê²Œ ìƒì„±(ì„¤ë¬¸ ê·¼ê±° + book_hook ì„ê¸°)
                    used_genre_ev, used_sit_ev, used_flavor, used_template = set(), set(), set(), set()
                    # ì±…ë³„ ì¥ë¥´ëŠ” â€œí˜„ì¬ ì•±ì˜ ì„±í–¥ ì¥ë¥´â€ë¡œ ë¶™ì—¬ë„ ë˜ì§€ë§Œ,
                    # í›„ë³´ ë¦¬ìŠ¤íŠ¸ì—ëŠ” ì¥ë¥´ ì •ë³´ê°€ í™•ì‹¤ì¹˜ ì•Šì•„ì„œ, ì—¬ê¸°ì„œëŠ”
                    # "ì£¼ëœ ì„±í–¥ ì¥ë¥´"ë¥¼ ê¸°ë³¸ ì¥ë¥´ë¡œ ì‚¬ìš©(ì•ˆì •ì ì¸ UX)
                    primary_genre = focus_genres[0] if focus_genres else "ì†Œì„¤"

                    for idx, b in enumerate(picked):
                        b["genre"] = primary_genre
                        b["why"] = build_reason_diversified(
                            answers=answers,
                            genre=primary_genre,
                            top_situations=top_situations,
                            idx=idx,
                            book=b,
                            used_genre_ev=used_genre_ev,
                            used_sit_ev=used_sit_ev,
                            used_flavor=used_flavor,
                            used_template=used_template,
                        )

                    st.session_state.submitted = True
                    st.session_state.result = {
                        "answers": answers,
                        "genre_scores": genre_scores,
                        "situation_scores": situation_scores,
                        "focus_genres": focus_genres,
                        "top_situations": top_situations,
                        "used_queries": used_queries,
                        "pool_count": len(pool),
                        "used_ai": used_ai,
                        "picked": picked,
                        "raw_first_pool_item": pool[0].get("raw") if pool else None,
                    }


# =====================================================
# Render Result
# =====================================================
if st.session_state.submitted and st.session_state.result:
    r = st.session_state.result

    st.subheader("ğŸ“Œ ë¶„ì„ ê²°ê³¼")
    st.success(f"ë…ì„œ ì„±í–¥(ìƒìœ„): {', '.join(r['focus_genres'])}")
    sit_text = ", ".join([tag_display.get(t, t) for t in r["top_situations"]]) if r["top_situations"] else "â€”"
    st.info(f"í˜„ì¬ í•„ìš”í•œ ê²ƒ(ìƒìœ„): **{sit_text}**")

    st.caption(f"êµ­ë¦½ì¤‘ì•™ë„ì„œê´€ ê²€ìƒ‰ í‚¤ì›Œë“œ: {', '.join(r['used_queries'])} Â· í›„ë³´ {r['pool_count']}ê¶Œ í™•ë³´")
    if r["used_ai"]:
        st.caption("âœ… AIê°€ í›„ë³´ ë¦¬ìŠ¤íŠ¸ ì¤‘ì—ì„œ 3ê¶Œì„ ì„ íƒí–ˆìŠµë‹ˆë‹¤.")
    else:
        st.caption("â„¹ï¸ AI ë¯¸ì‚¬ìš©/ì‹¤íŒ¨ë¡œ ê·œì¹™ ê¸°ë°˜ ì„ íƒì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.")

    if debug_show_raw and r.get("raw_first_pool_item"):
        with st.expander("ğŸ§ª í›„ë³´ 1ê°œ raw JSON"):
            st.json(r["raw_first_pool_item"])

    st.subheader("ğŸ“š ì¶”ì²œ ë„ì„œ 3ê¶Œ")
    for i, b in enumerate(r["picked"], start=1):
        st.markdown(f"### {i}. {b.get('title','')}")
        meta = []
        if b.get("author"):
            meta.append(f"ì €ì: {b['author']}")
        if b.get("publisher"):
            meta.append(f"ì¶œíŒì‚¬: {b['publisher']}")
        if b.get("pub_year"):
            meta.append(f"ë°œí–‰: {b['pub_year']}")
        if b.get("isbn"):
            meta.append(f"ISBN: {b['isbn']}")
        if meta:
            st.caption(" Â· ".join(meta))

        cols = st.columns([1, 2])
        with cols[0]:
            if b.get("cover_url"):
                st.image(b["cover_url"], use_container_width=True)
            else:
                st.info("í‘œì§€ ì´ë¯¸ì§€ ì—†ìŒ(ë°ì´í„° ë¯¸ì œê³µ)")

        with cols[1]:
            st.write("**ì¶”ì²œ ì´ìœ (ì„¤ë¬¸ ê·¼ê±° + ì±…ë³„ í¬ì¸íŠ¸)**")
            st.write(f"- {b.get('why','')}")

            st.write("**ì¤„ê±°ë¦¬/ì±…ì†Œê°œ**")
            if b.get("summary"):
                st.write(b["summary"])
            else:
                st.info("ì¤„ê±°ë¦¬ ë¯¸ë¡œë”©(â€˜ì¤„ê±°ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°â€™ ë²„íŠ¼ìœ¼ë¡œ ì§€ì—° ë¡œë”©) ë˜ëŠ” ì œê³µ URL ì—†ìŒ")

        st.divider()
