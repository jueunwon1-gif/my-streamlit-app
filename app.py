import json
import random
import re
import time
from html import unescape
from typing import Dict, List, Tuple

import requests
import streamlit as st
from requests.exceptions import ReadTimeout, ConnectionError, HTTPError, RequestException

# =====================================================
# Streamlit Setup
# =====================================================
st.set_page_config(page_title="ë‚˜ì™€ ì–´ìš¸ë¦¬ëŠ” ì±…ì€?", page_icon="ğŸ“š", layout="centered")

# =====================================================
# Sidebar
# =====================================================
st.sidebar.header("ğŸ”‘ API ì„¤ì •")

nl_api_key = st.sidebar.text_input(
    "êµ­ë¦½ì¤‘ì•™ë„ì„œê´€(ISBN ì„œì§€ì •ë³´) API Key (cert_key)",
    type="password",
)

openai_api_key = st.sidebar.text_input(
    "OpenAI API Key (ì„ íƒ)",
    type="password",
    help="ì…ë ¥í•˜ë©´ í›„ë³´ ë¦¬ìŠ¤íŠ¸ ì¤‘ì—ì„œ AIê°€ 3ê¶Œì„ ì„ íƒí•©ë‹ˆë‹¤. ì—†ìœ¼ë©´ ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ ê³ ë¦…ë‹ˆë‹¤.",
)
openai_model = st.sidebar.text_input("OpenAI ëª¨ë¸", value="gpt-4o-mini")

st.sidebar.subheader("âš¡ ì†ë„ ì˜µì…˜")
pool_size = st.sidebar.slider("í›„ë³´ í’€(ê°€ì ¸ì˜¬ ì±… ê°œìˆ˜)", 20, 120, 60, 10)
nl_timeout = st.sidebar.slider("êµ­ë¦½ì¤‘ì•™ë„ì„œê´€ API íƒ€ì„ì•„ì›ƒ(ì´ˆ)", 5, 30, 10, 1)
nl_retries = st.sidebar.slider("êµ­ë¦½ì¤‘ì•™ë„ì„œê´€ API ì¬ì‹œë„ íšŸìˆ˜", 0, 2, 1, 1)

fetch_summary_default = st.sidebar.checkbox(
    "ì¤„ê±°ë¦¬/ì±…ì†Œê°œë„ ë°”ë¡œ ê°€ì ¸ì˜¤ê¸°(ëŠë¦¼)",
    value=False,
)

st.sidebar.subheader("ğŸ§ª ë””ë²„ê·¸")
debug_show_raw = st.sidebar.checkbox("í›„ë³´ 1ê°œ raw JSON ë³´ê¸°", value=False)

# =====================================================
# Header
# =====================================================
st.title("ğŸ“š ë‚˜ì™€ ì–´ìš¸ë¦¬ëŠ” ì±…ì€?")
st.write("ì„±í–¥(ì¥ë¥´) + ìƒí™©(ì§€ê¸ˆ í•„ìš”í•œ ê²ƒ)ì„ ë¶„ì„í•˜ê³ , **êµ­ë¦½ì¤‘ì•™ë„ì„œê´€ í›„ë³´ ë¦¬ìŠ¤íŠ¸ ì¤‘ì—ì„œ** 3ê¶Œì„ ê³¨ë¼ ì¶”ì²œí•©ë‹ˆë‹¤.")

# =====================================================
# Questions
# =====================================================
questions = [
    "1) ìƒˆë¡œìš´ ì±…ì„ ê³ ë¥¼ ë•Œ ê°€ì¥ ëŒë¦¬ëŠ” ìš”ì†ŒëŠ”?",
    "2) ì¹œêµ¬ê°€ ì±… ì¶”ì²œì„ ë¶€íƒí•˜ë©´ ë‚˜ëŠ” ë³´í†µâ€¦",
    "3) ë‚´ê°€ ì±…ì„ ì½ì„ ë•Œ ê°€ì¥ ë§Œì¡±ìŠ¤ëŸ¬ìš´ ìˆœê°„ì€?",
    "4) í‰ì†Œ ë‚´ê°€ ê°€ì¥ ìì£¼ ê´€ì‹¬ì„ ê°–ëŠ” ì£¼ì œëŠ”?",
    "5) ìš”ì¦˜ ë‚˜ì—ê²Œ ê°€ì¥ í•„ìš”í•œ ê²ƒì€?",
    "6) ìµœê·¼ ë‚´ê°€ ì±…ì„ ì°¾ê²Œ ë˜ëŠ” ì´ìœ ëŠ”?",
    "7) ì§€ê¸ˆ ë‹¹ì¥ ì±…ì´ ë‚´ê²Œ í•´ì¤¬ìœ¼ë©´ í•˜ëŠ” ì—­í• ì€?",
]

question_choices = [
    ["A. ì½ê³  ë‚˜ì„œ ë°”ë¡œ ì‹¤ì²œí•  ìˆ˜ ìˆëŠ” ì¡°ì–¸","B. ì‚¶ì— ëŒ€í•œ ê¹Šì€ ì§ˆë¬¸ê³¼ í†µì°°","C. ìƒˆë¡œìš´ ì§€ì‹ê³¼ ê¸°ìˆ ì„ ë°°ìš°ëŠ” ì¬ë¯¸","D. ì‚¬íšŒì™€ ì‹œëŒ€ë¥¼ ì´í•´í•˜ëŠ” ê´€ì ","E. ê°ì •ì ìœ¼ë¡œ ëª°ì…í•  ìˆ˜ ìˆëŠ” ì´ì•¼ê¸°"],
    ["A. ë„ì›€ì´ ë  ë§Œí•œ í˜„ì‹¤ì ì¸ ì±…ì„ ì¶”ì²œí•œë‹¤","B. ìƒê°ì„ ë„“í˜€ì¤„ ì±…ì„ ì¶”ì²œí•œë‹¤","C. ì‹ ê¸°í•œ ì •ë³´ë¥¼ ì£¼ëŠ” ì±…ì„ ì¶”ì²œí•œë‹¤","D. ì„¸ìƒì„ ì´í•´í•˜ê²Œ í•´ì£¼ëŠ” ì±…ì„ ì¶”ì²œí•œë‹¤","E. ì¬ë¯¸ìˆê²Œ ì½íˆëŠ” ì±…ì„ ì¶”ì²œí•œë‹¤"],
    ["A. â€œì´ê±´ ë‚´ ì‚¶ì— ë°”ë¡œ ì ìš©í•  ìˆ˜ ìˆê² ë‹¤â€ ëŠë‚„ ë•Œ","B. â€œì„¸ìƒì„ ë³´ëŠ” ì‹œì•¼ê°€ ë„“ì–´ì¡Œë‹¤â€ ëŠë‚„ ë•Œ","C. â€œìƒˆë¡œìš´ ì‚¬ì‹¤ì„ ë°°ì› ë‹¤â€ ëŠë‚„ ë•Œ","D. â€œì‚¬íšŒë‚˜ ì—­ì‚¬ë¥¼ ì´í•´í•˜ê²Œ ëë‹¤â€ ëŠë‚„ ë•Œ","E. â€œì™„ì „íˆ ëª°ì…í•´ì„œ ê°ì •ì´ ì›€ì§ì˜€ë‹¤â€ ëŠë‚„ ë•Œ"],
    ["A. ì„±ì¥, ëª©í‘œ, ìê¸°ê´€ë¦¬","B. ì¸ê°„ê´€ê³„, ì‚¶ì˜ ì˜ë¯¸","C. ë¯¸ë˜ê¸°ìˆ , ê³¼í•™, ë°ì´í„°","D. ì‚¬íšŒë¬¸ì œ, ì—­ì‚¬ì  ì‚¬ê±´","E. ê°ì •, ì´ì•¼ê¸°, ìƒìƒ ì† ì„¸ê³„"],
    ["A. ë‹¤ì‹œ ë™ê¸°ë¶€ì—¬í•˜ê³  ë°©í–¥ì„ ì¡ëŠ” ê²ƒ","B. ë‚´ ë§ˆìŒì„ ì •ë¦¬í•  ìˆ˜ ìˆëŠ” í†µì°°","C. ë¨¸ë¦¬ë¥¼ ìê·¹í•˜ëŠ” ìƒˆë¡œìš´ í˜¸ê¸°ì‹¬","D. í˜„ì‹¤ì„ ì´í•´í•˜ê³  ì‹œì•¼ë¥¼ ë„“íˆëŠ” ê´€ì ","E. ìœ„ë¡œë°›ê³  ê°ì •ì„ ì‰¬ê²Œ í•˜ëŠ” ì´ì•¼ê¸°"],
    ["A. ë¯¸ë˜ ì¤€ë¹„ë‚˜ ìê¸°ê³„ë°œì´ í•„ìš”í•´ì„œ","B. ë³µì¡í•œ ê°ì •ì„ ì •ë¦¬í•˜ê³  ì‹¶ì–´ì„œ","C. ìƒˆë¡œìš´ ë¶„ì•¼ë¥¼ ë°°ìš°ê³  ì‹¶ì–´ì„œ","D. ì‚¬íšŒì™€ ì„¸ìƒ íë¦„ì´ ê¶ê¸ˆí•´ì„œ","E. ì§€ì¹˜ê³  ì‰¬ê³  ì‹¶ì–´ì„œ"],
    ["A. â€œì•ìœ¼ë¡œ ë­˜ í•´ì•¼ í• ì§€ ì•Œë ¤ì£¼ëŠ” ë‚˜ì¹¨ë°˜â€","B. â€œìƒê°ì„ ì •ë¦¬í•´ì£¼ëŠ” ëŒ€í™” ìƒëŒ€â€","C. â€œìƒˆë¡œìš´ ì„¸ìƒì„ ë³´ì—¬ì£¼ëŠ” ì°½ë¬¸â€","D. â€œí˜„ì‹¤ì„ ì´í•´í•˜ê²Œ í•´ì£¼ëŠ” ì§€ë„â€","E. â€œë§ˆìŒì„ ì‰¬ê²Œ í•´ì£¼ëŠ” íœ´ì‹ì²˜â€"],
]

# =====================================================
# Mappings
# =====================================================
genre_map = {"A": "ìê¸°ê³„ë°œ", "B": "ì¸ë¬¸/ì² í•™", "C": "ê³¼í•™/IT", "D": "ì—­ì‚¬/ì‚¬íšŒ", "E": "ì†Œì„¤"}

genre_persona = {
    "ìê¸°ê³„ë°œ": "ì‹¤í–‰Â·ë£¨í‹´Â·ì„±ê³¼ë¥¼ ì¤‘ì‹œí•˜ëŠ” ì„±ì¥í˜•",
    "ì¸ë¬¸/ì² í•™": "ì˜ë¯¸Â·ê°€ì¹˜Â·ìê¸°ì´í•´ë¥¼ ê¹Šê²Œ íŒŒê³ ë“œëŠ” ì„±ì°°í˜•",
    "ê³¼í•™/IT": "ì›ë¦¬Â·êµ¬ì¡°Â·ì •ë³´ë¥¼ ë¶„ì„í•˜ëŠ” íƒêµ¬í˜•",
    "ì—­ì‚¬/ì‚¬íšŒ": "ì‚¬íšŒ êµ¬ì¡°Â·ë§¥ë½Â·íë¦„ì„ ì´í•´í•˜ë ¤ëŠ” ê´€ì°°í˜•",
    "ì†Œì„¤": "ê°ì •Â·ë¶„ìœ„ê¸°Â·ì„œì‚¬ ëª°ì…ì„ í†µí•´ íšŒë³µí•˜ëŠ” ê°ì„±í˜•",
}

genre_flavors = {
    "ìê¸°ê³„ë°œ": ["ì‹¤í–‰", "ë£¨í‹´", "ë™ê¸°ë¶€ì—¬", "ìŠµê´€", "ìê¸°ê´€ë¦¬"],
    "ì¸ë¬¸/ì² í•™": ["ì„±ì°°", "ê´€ì ", "ìê¸°ì´í•´", "ê°€ì¹˜", "ì§ˆë¬¸"],
    "ê³¼í•™/IT": ["ì›ë¦¬", "í˜¸ê¸°ì‹¬", "ë¯¸ë˜", "ë¬¸ì œí•´ê²°", "êµ¬ì¡°"],
    "ì—­ì‚¬/ì‚¬íšŒ": ["ë§¥ë½", "íë¦„", "êµ¬ì¡°", "ì‚¬ë¡€", "ì‹œì•¼"],
    "ì†Œì„¤": ["ìœ„ë¡œ", "ëª°ì…", "ì—¬ìš´", "ê´€ê³„", "íšŒë³µ"],
}

situation_tag_map_q5_to_q7 = {
    5: {"A": ["ë™ê¸°"], "B": ["ìœ„ë¡œ"], "C": ["íƒêµ¬"], "D": ["íƒêµ¬"], "E": ["ìœ„ë¡œ", "íœ´ì‹"]},
    6: {"A": ["ë™ê¸°"], "B": ["ìœ„ë¡œ"], "C": ["íƒêµ¬"], "D": ["íƒêµ¬"], "E": ["íœ´ì‹", "ìœ„ë¡œ"]},
    7: {"A": ["ë™ê¸°"], "B": ["ìœ„ë¡œ"], "C": ["íƒêµ¬"], "D": ["íƒêµ¬"], "E": ["íœ´ì‹", "ìœ„ë¡œ"]},
}
tag_display = {"ë™ê¸°": "ë°©í–¥/ë™ê¸°ë¶€ì—¬", "ìœ„ë¡œ": "ê°ì • ì •ë¦¬/ìœ„ë¡œ", "íœ´ì‹": "íœ´ì‹/íšŒë³µ", "íƒêµ¬": "í˜¸ê¸°ì‹¬/íƒêµ¬"}

genre_seed_keywords = {
    "ìê¸°ê³„ë°œ": ["ìŠµê´€", "ê³µë¶€", "ì‹œê°„ê´€ë¦¬", "ëª©í‘œ", "ë£¨í‹´"],
    "ì¸ë¬¸/ì² í•™": ["ì² í•™", "ì‚¬ìœ ", "ì¸ê°„", "ê´€ê³„", "ì˜ë¯¸"],
    "ê³¼í•™/IT": ["AI", "ë°ì´í„°", "ê³¼í•™", "í”„ë¡œê·¸ë˜ë°", "ì½”ë”©"],
    "ì—­ì‚¬/ì‚¬íšŒ": ["ì‚¬íšŒ", "ì—­ì‚¬", "ì •ì¹˜", "ê²½ì œ", "ì„¸ê³„"],
    "ì†Œì„¤": ["ì†Œì„¤", "ì¥í¸", "ì²­ì¶˜", "ê´€ê³„", "íë§"],
}
situation_seed_keywords = {
    "ìœ„ë¡œ": ["ìœ„ë¡œ", "ë§ˆìŒ", "ë¶ˆì•ˆ", "ì¹˜ìœ "],
    "íœ´ì‹": ["íë§", "íœ´ì‹", "ì‰¼"],
    "ë™ê¸°": ["ë™ê¸°", "ì„±ì¥", "ëª©í‘œ", "ê³µë¶€"],
    "íƒêµ¬": ["í˜¸ê¸°ì‹¬", "ì§ˆë¬¸", "íƒêµ¬", "ë¯¸ë˜"],
}

# =====================================================
# Session State init
# =====================================================
if "submitted" not in st.session_state:
    st.session_state.submitted = False
if "result" not in st.session_state:
    st.session_state.result = None
if "summary_loaded" not in st.session_state:
    st.session_state.summary_loaded = False

for i in range(7):
    if f"q{i+1}" not in st.session_state:
        st.session_state[f"q{i+1}"] = None

def reset_test():
    for i in range(7):
        st.session_state[f"q{i+1}"] = None
    st.session_state.submitted = False
    st.session_state.result = None
    st.session_state.summary_loaded = False

# =====================================================
# Scoring
# =====================================================
def letter_of(ans: str) -> str:
    return ans.strip()[0]

def compute_genre_scores(answers: List[str]) -> Dict[str, int]:
    scores = {g: 0 for g in set(genre_map.values())}
    for a in answers:
        scores[genre_map[letter_of(a)]] += 1
    return scores

def compute_situation_scores(answers: List[str]) -> Dict[str, int]:
    tags = {"ìœ„ë¡œ": 0, "íœ´ì‹": 0, "ë™ê¸°": 0, "íƒêµ¬": 0}
    for qno in [5, 6, 7]:
        l = letter_of(answers[qno - 1])
        for t in situation_tag_map_q5_to_q7[qno].get(l, []):
            tags[t] += 1
    return tags

def ranked(scores: Dict[str, int]):
    return sorted(scores.items(), key=lambda x: x[1], reverse=True)

def top_two(scores: Dict[str, int]) -> List[str]:
    r = ranked(scores)
    if not r:
        return []
    top = [k for k, v in r if v == r[0][1]]
    if len(top) >= 2:
        return top[:2]
    for k, v in r:
        if v < r[0][1]:
            return top + [k]
    return top

def top_list(scores: Dict[str, int]) -> List[str]:
    r = ranked(scores)
    if not r:
        return []
    topv = r[0][1]
    return [k for k, v in r if v == topv]

# =====================================================
# Networking
# =====================================================
def requests_get(url, params=None, timeout=10, retries=1):
    last = None
    for i in range(retries + 1):
        try:
            return requests.get(url, params=params, timeout=timeout)
        except (ReadTimeout, ConnectionError) as e:
            last = e
            if i == retries:
                raise
            time.sleep(0.4 * (2**i))
    raise last

@st.cache_data(show_spinner=False)
def nl_search_raw(cert_key: str, title_query: str, page_no: int, page_size: int, timeout: int, retries: int) -> dict:
    url = "https://www.nl.go.kr/seoji/SearchApi.do"
    params = {
        "cert_key": cert_key,
        "result_style": "json",
        "page_no": page_no,
        "page_size": page_size,
        "title": title_query,
    }
    r = requests_get(url, params=params, timeout=timeout, retries=retries)
    r.raise_for_status()
    try:
        return r.json()
    except Exception:
        return json.loads(r.text)

def _extract_items(nl_json: dict) -> List[dict]:
    if not isinstance(nl_json, dict):
        return []
    for k in ["docs", "data", "items", "result"]:
        if k in nl_json and isinstance(nl_json[k], list):
            return nl_json[k]
    for v in nl_json.values():
        if isinstance(v, list) and v and isinstance(v[0], dict):
            return v
    return []

def _normalize_item(it: dict) -> dict:
    title = (it.get("TITLE") or it.get("title") or "").strip()
    author = (it.get("AUTHOR") or it.get("author") or "").strip()
    publisher = (it.get("PUBLISHER") or it.get("publisher") or "").strip()
    isbn = (it.get("EA_ISBN") or it.get("ISBN") or it.get("isbn") or "").strip()
    cover_url = (it.get("TITLE_URL") or it.get("cover") or it.get("image") or "").strip()
    intro_url = (it.get("BOOK_INTRODUCTION_URL") or "").strip()
    summary_url = (it.get("BOOK_SUMMARY_URL") or "").strip()
    pub_year = (it.get("PUBLISH_PREDATE") or it.get("PUBLISH_DATE") or "").strip()
    pub_year = pub_year[:4] if pub_year else ""
    kdc_name = (it.get("KDC_NAME") or "").strip()
    return {
        "title": title,
        "author": author,
        "publisher": publisher,
        "isbn": isbn,
        "cover_url": cover_url,
        "intro_url": intro_url,
        "summary_url": summary_url,
        "pub_year": pub_year,
        "kdc_name": kdc_name,
        "raw": it,
    }

def _dedup_items(items: List[dict]) -> List[dict]:
    seen = set()
    out = []
    for it in items:
        key = it.get("isbn") or (it.get("title","") + "|" + it.get("author",""))
        key = key.strip()
        if not key or key in seen:
            continue
        seen.add(key)
        out.append(it)
    return out

def build_nl_queries(focus_genres: List[str], top_situations: List[str]) -> List[str]:
    queries = []
    for g in focus_genres[:2]:
        gw = genre_seed_keywords.get(g, [])
        if top_situations:
            sw = situation_seed_keywords.get(top_situations[0], [])
            if gw and sw:
                queries.append(f"{random.choice(sw)} {random.choice(gw)}")
            elif gw:
                queries.append(random.choice(gw))
        elif gw:
            queries.append(random.choice(gw))
    if top_situations:
        sw = situation_seed_keywords.get(top_situations[0], [])
        if sw:
            queries.append(random.choice(sw))
    uniq = []
    for q in queries:
        q = q.strip()
        if q and q not in uniq:
            uniq.append(q)
    return uniq[:3]

def fetch_candidate_pool_from_nl(cert_key: str, focus_genres: List[str], top_situations: List[str], target_pool_size: int, timeout: int, retries: int):
    used_queries = build_nl_queries(focus_genres, top_situations)
    all_items: List[dict] = []
    per_query_page_size = max(10, min(50, target_pool_size // max(1, len(used_queries))))
    per_query_page_size = min(per_query_page_size, 50)

    for q in used_queries:
        try:
            raw = nl_search_raw(cert_key, title_query=q, page_no=1, page_size=per_query_page_size, timeout=timeout, retries=retries)
            items = [_normalize_item(it) for it in _extract_items(raw)]
            all_items.extend(items)
        except Exception:
            continue

    all_items = _dedup_items(all_items)
    if len(all_items) > target_pool_size:
        all_items = all_items[:target_pool_size]
    return all_items, used_queries

# =====================================================
# Lazy summary
# =====================================================
@st.cache_data(show_spinner=False)
def fetch_text_from_url(url: str, max_chars: int = 700, timeout: int = 10, retries: int = 0) -> str:
    if not url:
        return ""
    try:
        r = requests_get(url, params=None, timeout=timeout, retries=retries)
        r.raise_for_status()
        text = r.text
        text = re.sub(r"<script.*?>.*?</script>", " ", text, flags=re.DOTALL | re.IGNORECASE)
        text = re.sub(r"<style.*?>.*?</style>", " ", text, flags=re.DOTALL | re.IGNORECASE)
        text = re.sub(r"<[^>]+>", " ", text)
        text = unescape(text)
        text = re.sub(r"\s+", " ", text).strip()
        return (text[:max_chars].rstrip() + "â€¦") if len(text) > max_chars else text
    except RequestException:
        return ""

def get_summary_for_book(book: dict) -> str:
    s = ""
    if book.get("summary_url"):
        s = fetch_text_from_url(book["summary_url"], timeout=nl_timeout, retries=0)
    if not s and book.get("intro_url"):
        s = fetch_text_from_url(book["intro_url"], timeout=nl_timeout, retries=0)
    return s.strip()

# =====================================================
# OpenAI choose-from-pool (optional)
# =====================================================
@st.cache_data(show_spinner=False)
def call_openai_json(api_key: str, model: str, system: str, user: str) -> dict:
    url = "https://api.openai.com/v1/chat/completions"
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    payload = {
        "model": model,
        "temperature": 0.4,
        "response_format": {"type": "json_object"},
        "messages": [{"role": "system", "content": system}, {"role": "user", "content": user}],
    }
    r = requests.post(url, headers=headers, json=payload, timeout=30)
    r.raise_for_status()
    return json.loads(r.json()["choices"][0]["message"]["content"])

def ai_choose_from_pool(answers: List[str], focus_genres: List[str], top_situations: List[str], pool: List[dict]) -> List[dict]:
    pool_trim = pool[:40]
    brief = []
    for i, b in enumerate(pool_trim):
        brief.append({
            "id": i,
            "title": b.get("title", ""),
            "author": b.get("author", ""),
            "publisher": b.get("publisher", ""),
            "pub_year": b.get("pub_year", ""),
            "isbn": b.get("isbn", ""),
            "kdc_name": b.get("kdc_name", ""),
        })

    system = (
        "ë„ˆëŠ” í•œêµ­ì–´ ë…ì„œ íë ˆì´í„°ë‹¤.\n"
        "ì‚¬ìš©ìì˜ ì„¤ë¬¸(ì„±í–¥+ìƒí™©)ì„ ë°˜ì˜í•´, ì œê³µëœ í›„ë³´ ë¦¬ìŠ¤íŠ¸ ì•ˆì—ì„œë§Œ 3ê¶Œì„ ê³¨ë¼ë¼.\n"
        "ì„œë¡œ ë‹¤ë¥¸ ì±… 3ê¶Œì„ ê³ ë¥´ê³ , ê° ì±…ì— ëŒ€í•´ 1ë¬¸ì¥ book_hook(ì±…ë§ˆë‹¤ ë‹¤ë¥¸ í¬ì¸íŠ¸)ì„ ì‘ì„±í•´ë¼.\n"
        "ì¶œë ¥ì€ JSONë§Œ:\n"
        '{ "picks": [{"id":0,"book_hook":"..."},{"id":1,"book_hook":"..."},{"id":2,"book_hook":"..."}] }\n'
    )
    user = (
        f"focus_genres: {focus_genres}\n"
        f"top_situations: {top_situations}\n"
        "ì‚¬ìš©ì ë‹µë³€:\n" + "\n".join([f"- {a}" for a in answers]) + "\n\n"
        "í›„ë³´ ë¦¬ìŠ¤íŠ¸:\n" + json.dumps({"candidates": brief}, ensure_ascii=False)
    )

    obj = call_openai_json(openai_api_key, openai_model, system, user)
    picks = obj.get("picks", [])

    picked, used = [], set()
    for p in picks:
        try:
            idx = int(p.get("id"))
        except Exception:
            continue
        if idx < 0 or idx >= len(pool_trim) or idx in used:
            continue
        used.add(idx)
        b = dict(pool_trim[idx])
        b["book_hook"] = str(p.get("book_hook", "")).strip()
        picked.append(b)
        if len(picked) == 3:
            break
    return picked

def fallback_choose_from_pool(pool: List[dict]) -> List[dict]:
    def score(b):
        s = 0
        if b.get("isbn"): s += 3
        if b.get("cover_url"): s += 2
        if b.get("pub_year"): s += 1
        if b.get("kdc_name"): s += 1
        s += random.random() * 0.1
        return s

    sorted_pool = sorted(pool, key=score, reverse=True)
    out, seen = [], set()
    for b in sorted_pool:
        key = b.get("isbn") or (b.get("title","") + "|" + b.get("author",""))
        if not key or key in seen:
            continue
        seen.add(key)
        out.append({**b, "book_hook": ""})
        if len(out) == 3:
            break
    return out

# =====================================================
# Reason generation (ì±…ë§ˆë‹¤ ë‹¤ë¥´ê²Œ)
# =====================================================
def rotate_pick(items: List[str], used: set, fallback: str = "") -> str:
    for it in items:
        if it and it not in used:
            used.add(it)
            return it
    return fallback if fallback else (items[0] if items else "")

def pick_focus_tag(top_situations: List[str], idx: int) -> List[str]:
    if not top_situations:
        return []
    if len(top_situations) == 1:
        return top_situations
    if idx == 0:
        return [top_situations[0]]
    if idx == 1:
        return [top_situations[1 % len(top_situations)]]
    return top_situations[:2]

reason_templates = [
    "ìµœê·¼ â€œ{s_ev}â€ë¼ê³  ë‹µí•œ ê±¸ ë³´ë©´ ì§€ê¸ˆì€ **{sit}**ì´(ê°€) í•„ìš”í•´ ë³´ì—¬ìš”. {persona} ì„±í–¥ì¸ ë‹¹ì‹ ì—ê²Œ **{title}**ì€(ëŠ”) {flavor} í¬ì¸íŠ¸ë¡œ ë„ì›€ì´ ë  ìˆ˜ ìˆì–´ìš”. {hook}",
    "ë‹¹ì‹ ì´ ê³ ë¥¸ ë‹µ ì¤‘ â€œ{g_ev}â€ê°€ ëˆˆì— ë„ì–´ìš”. ê·¸ë˜ì„œ {flavor}ì— ê°•í•œ **{title}**ì„(ë¥¼) ê³¨ëê³ , íŠ¹íˆ **{sit}**ì— ì˜ ë§ì„ ê±°ì˜ˆìš”. {hook}",
    "ì§€ê¸ˆì€ **{sit}**ì´(ê°€) ìš°ì„ ì¼ ê²ƒ ê°™ì•„ìš”(â€œ{s_ev}â€). ë™ì‹œì— {persona}ë‹µê²Œ ì½ì„ ë§Œí•œ **{title}**ë¡œ {flavor}ì„(ë¥¼) ì±™ê²¨ë³´ë©´ ì¢‹ì•„ìš”. {hook}",
]

def build_reason(answers: List[str], primary_genre: str, top_situations: List[str], idx: int, book: dict) -> str:
    used_genre_ev = st.session_state.setdefault("_used_genre_ev", set())
    used_sit_ev = st.session_state.setdefault("_used_sit_ev", set())
    used_flavor = st.session_state.setdefault("_used_flavor", set())
    used_tmpl = st.session_state.setdefault("_used_tmpl", set())

    # ê·¼ê±° í›„ë³´
    q1to4 = [answers[i][3:].strip() for i in [0,1,2,3] if answers[i]]
    q5to7 = [answers[i][3:].strip() for i in [4,5,6] if answers[i]]

    focus_tags = pick_focus_tag(top_situations, idx)
    sit_label = ", ".join([tag_display.get(t, t) for t in focus_tags]) if focus_tags else "ì§€ê¸ˆ í•„ìš”í•œ ê²ƒ"

    g_ev = rotate_pick(q1to4, used_genre_ev, fallback=(q1to4[0] if q1to4 else "ì±…ì—ì„œ ì–»ê³  ì‹¶ì€ ê²Œ ìˆë‹¤"))
    s_ev = rotate_pick(q5to7, used_sit_ev, fallback=(q5to7[0] if q5to7 else "ìš”ì¦˜ ì±…ì´ í•„ìš”í•˜ë‹¤"))
    flavor = rotate_pick(genre_flavors.get(primary_genre, []), used_flavor, fallback="í•µì‹¬")
    tmpl = rotate_pick(reason_templates, used_tmpl, fallback=reason_templates[idx % len(reason_templates)])

    hook = book.get("book_hook","").strip()
    hook = f"({hook})" if hook else ""
    persona = genre_persona.get(primary_genre, "ì´ëŸ° ì„±í–¥")

    return tmpl.format(s_ev=s_ev, g_ev=g_ev, sit=sit_label, persona=persona, title=book.get("title",""), flavor=flavor, hook=hook).strip()

# =====================================================
# UI: Questionnaire
# =====================================================
st.divider()
st.subheader("ğŸ“ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”")

for i, q in enumerate(questions):
    st.markdown(f"**{q}**")
    st.radio(label=f"q{i+1}", options=question_choices[i], key=f"q{i+1}", index=None, label_visibility="collapsed")
    st.write("")

st.divider()
c1, c2, c3 = st.columns([1, 1, 1.4])
with c1:
    clicked = st.button("ê²°ê³¼ ë³´ê¸°", type="primary")
with c2:
    st.button("ë‹¤ì‹œ í…ŒìŠ¤íŠ¸í•˜ê¸°", on_click=reset_test)
with c3:
    load_summary_clicked = st.button("ì¤„ê±°ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°(ëŠë¦¼)", help="ê²°ê³¼ê°€ ë‚˜ì˜¨ ë’¤ ëˆŒëŸ¬ì£¼ì„¸ìš”. (ì§€ì—° ë¡œë”©)")

if load_summary_clicked:
    st.session_state.summary_loaded = True

# =====================================================
# Flow
# =====================================================
if clicked:
    answers = [st.session_state[f"q{i+1}"] for i in range(7)]

    # âœ… resultëŠ” í•­ìƒ ê¸°ë³¸ ìŠ¤í‚¤ë§ˆë¡œ ì´ˆê¸°í™” (KeyError ë°©ì§€)
    st.session_state.result = {
        "answers": answers,
        "genre_scores": {},
        "situation_scores": {},
        "focus_genres": [],
        "top_situations": [],
        "used_queries": [],
        "pool_count": 0,
        "used_ai": False,
        "picked": [],
        "raw_first_pool_item": None,
        "error": "",
    }

    if any(a is None for a in answers):
        missing = [str(i + 1) for i, a in enumerate(answers) if a is None]
        st.session_state.result["error"] = f"ëª¨ë“  ì§ˆë¬¸ì— ë‹µë³€í•´ ì£¼ì„¸ìš”! (ë¯¸ì‘ë‹µ: {', '.join(missing)}ë²ˆ)"
        st.session_state.submitted = True
    elif not nl_api_key:
        st.session_state.result["error"] = "êµ­ë¦½ì¤‘ì•™ë„ì„œê´€ API í‚¤(cert_key)ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì— ì…ë ¥í•´ ì£¼ì„¸ìš”."
        st.session_state.submitted = True
    else:
        with st.spinner("ë¶„ì„ + í›„ë³´ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
            genre_scores = compute_genre_scores(answers)
            situation_scores = compute_situation_scores(answers)

            focus_genres = top_two(genre_scores)
            top_situations = top_list(situation_scores)

            pool, used_queries = fetch_candidate_pool_from_nl(
                cert_key=nl_api_key,
                focus_genres=focus_genres,
                top_situations=top_situations,
                target_pool_size=pool_size,
                timeout=nl_timeout,
                retries=nl_retries,
            )

            st.session_state.result.update({
                "genre_scores": genre_scores,
                "situation_scores": situation_scores,
                "focus_genres": focus_genres,
                "top_situations": top_situations,
                "used_queries": used_queries,
                "pool_count": len(pool),
                "raw_first_pool_item": pool[0].get("raw") if pool else None,
            })

            if not pool:
                st.session_state.result["error"] = "í›„ë³´ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆì–´ìš”. (í‚¤/ë„¤íŠ¸ì›Œí¬/ì¿¼ë¦¬ ë¬¸ì œ ê°€ëŠ¥)"
            else:
                picked = []
                used_ai = False
                if openai_api_key:
                    try:
                        picked = ai_choose_from_pool(answers, focus_genres, top_situations, pool)
                        if len(picked) == 3:
                            used_ai = True
                        else:
                            picked = fallback_choose_from_pool(pool)
                            used_ai = False
                    except Exception:
                        picked = fallback_choose_from_pool(pool)
                        used_ai = False
                else:
                    picked = fallback_choose_from_pool(pool)
                    used_ai = False

                # ì¤„ê±°ë¦¬ ë¡œë”©
                if fetch_summary_default or st.session_state.summary_loaded:
                    for b in picked:
                        b["summary"] = get_summary_for_book(b)
                else:
                    for b in picked:
                        b["summary"] = ""

                # ì¶”ì²œ ì´ìœ  ìƒì„± (genreëŠ” ìƒìœ„ 1ê°œë¡œ í†µì¼)
                primary_genre = focus_genres[0] if focus_genres else "ì†Œì„¤"
                # used set ì´ˆê¸°í™”
                st.session_state["_used_genre_ev"] = set()
                st.session_state["_used_sit_ev"] = set()
                st.session_state["_used_flavor"] = set()
                st.session_state["_used_tmpl"] = set()

                for idx, b in enumerate(picked):
                    b["genre"] = primary_genre
                    b["why"] = build_reason(answers, primary_genre, top_situations, idx, b)

                st.session_state.result.update({
                    "picked": picked,
                    "used_ai": used_ai,
                })

        st.session_state.submitted = True

# =====================================================
# Render
# =====================================================
if st.session_state.submitted and st.session_state.result:
    r = st.session_state.result

    if r.get("error"):
        st.error(r["error"])
    else:
        st.subheader("ğŸ“Œ ë¶„ì„ ê²°ê³¼")
        focus_genres = r.get("focus_genres", [])
        top_situations = r.get("top_situations", [])

        st.success(f"ë…ì„œ ì„±í–¥(ìƒìœ„): {', '.join(focus_genres) if focus_genres else 'â€”'}")
        sit_text = ", ".join([tag_display.get(t, t) for t in top_situations]) if top_situations else "â€”"
        st.info(f"í˜„ì¬ í•„ìš”í•œ ê²ƒ(ìƒìœ„): **{sit_text}**")

        used_queries = r.get("used_queries", [])
        st.caption(f"êµ­ë¦½ì¤‘ì•™ë„ì„œê´€ ê²€ìƒ‰ í‚¤ì›Œë“œ: {', '.join(used_queries) if used_queries else 'â€”'} Â· í›„ë³´ {r.get('pool_count',0)}ê¶Œ í™•ë³´")

        if r.get("used_ai"):
            st.caption("âœ… AIê°€ í›„ë³´ ë¦¬ìŠ¤íŠ¸ ì¤‘ì—ì„œ 3ê¶Œì„ ì„ íƒí–ˆìŠµë‹ˆë‹¤.")
        else:
            st.caption("â„¹ï¸ AI ë¯¸ì‚¬ìš©/ì‹¤íŒ¨ë¡œ ê·œì¹™ ê¸°ë°˜ ì„ íƒì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.")

        if debug_show_raw and r.get("raw_first_pool_item"):
            with st.expander("ğŸ§ª í›„ë³´ 1ê°œ raw JSON"):
                st.json(r["raw_first_pool_item"])

        st.subheader("ğŸ“š ì¶”ì²œ ë„ì„œ 3ê¶Œ")
        for i, b in enumerate(r.get("picked", []), start=1):
            st.markdown(f"### {i}. {b.get('title','')}")
            meta = []
            if b.get("author"): meta.append(f"ì €ì: {b['author']}")
            if b.get("publisher"): meta.append(f"ì¶œíŒì‚¬: {b['publisher']}")
            if b.get("pub_year"): meta.append(f"ë°œí–‰: {b['pub_year']}")
            if b.get("isbn"): meta.append(f"ISBN: {b['isbn']}")
            if meta:
                st.caption(" Â· ".join(meta))

            cols = st.columns([1, 2])
            with cols[0]:
                if b.get("cover_url"):
                    st.image(b["cover_url"], use_container_width=True)
                else:
                    st.info("í‘œì§€ ì´ë¯¸ì§€ ì—†ìŒ(ë°ì´í„° ë¯¸ì œê³µ)")

            with cols[1]:
                st.write("**ì¶”ì²œ ì´ìœ (ì„¤ë¬¸ ê·¼ê±° + ì±…ë³„ í¬ì¸íŠ¸)**")
                st.write(f"- {b.get('why','')}")

                st.write("**ì¤„ê±°ë¦¬/ì±…ì†Œê°œ**")
                if b.get("summary"):
                    st.write(b["summary"])
                else:
                    st.info("ì¤„ê±°ë¦¬ ë¯¸ë¡œë”©(â€˜ì¤„ê±°ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°â€™ ë²„íŠ¼ìœ¼ë¡œ ì§€ì—° ë¡œë”©) ë˜ëŠ” ì œê³µ URL ì—†ìŒ")

            st.divider()
