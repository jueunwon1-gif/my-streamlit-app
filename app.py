import json
import random
import re
from html import unescape

import requests
import streamlit as st

st.set_page_config(page_title="ë‚˜ì™€ ì–´ìš¸ë¦¬ëŠ” ì±…ì€?", page_icon="ğŸ“š", layout="centered")

# =====================================================
# Sidebar: API Keys / Options
# =====================================================
st.sidebar.header("ğŸ”‘ API ì„¤ì •")

nl_api_key = st.sidebar.text_input(
    "êµ­ë¦½ì¤‘ì•™ë„ì„œê´€(ISBN ì„œì§€ì •ë³´) API Key (cert_key)",
    type="password",
    help="êµ­ë¦½ì¤‘ì•™ë„ì„œê´€ ISBN ì„œì§€ì •ë³´ API cert_key ê°’ì„ ì…ë ¥í•˜ì„¸ìš”.",
)

openai_api_key = st.sidebar.text_input(
    "OpenAI API Key (ì„ íƒ)",
    type="password",
    help="AIê°€ ë„ì„œ í›„ë³´(ë„ì„œëª…/ì €ì)ë¥¼ ë” ë‹¤ì–‘í•˜ê²Œ ì¶”ì²œí•˜ë„ë¡ í•˜ë ¤ë©´ í•„ìš”í•©ë‹ˆë‹¤. ì—†ìœ¼ë©´ ë°ëª¨ ì¶”ì²œ ëª©ë¡ìœ¼ë¡œ ë™ì‘í•©ë‹ˆë‹¤.",
)
openai_model = st.sidebar.text_input("OpenAI ëª¨ë¸", value="gpt-4o-mini")

demo_mode = st.sidebar.checkbox(
    "ë°ëª¨ ëª¨ë“œ(êµ­ë¦½ì¤‘ì•™ë„ì„œê´€ API ì—†ì´ë„ ê²°ê³¼ ë³´ê¸°)",
    value=True,
    help="API Keyê°€ ì—†ì–´ë„ ì¥ë¥´ ë¶„ì„ + ì¶”ì²œ 3ê¶Œ + ê°œì¸í™” ì´ìœ (ì„¤ë¬¸ ê·¼ê±°)ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
)

st.title("ğŸ“š ë‚˜ì™€ ì–´ìš¸ë¦¬ëŠ” ì±…ì€?")
st.write(
    "7ë¬¸í•­ ì‹¬ë¦¬í…ŒìŠ¤íŠ¸ë¡œ **ì„±í–¥(ì¥ë¥´ ì·¨í–¥)**ê³¼ **í˜„ì¬ ìƒí™©(ë¬´ì—‡ì´ í•„ìš”í•œì§€)**ì„ í•¨ê»˜ íŒŒì•…í•´ "
    "ë‹¹ì‹ ì—ê²Œ ë§ëŠ” ì±… 3ê¶Œì„ ì¶”ì²œí•´ë“œë¦½ë‹ˆë‹¤.\n\n"
    "- êµ­ë¦½ì¤‘ì•™ë„ì„œê´€ API í‚¤ê°€ ìˆìœ¼ë©´: **í‘œì§€/ISBN/ì†Œê°œ**ê¹Œì§€ ì‹¤ì œ ë°ì´í„°ë¡œ í‘œì‹œ\n"
    "- ì—†ìœ¼ë©´(ë°ëª¨ ëª¨ë“œ): ì¶”ì²œ/ì´ìœ  ì¤‘ì‹¬ìœ¼ë¡œ ë¨¼ì € í™•ì¸ ê°€ëŠ¥"
)

# =====================================================
# New Questionnaire (ì„±í–¥ + ìƒí™©)
#   - Q1~Q4: ì„±í–¥ ì¤‘ì‹¬
#   - Q5~Q7: ìƒí™© ì¤‘ì‹¬
# =====================================================
questions = [
    "1) ìƒˆë¡œìš´ ì±…ì„ ê³ ë¥¼ ë•Œ ê°€ì¥ ëŒë¦¬ëŠ” ìš”ì†ŒëŠ”?",
    "2) ì¹œêµ¬ê°€ ì±… ì¶”ì²œì„ ë¶€íƒí•˜ë©´ ë‚˜ëŠ” ë³´í†µâ€¦",
    "3) ë‚´ê°€ ì±…ì„ ì½ì„ ë•Œ ê°€ì¥ ë§Œì¡±ìŠ¤ëŸ¬ìš´ ìˆœê°„ì€?",
    "4) í‰ì†Œ ë‚´ê°€ ê°€ì¥ ìì£¼ ê´€ì‹¬ì„ ê°–ëŠ” ì£¼ì œëŠ”?",
    "5) ìš”ì¦˜ ë‚˜ì—ê²Œ ê°€ì¥ í•„ìš”í•œ ê²ƒì€?",
    "6) ìµœê·¼ ë‚´ê°€ ì±…ì„ ì°¾ê²Œ ë˜ëŠ” ì´ìœ ëŠ”?",
    "7) ì§€ê¸ˆ ë‹¹ì¥ ì±…ì´ ë‚´ê²Œ í•´ì¤¬ìœ¼ë©´ í•˜ëŠ” ì—­í• ì€?",
]

question_choices = [
    [
        "A. ì½ê³  ë‚˜ì„œ ë°”ë¡œ ì‹¤ì²œí•  ìˆ˜ ìˆëŠ” ì¡°ì–¸",
        "B. ì‚¶ì— ëŒ€í•œ ê¹Šì€ ì§ˆë¬¸ê³¼ í†µì°°",
        "C. ìƒˆë¡œìš´ ì§€ì‹ê³¼ ê¸°ìˆ ì„ ë°°ìš°ëŠ” ì¬ë¯¸",
        "D. ì‚¬íšŒì™€ ì‹œëŒ€ë¥¼ ì´í•´í•˜ëŠ” ê´€ì ",
        "E. ê°ì •ì ìœ¼ë¡œ ëª°ì…í•  ìˆ˜ ìˆëŠ” ì´ì•¼ê¸°",
    ],
    [
        "A. ë„ì›€ì´ ë  ë§Œí•œ í˜„ì‹¤ì ì¸ ì±…ì„ ì¶”ì²œí•œë‹¤",
        "B. ìƒê°ì„ ë„“í˜€ì¤„ ì±…ì„ ì¶”ì²œí•œë‹¤",
        "C. ì‹ ê¸°í•œ ì •ë³´ë¥¼ ì£¼ëŠ” ì±…ì„ ì¶”ì²œí•œë‹¤",
        "D. ì„¸ìƒì„ ì´í•´í•˜ê²Œ í•´ì£¼ëŠ” ì±…ì„ ì¶”ì²œí•œë‹¤",
        "E. ì¬ë¯¸ìˆê²Œ ì½íˆëŠ” ì±…ì„ ì¶”ì²œí•œë‹¤",
    ],
    [
        "A. â€œì´ê±´ ë‚´ ì‚¶ì— ë°”ë¡œ ì ìš©í•  ìˆ˜ ìˆê² ë‹¤â€ ëŠë‚„ ë•Œ",
        "B. â€œì„¸ìƒì„ ë³´ëŠ” ì‹œì•¼ê°€ ë„“ì–´ì¡Œë‹¤â€ ëŠë‚„ ë•Œ",
        "C. â€œìƒˆë¡œìš´ ì‚¬ì‹¤ì„ ë°°ì› ë‹¤â€ ëŠë‚„ ë•Œ",
        "D. â€œì‚¬íšŒë‚˜ ì—­ì‚¬ë¥¼ ì´í•´í•˜ê²Œ ëë‹¤â€ ëŠë‚„ ë•Œ",
        "E. â€œì™„ì „íˆ ëª°ì…í•´ì„œ ê°ì •ì´ ì›€ì§ì˜€ë‹¤â€ ëŠë‚„ ë•Œ",
    ],
    [
        "A. ì„±ì¥, ëª©í‘œ, ìê¸°ê´€ë¦¬",
        "B. ì¸ê°„ê´€ê³„, ì‚¶ì˜ ì˜ë¯¸",
        "C. ë¯¸ë˜ê¸°ìˆ , ê³¼í•™, ë°ì´í„°",
        "D. ì‚¬íšŒë¬¸ì œ, ì—­ì‚¬ì  ì‚¬ê±´",
        "E. ê°ì •, ì´ì•¼ê¸°, ìƒìƒ ì† ì„¸ê³„",
    ],
    [
        "A. ë‹¤ì‹œ ë™ê¸°ë¶€ì—¬í•˜ê³  ë°©í–¥ì„ ì¡ëŠ” ê²ƒ",
        "B. ë‚´ ë§ˆìŒì„ ì •ë¦¬í•  ìˆ˜ ìˆëŠ” í†µì°°",
        "C. ë¨¸ë¦¬ë¥¼ ìê·¹í•˜ëŠ” ìƒˆë¡œìš´ í˜¸ê¸°ì‹¬",
        "D. í˜„ì‹¤ì„ ì´í•´í•˜ê³  ì‹œì•¼ë¥¼ ë„“íˆëŠ” ê´€ì ",
        "E. ìœ„ë¡œë°›ê³  ê°ì •ì„ ì‰¬ê²Œ í•˜ëŠ” ì´ì•¼ê¸°",
    ],
    [
        "A. ë¯¸ë˜ ì¤€ë¹„ë‚˜ ìê¸°ê³„ë°œì´ í•„ìš”í•´ì„œ",
        "B. ë³µì¡í•œ ê°ì •ì„ ì •ë¦¬í•˜ê³  ì‹¶ì–´ì„œ",
        "C. ìƒˆë¡œìš´ ë¶„ì•¼ë¥¼ ë°°ìš°ê³  ì‹¶ì–´ì„œ",
        "D. ì‚¬íšŒì™€ ì„¸ìƒ íë¦„ì´ ê¶ê¸ˆí•´ì„œ",
        "E. ì§€ì¹˜ê³  ì‰¬ê³  ì‹¶ì–´ì„œ",
    ],
    [
        "A. â€œì•ìœ¼ë¡œ ë­˜ í•´ì•¼ í• ì§€ ì•Œë ¤ì£¼ëŠ” ë‚˜ì¹¨ë°˜â€",
        "B. â€œìƒê°ì„ ì •ë¦¬í•´ì£¼ëŠ” ëŒ€í™” ìƒëŒ€â€",
        "C. â€œìƒˆë¡œìš´ ì„¸ìƒì„ ë³´ì—¬ì£¼ëŠ” ì°½ë¬¸â€",
        "D. â€œí˜„ì‹¤ì„ ì´í•´í•˜ê²Œ í•´ì£¼ëŠ” ì§€ë„â€",
        "E. â€œë§ˆìŒì„ ì‰¬ê²Œ í•´ì£¼ëŠ” íœ´ì‹ì²˜â€",
    ],
]

# =====================================================
# Genre mapping (A~E)
# =====================================================
genre_map = {"A": "ìê¸°ê³„ë°œ", "B": "ì¸ë¬¸/ì² í•™", "C": "ê³¼í•™/IT", "D": "ì—­ì‚¬/ì‚¬íšŒ", "E": "ì†Œì„¤"}

genre_persona = {
    "ìê¸°ê³„ë°œ": "ì‹¤í–‰Â·ë£¨í‹´Â·ì„±ê³¼ë¥¼ ì¤‘ì‹œí•˜ëŠ” ì„±ì¥í˜•",
    "ì¸ë¬¸/ì² í•™": "ì˜ë¯¸Â·ê°€ì¹˜Â·ìê¸°ì´í•´ë¥¼ ê¹Šê²Œ íŒŒê³ ë“œëŠ” ì„±ì°°í˜•",
    "ê³¼í•™/IT": "ì›ë¦¬Â·êµ¬ì¡°Â·ì •ë³´ë¥¼ ë¶„ì„í•˜ëŠ” íƒêµ¬í˜•",
    "ì—­ì‚¬/ì‚¬íšŒ": "ì‚¬íšŒ êµ¬ì¡°Â·ë§¥ë½Â·íë¦„ì„ ì´í•´í•˜ë ¤ëŠ” ê´€ì°°í˜•",
    "ì†Œì„¤": "ê°ì •Â·ë¶„ìœ„ê¸°Â·ì„œì‚¬ ëª°ì…ì„ í†µí•´ íšŒë³µí•˜ëŠ” ê°ì„±í˜•",
}

# ìƒí™© íƒœê·¸(ìœ„ë¡œ/íœ´ì‹/ë™ê¸°/íƒêµ¬) ì ìˆ˜í™”: Q5~Q7 ê¸°ì¤€
# - ìœ„ë¡œ: ê°ì • ìœ„ë¡œ/ì •ì„œì  ì•ˆì •
# - íœ´ì‹: ì‰¬ê³  ì‹¶ìŒ/íšŒë³µ
# - ë™ê¸°: ë°©í–¥/ë™ê¸°ë¶€ì—¬/ì‹¤í–‰
# - íƒêµ¬: í˜¸ê¸°ì‹¬/ì§€ì‹ íƒìƒ‰/ì„¸ìƒ ì´í•´
situation_tag_map_q5_to_q7 = {
    # Q5
    5: {
        "A": ["ë™ê¸°"],
        "B": ["ìœ„ë¡œ"],
        "C": ["íƒêµ¬"],
        "D": ["íƒêµ¬"],
        "E": ["ìœ„ë¡œ", "íœ´ì‹"],
    },
    # Q6
    6: {
        "A": ["ë™ê¸°"],
        "B": ["ìœ„ë¡œ"],
        "C": ["íƒêµ¬"],
        "D": ["íƒêµ¬"],
        "E": ["íœ´ì‹", "ìœ„ë¡œ"],
    },
    # Q7
    7: {
        "A": ["ë™ê¸°"],
        "B": ["ìœ„ë¡œ"],
        "C": ["íƒêµ¬"],
        "D": ["íƒêµ¬"],
        "E": ["íœ´ì‹", "ìœ„ë¡œ"],
    },
}

tag_display = {
    "ë™ê¸°": "ë°©í–¥/ë™ê¸°ë¶€ì—¬",
    "ìœ„ë¡œ": "ê°ì • ì •ë¦¬/ìœ„ë¡œ",
    "íœ´ì‹": "íœ´ì‹/íšŒë³µ",
    "íƒêµ¬": "í˜¸ê¸°ì‹¬/íƒêµ¬",
}

# =====================================================
# Demo fallback pool
# =====================================================
fallback_pool = {
    "ìê¸°ê³„ë°œ": [
        {"title": "ì•„ì£¼ ì‘ì€ ìŠµê´€ì˜ í˜", "author": "ì œì„ìŠ¤ í´ë¦¬ì–´"},
        {"title": "ê·¸ë¦¿", "author": "ì•¤ì ˆë¼ ë”í¬ì›ŒìŠ¤"},
        {"title": "ë”¥ ì›Œí¬", "author": "ì¹¼ ë‰´í¬íŠ¸"},
        {"title": "ì›ì”½", "author": "ê²Œë¦¬ ì¼ˆëŸ¬"},
        {"title": "ë¯¸ë¼í´ ëª¨ë‹", "author": "í•  ì—˜ë¡œë“œ"},
    ],
    "ì¸ë¬¸/ì² í•™": [
        {"title": "ì •ì˜ë€ ë¬´ì—‡ì¸ê°€", "author": "ë§ˆì´í´ ìƒŒë¸"},
        {"title": "ì£½ìŒì˜ ìˆ˜ìš©ì†Œì—ì„œ", "author": "ë¹…í„° í”„ë­í´"},
        {"title": "ì†Œí¬ë¼í…ŒìŠ¤ ìµìŠ¤í”„ë ˆìŠ¤", "author": "ì—ë¦­ ì™€ì´ë„ˆ"},
        {"title": "ì² í•™ì€ ì–´ë–»ê²Œ ì‚¶ì˜ ë¬´ê¸°ê°€ ë˜ëŠ”ê°€", "author": "ì•¼ë§ˆêµ¬ì¹˜ ìŠˆ"},
        {"title": "ì‚¬í”¼ì—”ìŠ¤", "author": "ìœ ë°œ í•˜ë¼ë¦¬"},
    ],
    "ê³¼í•™/IT": [
        {"title": "ì½”ìŠ¤ëª¨ìŠ¤", "author": "ì¹¼ ì„¸ì´ê±´"},
        {"title": "íŒ©íŠ¸í’€ë‹ˆìŠ¤", "author": "í•œìŠ¤ ë¡œìŠ¬ë§"},
        {"title": "í´ë¦° ì½”ë“œ", "author": "ë¡œë²„íŠ¸ C. ë§ˆí‹´"},
        {"title": "AI 2041", "author": "ì¹´ì´í‘¸ ë¦¬, ì²œì¹˜ìš°íŒ"},
        {"title": "ì´ê¸°ì  ìœ ì „ì", "author": "ë¦¬ì²˜ë“œ ë„í‚¨ìŠ¤"},
    ],
    "ì—­ì‚¬/ì‚¬íšŒ": [
        {"title": "ì´, ê· , ì‡ ", "author": "ì¬ë ˆë“œ ë‹¤ì´ì•„ëª¬ë“œ"},
        {"title": "ë„›ì§€", "author": "ë¦¬ì²˜ë“œ íƒˆëŸ¬, ìºìŠ¤ ì„ ìŠ¤íƒ€ì¸"},
        {"title": "ì—­ì‚¬ì˜ ì“¸ëª¨", "author": "ìµœíƒœì„±"},
        {"title": "21ì„¸ê¸° ìë³¸", "author": "í† ë§ˆ í”¼ì¼€í‹°"},
        {"title": "ì •ì¹˜ì˜ ì‹¬ë¦¬í•™", "author": "ë“œë£¨ ì›¨ìŠ¤í„´"},
    ],
    "ì†Œì„¤": [
        {"title": "ë‚˜ë¯¸ì•¼ ì¡í™”ì ì˜ ê¸°ì ", "author": "íˆê°€ì‹œë…¸ ê²Œì´ê³ "},
        {"title": "ë¶ˆí¸í•œ í¸ì˜ì ", "author": "ê¹€í˜¸ì—°"},
        {"title": "1984", "author": "ì¡°ì§€ ì˜¤ì›°"},
        {"title": "ë‹¬ëŸ¬êµ¬íŠ¸ ê¿ˆ ë°±í™”ì ", "author": "ì´ë¯¸ì˜ˆ"},
        {"title": "ë°ë¯¸ì•ˆ", "author": "í—¤ë¥´ë§Œ í—¤ì„¸"},
    ],
}

# =====================================================
# Session State init
# =====================================================
if "submitted" not in st.session_state:
    st.session_state.submitted = False
if "result" not in st.session_state:
    st.session_state.result = None

for i in range(7):
    key = f"q{i+1}"
    if key not in st.session_state:
        st.session_state[key] = None


def reset_test():
    for i in range(7):
        st.session_state[f"q{i+1}"] = None
    st.session_state.submitted = False
    st.session_state.result = None


# =====================================================
# Helpers: scoring
# =====================================================
def letter_of(answer: str) -> str:
    return answer.strip()[0]


def compute_genre_scores(answers):
    scores = {g: 0 for g in genre_map.values()}
    for ans in answers:
        scores[genre_map[letter_of(ans)]] += 1
    return scores


def compute_situation_scores(answers):
    """
    Q5~Q7ë§Œ ìƒí™© íƒœê·¸ ì ìˆ˜í™”.
    answers ì¸ë±ìŠ¤: 0~6 (Q1~Q7)
    """
    tags = {"ìœ„ë¡œ": 0, "íœ´ì‹": 0, "ë™ê¸°": 0, "íƒêµ¬": 0}
    for qno in [5, 6, 7]:
        ans = answers[qno - 1]
        letter = letter_of(ans)
        for t in situation_tag_map_q5_to_q7[qno].get(letter, []):
            tags[t] += 1
    return tags


def get_ranked(scores: dict):
    return sorted(scores.items(), key=lambda x: x[1], reverse=True)


def top_keys(scores: dict):
    ranked = get_ranked(scores)
    max_score = ranked[0][1]
    top = [k for k, v in ranked if v == max_score]
    # second tier
    second_score = None
    for k, v in ranked:
        if v < max_score:
            second_score = v
            break
    second = [k for k, v in ranked if second_score is not None and v == second_score]
    return top, second, ranked


# =====================================================
# Recommend 3 books: (demo) mix by top genre(s)
# =====================================================
def pick_3_books(primary_genres, secondary_genres):
    """
    - 1ë“± ë™ì (ë³µí•©): 1ë“± ì¥ë¥´ë“¤ì—ì„œ ì„ì–´ì„œ 3ê¶Œ
    - ë‹¨ì¼ 1ë“± + 2ë“± ì¡´ì¬: 1ë“± 2ê¶Œ + 2ë“± 1ê¶Œ
    - ë‹¨ì¼ 1ë“±: 3ê¶Œ
    """
    books = []

    if len(primary_genres) >= 2:
        pool = []
        for g in primary_genres:
            pool += [{"genre": g, **b} for b in fallback_pool[g]]
        random.shuffle(pool)
        seen = set()
        for item in pool:
            if item["title"] in seen:
                continue
            books.append(item)
            seen.add(item["title"])
            if len(books) == 3:
                break
        return books

    primary = primary_genres[0]
    if secondary_genres:
        secondary = secondary_genres[0]
        p = random.sample(fallback_pool[primary], k=min(2, len(fallback_pool[primary])))
        s = random.sample(fallback_pool[secondary], k=1)
        books = [{"genre": primary, **b} for b in p] + [{"genre": secondary, **b} for b in s]
        random.shuffle(books)
        return books[:3]

    return [{"genre": primary, **b} for b in random.sample(fallback_pool[primary], k=3)]


# =====================================================
# Evidence-based ì´ìœ  ìƒì„± (ì„±í–¥ + ìƒí™© ë°˜ì˜)
# =====================================================
def evidence_by_genre(answers, target_genre, max_evidence=2):
    target_letter = None
    for letter, g in genre_map.items():
        if g == target_genre:
            target_letter = letter
            break

    matched = [a for a in answers if letter_of(a) == target_letter]
    cleaned = [m[3:].strip() if len(m) > 3 else m.strip() for m in matched]
    random.shuffle(cleaned)
    return cleaned[:max_evidence]


def evidence_by_situation(answers, top_situation_tags, max_evidence=2):
    """
    top_situation_tags: ì˜ˆ) ["íœ´ì‹"] ë˜ëŠ” ["ìœ„ë¡œ","íœ´ì‹"]
    Q5~Q7 ë‹µë³€ì—ì„œ í•´ë‹¹ ìƒí™© íƒœê·¸ë¥¼ ë§Œë“¤ì–´ë‚¸ ë¬¸í•­ë§Œ ê·¼ê±°ë¡œ ë½‘ìŒ
    """
    evidences = []
    for qno in [5, 6, 7]:
        ans = answers[qno - 1]
        letter = letter_of(ans)
        tags = situation_tag_map_q5_to_q7[qno].get(letter, [])
        if any(t in top_situation_tags for t in tags):
            evidences.append(ans[3:].strip() if len(ans) > 3 else ans.strip())

    # ì¤‘ë³µ/ê¸¸ì´ ë°©ì§€
    random.shuffle(evidences)
    return evidences[:max_evidence]


def build_reason(answers, book_title, book_genre, top_situation_tags):
    """
    - ì¥ë¥´ ê·¼ê±° 1~2ê°œ + ìƒí™© ê·¼ê±° 1ê°œë¥¼ ì¡°í•©í•´ ê°œì¸í™” ë¬¸ì¥ ìƒì„±
    """
    genre_ev = evidence_by_genre(answers, book_genre, max_evidence=2)
    situa_ev = evidence_by_situation(answers, top_situation_tags, max_evidence=1)

    persona = genre_persona.get(book_genre, "")
    point = genre_book_point.get(book_genre, "")

    situa_phrase = ", ".join([tag_display.get(t, t) for t in top_situation_tags])

    parts = []

    if situa_ev:
        parts.append(f"ë‹¹ì‹ ì€ ìµœê·¼ â€œ{situa_ev[0]}â€ë¼ê³  ë‹µí•´ **{situa_phrase}**ê°€ í•„ìš”í•œ ìƒíƒœë¡œ ë³´ì—¬ìš”.")
    else:
        parts.append(f"ì§€ê¸ˆì€ **{situa_phrase}**ì— ë„ì›€ì´ ë˜ëŠ” ì±…ì´ ì˜ ë§ëŠ” ì‹œì ì´ì—ìš”.")

    if genre_ev:
        if len(genre_ev) >= 2:
            parts.append(f"ë˜ â€œ{genre_ev[0]}â€, â€œ{genre_ev[1]}â€ë¥¼ ê³ ë¥¸ ê±¸ ë³´ë©´ {persona} ì„±í–¥ë„ ê°•í•´ìš”.")
        else:
            parts.append(f"ë˜ â€œ{genre_ev[0]}â€ë¥¼ ì„ íƒí•œ ê±¸ ë³´ë©´ {persona} ì„±í–¥ë„ ê°•í•´ìš”.")
    else:
        parts.append(f"{persona} ì„±í–¥ì„ ë°”íƒ•ìœ¼ë¡œ ì±…ì„ ê³¨ëì–´ìš”.")

    parts.append(f"ê·¸ë˜ì„œ {point}ë¥¼ ì£¼ëŠ” **{book_title}**ì„(ë¥¼) ì¶”ì²œí•©ë‹ˆë‹¤.")
    return " ".join(parts)


# =====================================================
# OpenAI: optional book candidate generation
#  - ì´ìœ ëŠ” ìš°ë¦¬ê°€ (ì„¤ë¬¸ ê·¼ê±° ê¸°ë°˜) ìƒì„±
# =====================================================
@st.cache_data(show_spinner=False)
def call_openai_json(api_key: str, model: str, system: str, user: str) -> dict:
    url = "https://api.openai.com/v1/chat/completions"
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    payload = {
        "model": model,
        "temperature": 0.7,
        "response_format": {"type": "json_object"},
        "messages": [{"role": "system", "content": system}, {"role": "user", "content": user}],
    }
    r = requests.post(url, headers=headers, json=payload, timeout=30)
    r.raise_for_status()
    return json.loads(r.json()["choices"][0]["message"]["content"])


def ai_pick_books(answers, focus_genres):
    system = (
        "ë„ˆëŠ” í•œêµ­ì–´ ë…ì„œ íë ˆì´í„°ë‹¤. ì‚¬ìš©ìì˜ ì„¤ë¬¸ ì‘ë‹µ(ì„±í–¥+ìƒí™©)ì„ ë°”íƒ•ìœ¼ë¡œ "
        "ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” ì±… 3ê¶Œì„ ì¶”ì²œí•˜ë˜, ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ë¼.\n\n"
        "{\n"
        '  "recommendations": [\n'
        '    {"title":"ë„ì„œëª…", "author":"ì €ì(ëª¨ë¥´ë©´ ë¹ˆ ë¬¸ìì—´)", "genre":"ìê¸°ê³„ë°œ|ì¸ë¬¸/ì² í•™|ê³¼í•™/IT|ì—­ì‚¬/ì‚¬íšŒ|ì†Œì„¤"}\n'
        "  ]\n"
        "}\n\n"
        "ê·œì¹™:\n"
        "- focus_genresì— ìµœëŒ€í•œ ë§ì¶° ì¶”ì²œ\n"
        "- ëŒ€í•™ìƒì´ ì½ê¸° ë¬´ë‚œí•œ ë‚œì´ë„ ìš°ì„ \n"
        "- ë„ì„œëª…ì€ ì‹¤ì œ ì¡´ì¬ ì±…\n"
        "- genreëŠ” ë°˜ë“œì‹œ 5ê°œ ì¤‘ í•˜ë‚˜\n"
    )
    user = (
        f"focus_genres: {focus_genres}\n"
        "ì‚¬ìš©ì ë‹µë³€(ì›ë¬¸):\n"
        + "\n".join([f"- {a}" for a in answers])
        + "\n\n"
        "ì¶”ì²œ JSONì„ ë§Œë“¤ì–´ì¤˜."
    )
    obj = call_openai_json(openai_api_key, openai_model, system, user)
    recs = obj.get("recommendations", [])[:3]

    cleaned = []
    for r in recs:
        title = str(r.get("title", "")).strip()
        author = str(r.get("author", "")).strip()
        genre = str(r.get("genre", "")).strip()
        if genre not in genre_map.values():
            genre = focus_genres[0]
        if title:
            cleaned.append({"title": title, "author": author, "genre": genre})

    return cleaned[:3]


# =====================================================
# National Library (ISBN ì„œì§€ì •ë³´) API helpers
# =====================================================
@st.cache_data(show_spinner=False)
def nl_isbn_search(cert_key: str, title: str, author: str = "", page_size: int = 10):
    url = "https://www.nl.go.kr/seoji/SearchApi.do"
    params = {
        "cert_key": cert_key,
        "result_style": "json",
        "page_no": 1,
        "page_size": page_size,
        "title": title,
    }
    if author:
        params["author"] = author

    r = requests.get(url, params=params, timeout=30)
    r.raise_for_status()
    try:
        return r.json()
    except Exception:
        return json.loads(r.text)


def pick_best_item(nl_json, wanted_title: str):
    items = None
    if isinstance(nl_json, dict):
        for k in ["docs", "data", "items", "result"]:
            if k in nl_json and isinstance(nl_json[k], list):
                items = nl_json[k]
                break
        if items is None:
            for v in nl_json.values():
                if isinstance(v, list) and v and isinstance(v[0], dict):
                    items = v
                    break

    if not items:
        return None

    wt = wanted_title.replace(" ", "").lower()

    def score(item):
        t = str(item.get("TITLE", "") or item.get("title", "")).replace(" ", "").lower()
        if not t:
            return 0
        if t == wt:
            return 100
        if wt in t or t in wt:
            return 60
        return 10 if t[:5] == wt[:5] else 1

    return sorted(items, key=score, reverse=True)[0]


def fetch_text_from_url(url: str, max_chars: int = 700):
    if not url:
        return ""
    try:
        r = requests.get(url, timeout=30)
        r.raise_for_status()
        text = r.text

        text = re.sub(r"<script.*?>.*?</script>", " ", text, flags=re.DOTALL | re.IGNORECASE)
        text = re.sub(r"<style.*?>.*?</style>", " ", text, flags=re.DOTALL | re.IGNORECASE)
        text = re.sub(r"<[^>]+>", " ", text)
        text = unescape(text)
        text = re.sub(r"\s+", " ", text).strip()

        if len(text) > max_chars:
            text = text[:max_chars].rstrip() + "â€¦"
        return text
    except Exception:
        return ""


# =====================================================
# UI: Questionnaire
# =====================================================
st.divider()
st.subheader("ğŸ“ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”")

for i, q in enumerate(questions):
    st.markdown(f"**{q}**")
    st.radio(
        label=f"q{i+1}",
        options=question_choices[i],
        key=f"q{i+1}",
        index=None,
        label_visibility="collapsed",
    )
    st.write("")

st.divider()

c1, c2 = st.columns(2)
with c1:
    clicked = st.button("ê²°ê³¼ ë³´ê¸°", type="primary")
with c2:
    st.button("ë‹¤ì‹œ í…ŒìŠ¤íŠ¸í•˜ê¸°", on_click=reset_test)

# =====================================================
# Flow: analyze -> recommend -> (optionally) fetch real book info
# =====================================================
if clicked:
    answers = [st.session_state[f"q{i+1}"] for i in range(7)]
    if any(a is None for a in answers):
        missing = [str(i + 1) for i, a in enumerate(answers) if a is None]
        st.warning(f"ëª¨ë“  ì§ˆë¬¸ì— ë‹µë³€í•´ ì£¼ì„¸ìš”! (ë¯¸ì‘ë‹µ: {', '.join(missing)}ë²ˆ)")
    else:
        with st.spinner("ë¶„ì„ ì¤‘..."):
            # 1) ì„±í–¥(ì¥ë¥´) ì ìˆ˜
            genre_scores = compute_genre_scores(answers)
            top_genres, second_genres, genre_ranked = top_keys(genre_scores)

            # 2) ìƒí™© íƒœê·¸ ì ìˆ˜
            situation_scores = compute_situation_scores(answers)
            top_situations, second_situations, situation_ranked = top_keys(situation_scores)

            # focus genres for AI or mixing
            focus_genres = (top_genres[:2] if len(top_genres) >= 2 else top_genres + second_genres[:1]) or top_genres

            # 3) ì±… í›„ë³´ 3ê¶Œ ìƒì„±
            if openai_api_key:
                candidates = ai_pick_books(answers, focus_genres=focus_genres)
                # í˜¹ì‹œ ë¶€ì¡±í•˜ë©´ ë°ëª¨ë¡œ ë³´ì¶©
                if len(candidates) < 3:
                    fill = pick_3_books(top_genres, second_genres)
                    for f in fill:
                        if len(candidates) >= 3:
                            break
                        candidates.append({"title": f["title"], "author": f.get("author", ""), "genre": f["genre"]})
            else:
                fill = pick_3_books(top_genres, second_genres)
                candidates = [{"title": b["title"], "author": b.get("author", ""), "genre": b["genre"]} for b in fill]

            # 4) ê°œì¸í™” ì¶”ì²œ ì´ìœ (ì„¤ë¬¸ ê·¼ê±° + ìƒí™© íƒœê·¸ ê¸°ë°˜) ìƒì„±
            enriched = []
            for c in candidates[:3]:
                why = build_reason(answers, c["title"], c["genre"], top_situations)
                enriched.append({**c, "why": why})

            # 5) êµ­ë¦½ì¤‘ì•™ë„ì„œê´€ APIë¡œ ì‹¤ì œ ë„ì„œ ì •ë³´ ì¡°íšŒ(ê°€ëŠ¥í•  ë•Œë§Œ)
            books_final = []
            can_fetch_nl = bool(nl_api_key)

            if can_fetch_nl:
                for c in enriched:
                    title = c["title"]
                    author = c.get("author", "")

                    nl_json = nl_isbn_search(nl_api_key, title=title, author=author, page_size=10)
                    item = pick_best_item(nl_json, wanted_title=title)

                    if not item:
                        books_final.append(
                            {
                                **c,
                                "isbn": "",
                                "cover_url": "",
                                "summary": "",
                                "note": "êµ­ë¦½ì¤‘ì•™ë„ì„œê´€ì—ì„œ ì¼ì¹˜í•˜ëŠ” ë„ì„œë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”.",
                            }
                        )
                        continue

                    picked_title = item.get("TITLE") or item.get("title") or title
                    picked_author = item.get("AUTHOR") or item.get("author") or author
                    isbn = item.get("EA_ISBN") or item.get("ISBN") or item.get("isbn") or ""

                    cover_url = item.get("TITLE_URL") or item.get("cover") or item.get("image") or ""
                    intro_url = item.get("BOOK_INTRODUCTION_URL") or ""
                    summary_url = item.get("BOOK_SUMMARY_URL") or ""

                    summary_text = fetch_text_from_url(summary_url)
                    if not summary_text:
                        summary_text = fetch_text_from_url(intro_url)

                    books_final.append(
                        {
                            **c,
                            "title": str(picked_title).strip(),
                            "author": str(picked_author).strip(),
                            "isbn": str(isbn).strip(),
                            "cover_url": str(cover_url).strip(),
                            "summary": summary_text.strip(),
                            "note": "",
                        }
                    )
            else:
                # ë°ëª¨ ëª¨ë“œê°€ ì¼œì ¸ ìˆìœ¼ë©´ ê²°ê³¼ëŠ” ë³´ì—¬ì£¼ë˜, í‘œì§€/ì†Œê°œëŠ” ë¹„ì›€
                if demo_mode:
                    for c in enriched:
                        books_final.append({**c, "isbn": "", "cover_url": "", "summary": "", "note": ""})
                else:
                    # ë°ëª¨ ëª¨ë“œ OFF + í‚¤ ì—†ìŒ => ê²°ê³¼ë¥¼ ë§Œë“¤ì§€ ì•Šê³  ì•ˆë‚´ë§Œ
                    st.error("êµ­ë¦½ì¤‘ì•™ë„ì„œê´€ API í‚¤(cert_key)ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì— ì…ë ¥í•´ ì£¼ì„¸ìš”.")
                    st.stop()

            st.session_state.submitted = True
            st.session_state.result = {
                "genre_scores": genre_scores,
                "genre_top": top_genres,
                "genre_second": second_genres,
                "genre_ranked": genre_ranked,
                "situation_scores": situation_scores,
                "situation_top": top_situations,
                "situation_second": second_situations,
                "situation_ranked": situation_ranked,
                "focus_genres": focus_genres,
                "used_openai": bool(openai_api_key),
                "used_nl": can_fetch_nl,
                "books": books_final,
                "answers": answers,
            }


# =====================================================
# Render result
# =====================================================
if st.session_state.submitted and st.session_state.result:
    r = st.session_state.result

    st.subheader("ğŸ“Œ ë¶„ì„ ê²°ê³¼")

    # ì„±í–¥(ì¥ë¥´)
    if len(r["genre_top"]) >= 2:
        st.success(f"ë‹¹ì‹ ì˜ **ë…ì„œ ì„±í–¥(ë³µí•©)**: {', '.join(r['genre_top'])}")
    else:
        st.success(f"ë‹¹ì‹ ì˜ **ë…ì„œ ì„±í–¥**: {r['genre_top'][0]}")

    # ìƒí™©(íƒœê·¸)
    top_sit = r["situation_top"]
    sit_text = ", ".join([tag_display.get(t, t) for t in top_sit])
    st.info(f"í˜„ì¬ ë‹¹ì‹ ì—ê²Œ ê°€ì¥ í•„ìš”í•œ ê²ƒ: **{sit_text}**")

    # ì ìˆ˜ í‘œì‹œ(ê°„ë‹¨)
    st.caption("ì¥ë¥´ ì ìˆ˜: " + ", ".join([f"{k} {v}" for k, v in r["genre_scores"].items()]))
    st.caption("ìƒí™© ì ìˆ˜: " + ", ".join([f"{tag_display.get(k,k)} {v}" for k, v in r["situation_scores"].items()]))

    if not r["used_openai"]:
        st.info("OpenAI í‚¤ê°€ ì—†ì–´ **ë°ëª¨ ì¶”ì²œ ëª©ë¡**ìœ¼ë¡œ ë„ì„œë¥¼ ê³¨ëìŠµë‹ˆë‹¤. (ì¶”ì²œ ì´ìœ ëŠ” ì„¤ë¬¸ ë‹µë³€ ê·¼ê±° ê¸°ë°˜)")
    if not r["used_nl"]:
        st.warning("êµ­ë¦½ì¤‘ì•™ë„ì„œê´€ API í‚¤ê°€ ì—†ì–´ **í‘œì§€/ISBN/ì¤„ê±°ë¦¬**ëŠ” í‘œì‹œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. (ë°ëª¨ ëª¨ë“œ)")

    st.subheader("ğŸ“š ì¶”ì²œ ë„ì„œ 3ê¶Œ")
    for idx, b in enumerate(r["books"], start=1):
        st.markdown(f"### {idx}. {b['title']}")
        meta = []
        if b.get("author"):
            meta.append(f"ì €ì: {b['author']}")
        if b.get("isbn"):
            meta.append(f"ISBN: {b['isbn']}")
        if meta:
            st.caption(" Â· ".join(meta))

        cols = st.columns([1, 2])
        with cols[0]:
            if b.get("cover_url"):
                st.image(b["cover_url"], use_container_width=True)
            else:
                st.info("í‘œì§€ ì´ë¯¸ì§€ ì—†ìŒ(ë°ëª¨/ê²€ìƒ‰ ì‹¤íŒ¨)")

        with cols[1]:
            st.write("**ì´ ì±…ì„ ì¶”ì²œí•˜ëŠ” ì´ìœ (ì„¤ë¬¸ ê·¼ê±° + ìƒí™© ê¸°ë°˜)**")
            st.write(f"- {b.get('why','')}")

            st.write("**ì¤„ê±°ë¦¬/ì±…ì†Œê°œ**")
            if b.get("summary"):
                st.write(b["summary"])
            else:
                st.info("ì¤„ê±°ë¦¬/ì±…ì†Œê°œ ì •ë³´ë¥¼ ì•„ì§ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆì–´ìš”. (API í‚¤ í•„ìš” ë˜ëŠ” ì œê³µ URL ì—†ìŒ)")

            if b.get("note"):
                st.warning(b["note"])

        st.divider()
